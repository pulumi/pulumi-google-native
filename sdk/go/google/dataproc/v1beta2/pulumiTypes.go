// *** WARNING: this file was generated by the Pulumi SDK Generator. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package v1beta2

import (
	"context"
	"reflect"

	"github.com/pulumi/pulumi/sdk/v2/go/pulumi"
)

// Specifies the type and number of accelerator cards attached to the instances of an instance group (see GPUs on Compute Engine (https://cloud.google.com/compute/docs/gpus/)).
type AcceleratorConfig struct {
	// The number of the accelerator cards of this type exposed to this instance.
	AcceleratorCount *int `pulumi:"acceleratorCount"`
	// Full URL, partial URI, or short name of the accelerator type resource to expose to this instance. See Compute Engine AcceleratorTypes (https://cloud.google.com/compute/docs/reference/beta/acceleratorTypes)Examples * https://www.googleapis.com/compute/beta/projects/[project_id]/zones/us-east1-a/acceleratorTypes/nvidia-tesla-k80 * projects/[project_id]/zones/us-east1-a/acceleratorTypes/nvidia-tesla-k80 * nvidia-tesla-k80Auto Zone Exception: If you are using the Dataproc Auto Zone Placement (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement) feature, you must use the short name of the accelerator type resource, for example, nvidia-tesla-k80.
	AcceleratorTypeUri *string `pulumi:"acceleratorTypeUri"`
}

// AcceleratorConfigInput is an input type that accepts AcceleratorConfigArgs and AcceleratorConfigOutput values.
// You can construct a concrete instance of `AcceleratorConfigInput` via:
//
//          AcceleratorConfigArgs{...}
type AcceleratorConfigInput interface {
	pulumi.Input

	ToAcceleratorConfigOutput() AcceleratorConfigOutput
	ToAcceleratorConfigOutputWithContext(context.Context) AcceleratorConfigOutput
}

// Specifies the type and number of accelerator cards attached to the instances of an instance group (see GPUs on Compute Engine (https://cloud.google.com/compute/docs/gpus/)).
type AcceleratorConfigArgs struct {
	// The number of the accelerator cards of this type exposed to this instance.
	AcceleratorCount pulumi.IntPtrInput `pulumi:"acceleratorCount"`
	// Full URL, partial URI, or short name of the accelerator type resource to expose to this instance. See Compute Engine AcceleratorTypes (https://cloud.google.com/compute/docs/reference/beta/acceleratorTypes)Examples * https://www.googleapis.com/compute/beta/projects/[project_id]/zones/us-east1-a/acceleratorTypes/nvidia-tesla-k80 * projects/[project_id]/zones/us-east1-a/acceleratorTypes/nvidia-tesla-k80 * nvidia-tesla-k80Auto Zone Exception: If you are using the Dataproc Auto Zone Placement (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement) feature, you must use the short name of the accelerator type resource, for example, nvidia-tesla-k80.
	AcceleratorTypeUri pulumi.StringPtrInput `pulumi:"acceleratorTypeUri"`
}

func (AcceleratorConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AcceleratorConfig)(nil)).Elem()
}

func (i AcceleratorConfigArgs) ToAcceleratorConfigOutput() AcceleratorConfigOutput {
	return i.ToAcceleratorConfigOutputWithContext(context.Background())
}

func (i AcceleratorConfigArgs) ToAcceleratorConfigOutputWithContext(ctx context.Context) AcceleratorConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AcceleratorConfigOutput)
}

// AcceleratorConfigArrayInput is an input type that accepts AcceleratorConfigArray and AcceleratorConfigArrayOutput values.
// You can construct a concrete instance of `AcceleratorConfigArrayInput` via:
//
//          AcceleratorConfigArray{ AcceleratorConfigArgs{...} }
type AcceleratorConfigArrayInput interface {
	pulumi.Input

	ToAcceleratorConfigArrayOutput() AcceleratorConfigArrayOutput
	ToAcceleratorConfigArrayOutputWithContext(context.Context) AcceleratorConfigArrayOutput
}

type AcceleratorConfigArray []AcceleratorConfigInput

func (AcceleratorConfigArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AcceleratorConfig)(nil)).Elem()
}

func (i AcceleratorConfigArray) ToAcceleratorConfigArrayOutput() AcceleratorConfigArrayOutput {
	return i.ToAcceleratorConfigArrayOutputWithContext(context.Background())
}

func (i AcceleratorConfigArray) ToAcceleratorConfigArrayOutputWithContext(ctx context.Context) AcceleratorConfigArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AcceleratorConfigArrayOutput)
}

// Specifies the type and number of accelerator cards attached to the instances of an instance group (see GPUs on Compute Engine (https://cloud.google.com/compute/docs/gpus/)).
type AcceleratorConfigOutput struct{ *pulumi.OutputState }

func (AcceleratorConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AcceleratorConfig)(nil)).Elem()
}

func (o AcceleratorConfigOutput) ToAcceleratorConfigOutput() AcceleratorConfigOutput {
	return o
}

func (o AcceleratorConfigOutput) ToAcceleratorConfigOutputWithContext(ctx context.Context) AcceleratorConfigOutput {
	return o
}

// The number of the accelerator cards of this type exposed to this instance.
func (o AcceleratorConfigOutput) AcceleratorCount() pulumi.IntPtrOutput {
	return o.ApplyT(func(v AcceleratorConfig) *int { return v.AcceleratorCount }).(pulumi.IntPtrOutput)
}

// Full URL, partial URI, or short name of the accelerator type resource to expose to this instance. See Compute Engine AcceleratorTypes (https://cloud.google.com/compute/docs/reference/beta/acceleratorTypes)Examples * https://www.googleapis.com/compute/beta/projects/[project_id]/zones/us-east1-a/acceleratorTypes/nvidia-tesla-k80 * projects/[project_id]/zones/us-east1-a/acceleratorTypes/nvidia-tesla-k80 * nvidia-tesla-k80Auto Zone Exception: If you are using the Dataproc Auto Zone Placement (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement) feature, you must use the short name of the accelerator type resource, for example, nvidia-tesla-k80.
func (o AcceleratorConfigOutput) AcceleratorTypeUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AcceleratorConfig) *string { return v.AcceleratorTypeUri }).(pulumi.StringPtrOutput)
}

type AcceleratorConfigArrayOutput struct{ *pulumi.OutputState }

func (AcceleratorConfigArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]AcceleratorConfig)(nil)).Elem()
}

func (o AcceleratorConfigArrayOutput) ToAcceleratorConfigArrayOutput() AcceleratorConfigArrayOutput {
	return o
}

func (o AcceleratorConfigArrayOutput) ToAcceleratorConfigArrayOutputWithContext(ctx context.Context) AcceleratorConfigArrayOutput {
	return o
}

func (o AcceleratorConfigArrayOutput) Index(i pulumi.IntInput) AcceleratorConfigOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) AcceleratorConfig {
		return vs[0].([]AcceleratorConfig)[vs[1].(int)]
	}).(AcceleratorConfigOutput)
}

// Autoscaling Policy config associated with the cluster.
type AutoscalingConfig struct {
	// Optional. The autoscaling policy used by the cluster.Only resource names including projectid and location (region) are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/locations/[dataproc_region]/autoscalingPolicies/[policy_id] projects/[project_id]/locations/[dataproc_region]/autoscalingPolicies/[policy_id]Note that the policy must be in the same project and Dataproc region.
	PolicyUri *string `pulumi:"policyUri"`
}

// AutoscalingConfigInput is an input type that accepts AutoscalingConfigArgs and AutoscalingConfigOutput values.
// You can construct a concrete instance of `AutoscalingConfigInput` via:
//
//          AutoscalingConfigArgs{...}
type AutoscalingConfigInput interface {
	pulumi.Input

	ToAutoscalingConfigOutput() AutoscalingConfigOutput
	ToAutoscalingConfigOutputWithContext(context.Context) AutoscalingConfigOutput
}

// Autoscaling Policy config associated with the cluster.
type AutoscalingConfigArgs struct {
	// Optional. The autoscaling policy used by the cluster.Only resource names including projectid and location (region) are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/locations/[dataproc_region]/autoscalingPolicies/[policy_id] projects/[project_id]/locations/[dataproc_region]/autoscalingPolicies/[policy_id]Note that the policy must be in the same project and Dataproc region.
	PolicyUri pulumi.StringPtrInput `pulumi:"policyUri"`
}

func (AutoscalingConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*AutoscalingConfig)(nil)).Elem()
}

func (i AutoscalingConfigArgs) ToAutoscalingConfigOutput() AutoscalingConfigOutput {
	return i.ToAutoscalingConfigOutputWithContext(context.Background())
}

func (i AutoscalingConfigArgs) ToAutoscalingConfigOutputWithContext(ctx context.Context) AutoscalingConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AutoscalingConfigOutput)
}

func (i AutoscalingConfigArgs) ToAutoscalingConfigPtrOutput() AutoscalingConfigPtrOutput {
	return i.ToAutoscalingConfigPtrOutputWithContext(context.Background())
}

func (i AutoscalingConfigArgs) ToAutoscalingConfigPtrOutputWithContext(ctx context.Context) AutoscalingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AutoscalingConfigOutput).ToAutoscalingConfigPtrOutputWithContext(ctx)
}

// AutoscalingConfigPtrInput is an input type that accepts AutoscalingConfigArgs, AutoscalingConfigPtr and AutoscalingConfigPtrOutput values.
// You can construct a concrete instance of `AutoscalingConfigPtrInput` via:
//
//          AutoscalingConfigArgs{...}
//
//  or:
//
//          nil
type AutoscalingConfigPtrInput interface {
	pulumi.Input

	ToAutoscalingConfigPtrOutput() AutoscalingConfigPtrOutput
	ToAutoscalingConfigPtrOutputWithContext(context.Context) AutoscalingConfigPtrOutput
}

type autoscalingConfigPtrType AutoscalingConfigArgs

func AutoscalingConfigPtr(v *AutoscalingConfigArgs) AutoscalingConfigPtrInput {
	return (*autoscalingConfigPtrType)(v)
}

func (*autoscalingConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**AutoscalingConfig)(nil)).Elem()
}

func (i *autoscalingConfigPtrType) ToAutoscalingConfigPtrOutput() AutoscalingConfigPtrOutput {
	return i.ToAutoscalingConfigPtrOutputWithContext(context.Background())
}

func (i *autoscalingConfigPtrType) ToAutoscalingConfigPtrOutputWithContext(ctx context.Context) AutoscalingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(AutoscalingConfigPtrOutput)
}

// Autoscaling Policy config associated with the cluster.
type AutoscalingConfigOutput struct{ *pulumi.OutputState }

func (AutoscalingConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*AutoscalingConfig)(nil)).Elem()
}

func (o AutoscalingConfigOutput) ToAutoscalingConfigOutput() AutoscalingConfigOutput {
	return o
}

func (o AutoscalingConfigOutput) ToAutoscalingConfigOutputWithContext(ctx context.Context) AutoscalingConfigOutput {
	return o
}

func (o AutoscalingConfigOutput) ToAutoscalingConfigPtrOutput() AutoscalingConfigPtrOutput {
	return o.ToAutoscalingConfigPtrOutputWithContext(context.Background())
}

func (o AutoscalingConfigOutput) ToAutoscalingConfigPtrOutputWithContext(ctx context.Context) AutoscalingConfigPtrOutput {
	return o.ApplyT(func(v AutoscalingConfig) *AutoscalingConfig {
		return &v
	}).(AutoscalingConfigPtrOutput)
}

// Optional. The autoscaling policy used by the cluster.Only resource names including projectid and location (region) are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/locations/[dataproc_region]/autoscalingPolicies/[policy_id] projects/[project_id]/locations/[dataproc_region]/autoscalingPolicies/[policy_id]Note that the policy must be in the same project and Dataproc region.
func (o AutoscalingConfigOutput) PolicyUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v AutoscalingConfig) *string { return v.PolicyUri }).(pulumi.StringPtrOutput)
}

type AutoscalingConfigPtrOutput struct{ *pulumi.OutputState }

func (AutoscalingConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**AutoscalingConfig)(nil)).Elem()
}

func (o AutoscalingConfigPtrOutput) ToAutoscalingConfigPtrOutput() AutoscalingConfigPtrOutput {
	return o
}

func (o AutoscalingConfigPtrOutput) ToAutoscalingConfigPtrOutputWithContext(ctx context.Context) AutoscalingConfigPtrOutput {
	return o
}

func (o AutoscalingConfigPtrOutput) Elem() AutoscalingConfigOutput {
	return o.ApplyT(func(v *AutoscalingConfig) AutoscalingConfig { return *v }).(AutoscalingConfigOutput)
}

// Optional. The autoscaling policy used by the cluster.Only resource names including projectid and location (region) are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/locations/[dataproc_region]/autoscalingPolicies/[policy_id] projects/[project_id]/locations/[dataproc_region]/autoscalingPolicies/[policy_id]Note that the policy must be in the same project and Dataproc region.
func (o AutoscalingConfigPtrOutput) PolicyUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *AutoscalingConfig) *string {
		if v == nil {
			return nil
		}
		return v.PolicyUri
	}).(pulumi.StringPtrOutput)
}

// Basic algorithm for autoscaling.
type BasicAutoscalingAlgorithm struct {
	// Optional. Duration between scaling events. A scaling period starts after the update operation from the previous event has completed.Bounds: 2m, 1d. Default: 2m.
	CooldownPeriod *string `pulumi:"cooldownPeriod"`
	// Required. YARN autoscaling configuration.
	YarnConfig *BasicYarnAutoscalingConfig `pulumi:"yarnConfig"`
}

// BasicAutoscalingAlgorithmInput is an input type that accepts BasicAutoscalingAlgorithmArgs and BasicAutoscalingAlgorithmOutput values.
// You can construct a concrete instance of `BasicAutoscalingAlgorithmInput` via:
//
//          BasicAutoscalingAlgorithmArgs{...}
type BasicAutoscalingAlgorithmInput interface {
	pulumi.Input

	ToBasicAutoscalingAlgorithmOutput() BasicAutoscalingAlgorithmOutput
	ToBasicAutoscalingAlgorithmOutputWithContext(context.Context) BasicAutoscalingAlgorithmOutput
}

// Basic algorithm for autoscaling.
type BasicAutoscalingAlgorithmArgs struct {
	// Optional. Duration between scaling events. A scaling period starts after the update operation from the previous event has completed.Bounds: 2m, 1d. Default: 2m.
	CooldownPeriod pulumi.StringPtrInput `pulumi:"cooldownPeriod"`
	// Required. YARN autoscaling configuration.
	YarnConfig BasicYarnAutoscalingConfigPtrInput `pulumi:"yarnConfig"`
}

func (BasicAutoscalingAlgorithmArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*BasicAutoscalingAlgorithm)(nil)).Elem()
}

func (i BasicAutoscalingAlgorithmArgs) ToBasicAutoscalingAlgorithmOutput() BasicAutoscalingAlgorithmOutput {
	return i.ToBasicAutoscalingAlgorithmOutputWithContext(context.Background())
}

func (i BasicAutoscalingAlgorithmArgs) ToBasicAutoscalingAlgorithmOutputWithContext(ctx context.Context) BasicAutoscalingAlgorithmOutput {
	return pulumi.ToOutputWithContext(ctx, i).(BasicAutoscalingAlgorithmOutput)
}

func (i BasicAutoscalingAlgorithmArgs) ToBasicAutoscalingAlgorithmPtrOutput() BasicAutoscalingAlgorithmPtrOutput {
	return i.ToBasicAutoscalingAlgorithmPtrOutputWithContext(context.Background())
}

func (i BasicAutoscalingAlgorithmArgs) ToBasicAutoscalingAlgorithmPtrOutputWithContext(ctx context.Context) BasicAutoscalingAlgorithmPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(BasicAutoscalingAlgorithmOutput).ToBasicAutoscalingAlgorithmPtrOutputWithContext(ctx)
}

// BasicAutoscalingAlgorithmPtrInput is an input type that accepts BasicAutoscalingAlgorithmArgs, BasicAutoscalingAlgorithmPtr and BasicAutoscalingAlgorithmPtrOutput values.
// You can construct a concrete instance of `BasicAutoscalingAlgorithmPtrInput` via:
//
//          BasicAutoscalingAlgorithmArgs{...}
//
//  or:
//
//          nil
type BasicAutoscalingAlgorithmPtrInput interface {
	pulumi.Input

	ToBasicAutoscalingAlgorithmPtrOutput() BasicAutoscalingAlgorithmPtrOutput
	ToBasicAutoscalingAlgorithmPtrOutputWithContext(context.Context) BasicAutoscalingAlgorithmPtrOutput
}

type basicAutoscalingAlgorithmPtrType BasicAutoscalingAlgorithmArgs

func BasicAutoscalingAlgorithmPtr(v *BasicAutoscalingAlgorithmArgs) BasicAutoscalingAlgorithmPtrInput {
	return (*basicAutoscalingAlgorithmPtrType)(v)
}

func (*basicAutoscalingAlgorithmPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**BasicAutoscalingAlgorithm)(nil)).Elem()
}

func (i *basicAutoscalingAlgorithmPtrType) ToBasicAutoscalingAlgorithmPtrOutput() BasicAutoscalingAlgorithmPtrOutput {
	return i.ToBasicAutoscalingAlgorithmPtrOutputWithContext(context.Background())
}

func (i *basicAutoscalingAlgorithmPtrType) ToBasicAutoscalingAlgorithmPtrOutputWithContext(ctx context.Context) BasicAutoscalingAlgorithmPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(BasicAutoscalingAlgorithmPtrOutput)
}

// Basic algorithm for autoscaling.
type BasicAutoscalingAlgorithmOutput struct{ *pulumi.OutputState }

func (BasicAutoscalingAlgorithmOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*BasicAutoscalingAlgorithm)(nil)).Elem()
}

func (o BasicAutoscalingAlgorithmOutput) ToBasicAutoscalingAlgorithmOutput() BasicAutoscalingAlgorithmOutput {
	return o
}

func (o BasicAutoscalingAlgorithmOutput) ToBasicAutoscalingAlgorithmOutputWithContext(ctx context.Context) BasicAutoscalingAlgorithmOutput {
	return o
}

func (o BasicAutoscalingAlgorithmOutput) ToBasicAutoscalingAlgorithmPtrOutput() BasicAutoscalingAlgorithmPtrOutput {
	return o.ToBasicAutoscalingAlgorithmPtrOutputWithContext(context.Background())
}

func (o BasicAutoscalingAlgorithmOutput) ToBasicAutoscalingAlgorithmPtrOutputWithContext(ctx context.Context) BasicAutoscalingAlgorithmPtrOutput {
	return o.ApplyT(func(v BasicAutoscalingAlgorithm) *BasicAutoscalingAlgorithm {
		return &v
	}).(BasicAutoscalingAlgorithmPtrOutput)
}

// Optional. Duration between scaling events. A scaling period starts after the update operation from the previous event has completed.Bounds: 2m, 1d. Default: 2m.
func (o BasicAutoscalingAlgorithmOutput) CooldownPeriod() pulumi.StringPtrOutput {
	return o.ApplyT(func(v BasicAutoscalingAlgorithm) *string { return v.CooldownPeriod }).(pulumi.StringPtrOutput)
}

// Required. YARN autoscaling configuration.
func (o BasicAutoscalingAlgorithmOutput) YarnConfig() BasicYarnAutoscalingConfigPtrOutput {
	return o.ApplyT(func(v BasicAutoscalingAlgorithm) *BasicYarnAutoscalingConfig { return v.YarnConfig }).(BasicYarnAutoscalingConfigPtrOutput)
}

type BasicAutoscalingAlgorithmPtrOutput struct{ *pulumi.OutputState }

func (BasicAutoscalingAlgorithmPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**BasicAutoscalingAlgorithm)(nil)).Elem()
}

func (o BasicAutoscalingAlgorithmPtrOutput) ToBasicAutoscalingAlgorithmPtrOutput() BasicAutoscalingAlgorithmPtrOutput {
	return o
}

func (o BasicAutoscalingAlgorithmPtrOutput) ToBasicAutoscalingAlgorithmPtrOutputWithContext(ctx context.Context) BasicAutoscalingAlgorithmPtrOutput {
	return o
}

func (o BasicAutoscalingAlgorithmPtrOutput) Elem() BasicAutoscalingAlgorithmOutput {
	return o.ApplyT(func(v *BasicAutoscalingAlgorithm) BasicAutoscalingAlgorithm { return *v }).(BasicAutoscalingAlgorithmOutput)
}

// Optional. Duration between scaling events. A scaling period starts after the update operation from the previous event has completed.Bounds: 2m, 1d. Default: 2m.
func (o BasicAutoscalingAlgorithmPtrOutput) CooldownPeriod() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *BasicAutoscalingAlgorithm) *string {
		if v == nil {
			return nil
		}
		return v.CooldownPeriod
	}).(pulumi.StringPtrOutput)
}

// Required. YARN autoscaling configuration.
func (o BasicAutoscalingAlgorithmPtrOutput) YarnConfig() BasicYarnAutoscalingConfigPtrOutput {
	return o.ApplyT(func(v *BasicAutoscalingAlgorithm) *BasicYarnAutoscalingConfig {
		if v == nil {
			return nil
		}
		return v.YarnConfig
	}).(BasicYarnAutoscalingConfigPtrOutput)
}

// Basic autoscaling configurations for YARN.
type BasicYarnAutoscalingConfig struct {
	// Required. Timeout for YARN graceful decommissioning of Node Managers. Specifies the duration to wait for jobs to complete before forcefully removing workers (and potentially interrupting jobs). Only applicable to downscaling operations.Bounds: 0s, 1d.
	GracefulDecommissionTimeout *string `pulumi:"gracefulDecommissionTimeout"`
	// Required. Fraction of average YARN pending memory in the last cooldown period for which to remove workers. A scale-down factor of 1 will result in scaling down so that there is no available memory remaining after the update (more aggressive scaling). A scale-down factor of 0 disables removing workers, which can be beneficial for autoscaling a single job. See How autoscaling works for more information.Bounds: 0.0, 1.0.
	ScaleDownFactor *float64 `pulumi:"scaleDownFactor"`
	// Optional. Minimum scale-down threshold as a fraction of total cluster size before scaling occurs. For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler must recommend at least a 2 worker scale-down for the cluster to scale. A threshold of 0 means the autoscaler will scale down on any recommended change.Bounds: 0.0, 1.0. Default: 0.0.
	ScaleDownMinWorkerFraction *float64 `pulumi:"scaleDownMinWorkerFraction"`
	// Required. Fraction of average YARN pending memory in the last cooldown period for which to add workers. A scale-up factor of 1.0 will result in scaling up so that there is no pending memory remaining after the update (more aggressive scaling). A scale-up factor closer to 0 will result in a smaller magnitude of scaling up (less aggressive scaling). See How autoscaling works for more information.Bounds: 0.0, 1.0.
	ScaleUpFactor *float64 `pulumi:"scaleUpFactor"`
	// Optional. Minimum scale-up threshold as a fraction of total cluster size before scaling occurs. For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler must recommend at least a 2-worker scale-up for the cluster to scale. A threshold of 0 means the autoscaler will scale up on any recommended change.Bounds: 0.0, 1.0. Default: 0.0.
	ScaleUpMinWorkerFraction *float64 `pulumi:"scaleUpMinWorkerFraction"`
}

// BasicYarnAutoscalingConfigInput is an input type that accepts BasicYarnAutoscalingConfigArgs and BasicYarnAutoscalingConfigOutput values.
// You can construct a concrete instance of `BasicYarnAutoscalingConfigInput` via:
//
//          BasicYarnAutoscalingConfigArgs{...}
type BasicYarnAutoscalingConfigInput interface {
	pulumi.Input

	ToBasicYarnAutoscalingConfigOutput() BasicYarnAutoscalingConfigOutput
	ToBasicYarnAutoscalingConfigOutputWithContext(context.Context) BasicYarnAutoscalingConfigOutput
}

// Basic autoscaling configurations for YARN.
type BasicYarnAutoscalingConfigArgs struct {
	// Required. Timeout for YARN graceful decommissioning of Node Managers. Specifies the duration to wait for jobs to complete before forcefully removing workers (and potentially interrupting jobs). Only applicable to downscaling operations.Bounds: 0s, 1d.
	GracefulDecommissionTimeout pulumi.StringPtrInput `pulumi:"gracefulDecommissionTimeout"`
	// Required. Fraction of average YARN pending memory in the last cooldown period for which to remove workers. A scale-down factor of 1 will result in scaling down so that there is no available memory remaining after the update (more aggressive scaling). A scale-down factor of 0 disables removing workers, which can be beneficial for autoscaling a single job. See How autoscaling works for more information.Bounds: 0.0, 1.0.
	ScaleDownFactor pulumi.Float64PtrInput `pulumi:"scaleDownFactor"`
	// Optional. Minimum scale-down threshold as a fraction of total cluster size before scaling occurs. For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler must recommend at least a 2 worker scale-down for the cluster to scale. A threshold of 0 means the autoscaler will scale down on any recommended change.Bounds: 0.0, 1.0. Default: 0.0.
	ScaleDownMinWorkerFraction pulumi.Float64PtrInput `pulumi:"scaleDownMinWorkerFraction"`
	// Required. Fraction of average YARN pending memory in the last cooldown period for which to add workers. A scale-up factor of 1.0 will result in scaling up so that there is no pending memory remaining after the update (more aggressive scaling). A scale-up factor closer to 0 will result in a smaller magnitude of scaling up (less aggressive scaling). See How autoscaling works for more information.Bounds: 0.0, 1.0.
	ScaleUpFactor pulumi.Float64PtrInput `pulumi:"scaleUpFactor"`
	// Optional. Minimum scale-up threshold as a fraction of total cluster size before scaling occurs. For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler must recommend at least a 2-worker scale-up for the cluster to scale. A threshold of 0 means the autoscaler will scale up on any recommended change.Bounds: 0.0, 1.0. Default: 0.0.
	ScaleUpMinWorkerFraction pulumi.Float64PtrInput `pulumi:"scaleUpMinWorkerFraction"`
}

func (BasicYarnAutoscalingConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*BasicYarnAutoscalingConfig)(nil)).Elem()
}

func (i BasicYarnAutoscalingConfigArgs) ToBasicYarnAutoscalingConfigOutput() BasicYarnAutoscalingConfigOutput {
	return i.ToBasicYarnAutoscalingConfigOutputWithContext(context.Background())
}

func (i BasicYarnAutoscalingConfigArgs) ToBasicYarnAutoscalingConfigOutputWithContext(ctx context.Context) BasicYarnAutoscalingConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(BasicYarnAutoscalingConfigOutput)
}

func (i BasicYarnAutoscalingConfigArgs) ToBasicYarnAutoscalingConfigPtrOutput() BasicYarnAutoscalingConfigPtrOutput {
	return i.ToBasicYarnAutoscalingConfigPtrOutputWithContext(context.Background())
}

func (i BasicYarnAutoscalingConfigArgs) ToBasicYarnAutoscalingConfigPtrOutputWithContext(ctx context.Context) BasicYarnAutoscalingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(BasicYarnAutoscalingConfigOutput).ToBasicYarnAutoscalingConfigPtrOutputWithContext(ctx)
}

// BasicYarnAutoscalingConfigPtrInput is an input type that accepts BasicYarnAutoscalingConfigArgs, BasicYarnAutoscalingConfigPtr and BasicYarnAutoscalingConfigPtrOutput values.
// You can construct a concrete instance of `BasicYarnAutoscalingConfigPtrInput` via:
//
//          BasicYarnAutoscalingConfigArgs{...}
//
//  or:
//
//          nil
type BasicYarnAutoscalingConfigPtrInput interface {
	pulumi.Input

	ToBasicYarnAutoscalingConfigPtrOutput() BasicYarnAutoscalingConfigPtrOutput
	ToBasicYarnAutoscalingConfigPtrOutputWithContext(context.Context) BasicYarnAutoscalingConfigPtrOutput
}

type basicYarnAutoscalingConfigPtrType BasicYarnAutoscalingConfigArgs

func BasicYarnAutoscalingConfigPtr(v *BasicYarnAutoscalingConfigArgs) BasicYarnAutoscalingConfigPtrInput {
	return (*basicYarnAutoscalingConfigPtrType)(v)
}

func (*basicYarnAutoscalingConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**BasicYarnAutoscalingConfig)(nil)).Elem()
}

func (i *basicYarnAutoscalingConfigPtrType) ToBasicYarnAutoscalingConfigPtrOutput() BasicYarnAutoscalingConfigPtrOutput {
	return i.ToBasicYarnAutoscalingConfigPtrOutputWithContext(context.Background())
}

func (i *basicYarnAutoscalingConfigPtrType) ToBasicYarnAutoscalingConfigPtrOutputWithContext(ctx context.Context) BasicYarnAutoscalingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(BasicYarnAutoscalingConfigPtrOutput)
}

// Basic autoscaling configurations for YARN.
type BasicYarnAutoscalingConfigOutput struct{ *pulumi.OutputState }

func (BasicYarnAutoscalingConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*BasicYarnAutoscalingConfig)(nil)).Elem()
}

func (o BasicYarnAutoscalingConfigOutput) ToBasicYarnAutoscalingConfigOutput() BasicYarnAutoscalingConfigOutput {
	return o
}

func (o BasicYarnAutoscalingConfigOutput) ToBasicYarnAutoscalingConfigOutputWithContext(ctx context.Context) BasicYarnAutoscalingConfigOutput {
	return o
}

func (o BasicYarnAutoscalingConfigOutput) ToBasicYarnAutoscalingConfigPtrOutput() BasicYarnAutoscalingConfigPtrOutput {
	return o.ToBasicYarnAutoscalingConfigPtrOutputWithContext(context.Background())
}

func (o BasicYarnAutoscalingConfigOutput) ToBasicYarnAutoscalingConfigPtrOutputWithContext(ctx context.Context) BasicYarnAutoscalingConfigPtrOutput {
	return o.ApplyT(func(v BasicYarnAutoscalingConfig) *BasicYarnAutoscalingConfig {
		return &v
	}).(BasicYarnAutoscalingConfigPtrOutput)
}

// Required. Timeout for YARN graceful decommissioning of Node Managers. Specifies the duration to wait for jobs to complete before forcefully removing workers (and potentially interrupting jobs). Only applicable to downscaling operations.Bounds: 0s, 1d.
func (o BasicYarnAutoscalingConfigOutput) GracefulDecommissionTimeout() pulumi.StringPtrOutput {
	return o.ApplyT(func(v BasicYarnAutoscalingConfig) *string { return v.GracefulDecommissionTimeout }).(pulumi.StringPtrOutput)
}

// Required. Fraction of average YARN pending memory in the last cooldown period for which to remove workers. A scale-down factor of 1 will result in scaling down so that there is no available memory remaining after the update (more aggressive scaling). A scale-down factor of 0 disables removing workers, which can be beneficial for autoscaling a single job. See How autoscaling works for more information.Bounds: 0.0, 1.0.
func (o BasicYarnAutoscalingConfigOutput) ScaleDownFactor() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v BasicYarnAutoscalingConfig) *float64 { return v.ScaleDownFactor }).(pulumi.Float64PtrOutput)
}

// Optional. Minimum scale-down threshold as a fraction of total cluster size before scaling occurs. For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler must recommend at least a 2 worker scale-down for the cluster to scale. A threshold of 0 means the autoscaler will scale down on any recommended change.Bounds: 0.0, 1.0. Default: 0.0.
func (o BasicYarnAutoscalingConfigOutput) ScaleDownMinWorkerFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v BasicYarnAutoscalingConfig) *float64 { return v.ScaleDownMinWorkerFraction }).(pulumi.Float64PtrOutput)
}

// Required. Fraction of average YARN pending memory in the last cooldown period for which to add workers. A scale-up factor of 1.0 will result in scaling up so that there is no pending memory remaining after the update (more aggressive scaling). A scale-up factor closer to 0 will result in a smaller magnitude of scaling up (less aggressive scaling). See How autoscaling works for more information.Bounds: 0.0, 1.0.
func (o BasicYarnAutoscalingConfigOutput) ScaleUpFactor() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v BasicYarnAutoscalingConfig) *float64 { return v.ScaleUpFactor }).(pulumi.Float64PtrOutput)
}

// Optional. Minimum scale-up threshold as a fraction of total cluster size before scaling occurs. For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler must recommend at least a 2-worker scale-up for the cluster to scale. A threshold of 0 means the autoscaler will scale up on any recommended change.Bounds: 0.0, 1.0. Default: 0.0.
func (o BasicYarnAutoscalingConfigOutput) ScaleUpMinWorkerFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v BasicYarnAutoscalingConfig) *float64 { return v.ScaleUpMinWorkerFraction }).(pulumi.Float64PtrOutput)
}

type BasicYarnAutoscalingConfigPtrOutput struct{ *pulumi.OutputState }

func (BasicYarnAutoscalingConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**BasicYarnAutoscalingConfig)(nil)).Elem()
}

func (o BasicYarnAutoscalingConfigPtrOutput) ToBasicYarnAutoscalingConfigPtrOutput() BasicYarnAutoscalingConfigPtrOutput {
	return o
}

func (o BasicYarnAutoscalingConfigPtrOutput) ToBasicYarnAutoscalingConfigPtrOutputWithContext(ctx context.Context) BasicYarnAutoscalingConfigPtrOutput {
	return o
}

func (o BasicYarnAutoscalingConfigPtrOutput) Elem() BasicYarnAutoscalingConfigOutput {
	return o.ApplyT(func(v *BasicYarnAutoscalingConfig) BasicYarnAutoscalingConfig { return *v }).(BasicYarnAutoscalingConfigOutput)
}

// Required. Timeout for YARN graceful decommissioning of Node Managers. Specifies the duration to wait for jobs to complete before forcefully removing workers (and potentially interrupting jobs). Only applicable to downscaling operations.Bounds: 0s, 1d.
func (o BasicYarnAutoscalingConfigPtrOutput) GracefulDecommissionTimeout() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *BasicYarnAutoscalingConfig) *string {
		if v == nil {
			return nil
		}
		return v.GracefulDecommissionTimeout
	}).(pulumi.StringPtrOutput)
}

// Required. Fraction of average YARN pending memory in the last cooldown period for which to remove workers. A scale-down factor of 1 will result in scaling down so that there is no available memory remaining after the update (more aggressive scaling). A scale-down factor of 0 disables removing workers, which can be beneficial for autoscaling a single job. See How autoscaling works for more information.Bounds: 0.0, 1.0.
func (o BasicYarnAutoscalingConfigPtrOutput) ScaleDownFactor() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *BasicYarnAutoscalingConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.ScaleDownFactor
	}).(pulumi.Float64PtrOutput)
}

// Optional. Minimum scale-down threshold as a fraction of total cluster size before scaling occurs. For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler must recommend at least a 2 worker scale-down for the cluster to scale. A threshold of 0 means the autoscaler will scale down on any recommended change.Bounds: 0.0, 1.0. Default: 0.0.
func (o BasicYarnAutoscalingConfigPtrOutput) ScaleDownMinWorkerFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *BasicYarnAutoscalingConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.ScaleDownMinWorkerFraction
	}).(pulumi.Float64PtrOutput)
}

// Required. Fraction of average YARN pending memory in the last cooldown period for which to add workers. A scale-up factor of 1.0 will result in scaling up so that there is no pending memory remaining after the update (more aggressive scaling). A scale-up factor closer to 0 will result in a smaller magnitude of scaling up (less aggressive scaling). See How autoscaling works for more information.Bounds: 0.0, 1.0.
func (o BasicYarnAutoscalingConfigPtrOutput) ScaleUpFactor() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *BasicYarnAutoscalingConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.ScaleUpFactor
	}).(pulumi.Float64PtrOutput)
}

// Optional. Minimum scale-up threshold as a fraction of total cluster size before scaling occurs. For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler must recommend at least a 2-worker scale-up for the cluster to scale. A threshold of 0 means the autoscaler will scale up on any recommended change.Bounds: 0.0, 1.0. Default: 0.0.
func (o BasicYarnAutoscalingConfigPtrOutput) ScaleUpMinWorkerFraction() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *BasicYarnAutoscalingConfig) *float64 {
		if v == nil {
			return nil
		}
		return v.ScaleUpMinWorkerFraction
	}).(pulumi.Float64PtrOutput)
}

// Associates members with a role.
type Binding struct {
	// The condition that is associated with this binding.If the condition evaluates to true, then this binding applies to the current request.If the condition evaluates to false, then this binding does not apply to the current request. However, a different role binding might grant the same role to one or more of the members in this binding.To learn which resources support conditions in their IAM policies, see the IAM documentation (https://cloud.google.com/iam/help/conditions/resource-policies).
	Condition *Expr `pulumi:"condition"`
	// Specifies the identities requesting access for a Cloud Platform resource. members can have the following values: allUsers: A special identifier that represents anyone who is on the internet; with or without a Google account. allAuthenticatedUsers: A special identifier that represents anyone who is authenticated with a Google account or a service account. user:{emailid}: An email address that represents a specific Google account. For example, alice@example.com . serviceAccount:{emailid}: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com. group:{emailid}: An email address that represents a Google group. For example, admins@example.com. deleted:user:{emailid}?uid={uniqueid}: An email address (plus unique identifier) representing a user that has been recently deleted. For example, alice@example.com?uid=123456789012345678901. If the user is recovered, this value reverts to user:{emailid} and the recovered user retains the role in the binding. deleted:serviceAccount:{emailid}?uid={uniqueid}: An email address (plus unique identifier) representing a service account that has been recently deleted. For example, my-other-app@appspot.gserviceaccount.com?uid=123456789012345678901. If the service account is undeleted, this value reverts to serviceAccount:{emailid} and the undeleted service account retains the role in the binding. deleted:group:{emailid}?uid={uniqueid}: An email address (plus unique identifier) representing a Google group that has been recently deleted. For example, admins@example.com?uid=123456789012345678901. If the group is recovered, this value reverts to group:{emailid} and the recovered group retains the role in the binding. domain:{domain}: The G Suite domain (primary) that represents all the users of that domain. For example, google.com or example.com.
	Members []string `pulumi:"members"`
	// Role that is assigned to members. For example, roles/viewer, roles/editor, or roles/owner.
	Role *string `pulumi:"role"`
}

// BindingInput is an input type that accepts BindingArgs and BindingOutput values.
// You can construct a concrete instance of `BindingInput` via:
//
//          BindingArgs{...}
type BindingInput interface {
	pulumi.Input

	ToBindingOutput() BindingOutput
	ToBindingOutputWithContext(context.Context) BindingOutput
}

// Associates members with a role.
type BindingArgs struct {
	// The condition that is associated with this binding.If the condition evaluates to true, then this binding applies to the current request.If the condition evaluates to false, then this binding does not apply to the current request. However, a different role binding might grant the same role to one or more of the members in this binding.To learn which resources support conditions in their IAM policies, see the IAM documentation (https://cloud.google.com/iam/help/conditions/resource-policies).
	Condition ExprPtrInput `pulumi:"condition"`
	// Specifies the identities requesting access for a Cloud Platform resource. members can have the following values: allUsers: A special identifier that represents anyone who is on the internet; with or without a Google account. allAuthenticatedUsers: A special identifier that represents anyone who is authenticated with a Google account or a service account. user:{emailid}: An email address that represents a specific Google account. For example, alice@example.com . serviceAccount:{emailid}: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com. group:{emailid}: An email address that represents a Google group. For example, admins@example.com. deleted:user:{emailid}?uid={uniqueid}: An email address (plus unique identifier) representing a user that has been recently deleted. For example, alice@example.com?uid=123456789012345678901. If the user is recovered, this value reverts to user:{emailid} and the recovered user retains the role in the binding. deleted:serviceAccount:{emailid}?uid={uniqueid}: An email address (plus unique identifier) representing a service account that has been recently deleted. For example, my-other-app@appspot.gserviceaccount.com?uid=123456789012345678901. If the service account is undeleted, this value reverts to serviceAccount:{emailid} and the undeleted service account retains the role in the binding. deleted:group:{emailid}?uid={uniqueid}: An email address (plus unique identifier) representing a Google group that has been recently deleted. For example, admins@example.com?uid=123456789012345678901. If the group is recovered, this value reverts to group:{emailid} and the recovered group retains the role in the binding. domain:{domain}: The G Suite domain (primary) that represents all the users of that domain. For example, google.com or example.com.
	Members pulumi.StringArrayInput `pulumi:"members"`
	// Role that is assigned to members. For example, roles/viewer, roles/editor, or roles/owner.
	Role pulumi.StringPtrInput `pulumi:"role"`
}

func (BindingArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*Binding)(nil)).Elem()
}

func (i BindingArgs) ToBindingOutput() BindingOutput {
	return i.ToBindingOutputWithContext(context.Background())
}

func (i BindingArgs) ToBindingOutputWithContext(ctx context.Context) BindingOutput {
	return pulumi.ToOutputWithContext(ctx, i).(BindingOutput)
}

// BindingArrayInput is an input type that accepts BindingArray and BindingArrayOutput values.
// You can construct a concrete instance of `BindingArrayInput` via:
//
//          BindingArray{ BindingArgs{...} }
type BindingArrayInput interface {
	pulumi.Input

	ToBindingArrayOutput() BindingArrayOutput
	ToBindingArrayOutputWithContext(context.Context) BindingArrayOutput
}

type BindingArray []BindingInput

func (BindingArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]Binding)(nil)).Elem()
}

func (i BindingArray) ToBindingArrayOutput() BindingArrayOutput {
	return i.ToBindingArrayOutputWithContext(context.Background())
}

func (i BindingArray) ToBindingArrayOutputWithContext(ctx context.Context) BindingArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(BindingArrayOutput)
}

// Associates members with a role.
type BindingOutput struct{ *pulumi.OutputState }

func (BindingOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*Binding)(nil)).Elem()
}

func (o BindingOutput) ToBindingOutput() BindingOutput {
	return o
}

func (o BindingOutput) ToBindingOutputWithContext(ctx context.Context) BindingOutput {
	return o
}

// The condition that is associated with this binding.If the condition evaluates to true, then this binding applies to the current request.If the condition evaluates to false, then this binding does not apply to the current request. However, a different role binding might grant the same role to one or more of the members in this binding.To learn which resources support conditions in their IAM policies, see the IAM documentation (https://cloud.google.com/iam/help/conditions/resource-policies).
func (o BindingOutput) Condition() ExprPtrOutput {
	return o.ApplyT(func(v Binding) *Expr { return v.Condition }).(ExprPtrOutput)
}

// Specifies the identities requesting access for a Cloud Platform resource. members can have the following values: allUsers: A special identifier that represents anyone who is on the internet; with or without a Google account. allAuthenticatedUsers: A special identifier that represents anyone who is authenticated with a Google account or a service account. user:{emailid}: An email address that represents a specific Google account. For example, alice@example.com . serviceAccount:{emailid}: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com. group:{emailid}: An email address that represents a Google group. For example, admins@example.com. deleted:user:{emailid}?uid={uniqueid}: An email address (plus unique identifier) representing a user that has been recently deleted. For example, alice@example.com?uid=123456789012345678901. If the user is recovered, this value reverts to user:{emailid} and the recovered user retains the role in the binding. deleted:serviceAccount:{emailid}?uid={uniqueid}: An email address (plus unique identifier) representing a service account that has been recently deleted. For example, my-other-app@appspot.gserviceaccount.com?uid=123456789012345678901. If the service account is undeleted, this value reverts to serviceAccount:{emailid} and the undeleted service account retains the role in the binding. deleted:group:{emailid}?uid={uniqueid}: An email address (plus unique identifier) representing a Google group that has been recently deleted. For example, admins@example.com?uid=123456789012345678901. If the group is recovered, this value reverts to group:{emailid} and the recovered group retains the role in the binding. domain:{domain}: The G Suite domain (primary) that represents all the users of that domain. For example, google.com or example.com.
func (o BindingOutput) Members() pulumi.StringArrayOutput {
	return o.ApplyT(func(v Binding) []string { return v.Members }).(pulumi.StringArrayOutput)
}

// Role that is assigned to members. For example, roles/viewer, roles/editor, or roles/owner.
func (o BindingOutput) Role() pulumi.StringPtrOutput {
	return o.ApplyT(func(v Binding) *string { return v.Role }).(pulumi.StringPtrOutput)
}

type BindingArrayOutput struct{ *pulumi.OutputState }

func (BindingArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]Binding)(nil)).Elem()
}

func (o BindingArrayOutput) ToBindingArrayOutput() BindingArrayOutput {
	return o
}

func (o BindingArrayOutput) ToBindingArrayOutputWithContext(ctx context.Context) BindingArrayOutput {
	return o
}

func (o BindingArrayOutput) Index(i pulumi.IntInput) BindingOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) Binding {
		return vs[0].([]Binding)[vs[1].(int)]
	}).(BindingOutput)
}

// The cluster config.
type ClusterConfig struct {
	// Optional. Autoscaling config for the policy associated with the cluster. Cluster does not autoscale if this field is unset.
	AutoscalingConfig *AutoscalingConfig `pulumi:"autoscalingConfig"`
	// Optional. A Cloud Storage bucket used to stage job dependencies, config files, and job driver console output. If you do not specify a staging bucket, Cloud Dataproc will determine a Cloud Storage location (US, ASIA, or EU) for your cluster's staging bucket according to the Compute Engine zone where your cluster is deployed, and then create and manage this project-level, per-location bucket (see Dataproc staging bucket (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)). This field requires a Cloud Storage bucket name, not a URI to a Cloud Storage bucket.
	ConfigBucket *string `pulumi:"configBucket"`
	// Optional. Encryption settings for the cluster.
	EncryptionConfig *EncryptionConfig `pulumi:"encryptionConfig"`
	// Optional. Port/endpoint configuration for this cluster
	EndpointConfig *EndpointConfig `pulumi:"endpointConfig"`
	// Optional. The shared Compute Engine config settings for all instances in a cluster.
	GceClusterConfig *GceClusterConfig `pulumi:"gceClusterConfig"`
	// Optional. The Kubernetes Engine config for Dataproc clusters deployed to Kubernetes. Setting this is considered mutually exclusive with Compute Engine-based options such as gce_cluster_config, master_config, worker_config, secondary_worker_config, and autoscaling_config.
	GkeClusterConfig *GkeClusterConfig `pulumi:"gkeClusterConfig"`
	// Optional. Commands to execute on each node after config is completed. By default, executables are run on master and all worker nodes. You can test a node's role metadata to run an executable on a master or worker node, as shown below using curl (you can also use wget): ROLE=$(curl -H Metadata-Flavor:Google http://metadata/computeMetadata/v1beta2/instance/attributes/dataproc-role) if [[ "${ROLE}" == 'Master' ]]; then ... master specific actions ... else ... worker specific actions ... fi
	InitializationActions []NodeInitializationAction `pulumi:"initializationActions"`
	// Optional. The config setting for auto delete cluster schedule.
	LifecycleConfig *LifecycleConfig `pulumi:"lifecycleConfig"`
	// Optional. The Compute Engine config settings for the master instance in a cluster.
	MasterConfig *InstanceGroupConfig `pulumi:"masterConfig"`
	// Optional. Metastore configuration.
	MetastoreConfig *MetastoreConfig `pulumi:"metastoreConfig"`
	// Optional. The Compute Engine config settings for additional worker instances in a cluster.
	SecondaryWorkerConfig *InstanceGroupConfig `pulumi:"secondaryWorkerConfig"`
	// Optional. Security related configuration.
	SecurityConfig *SecurityConfig `pulumi:"securityConfig"`
	// Optional. The config settings for software inside the cluster.
	SoftwareConfig *SoftwareConfig `pulumi:"softwareConfig"`
	// Optional. A Cloud Storage bucket used to store ephemeral cluster and jobs data, such as Spark and MapReduce history files. If you do not specify a temp bucket, Dataproc will determine a Cloud Storage location (US, ASIA, or EU) for your cluster's temp bucket according to the Compute Engine zone where your cluster is deployed, and then create and manage this project-level, per-location bucket. The default bucket has a TTL of 90 days, but you can use any TTL (or none) if you specify a bucket. This field requires a Cloud Storage bucket name, not a URI to a Cloud Storage bucket.
	TempBucket *string `pulumi:"tempBucket"`
	// Optional. The Compute Engine config settings for worker instances in a cluster.
	WorkerConfig *InstanceGroupConfig `pulumi:"workerConfig"`
}

// ClusterConfigInput is an input type that accepts ClusterConfigArgs and ClusterConfigOutput values.
// You can construct a concrete instance of `ClusterConfigInput` via:
//
//          ClusterConfigArgs{...}
type ClusterConfigInput interface {
	pulumi.Input

	ToClusterConfigOutput() ClusterConfigOutput
	ToClusterConfigOutputWithContext(context.Context) ClusterConfigOutput
}

// The cluster config.
type ClusterConfigArgs struct {
	// Optional. Autoscaling config for the policy associated with the cluster. Cluster does not autoscale if this field is unset.
	AutoscalingConfig AutoscalingConfigPtrInput `pulumi:"autoscalingConfig"`
	// Optional. A Cloud Storage bucket used to stage job dependencies, config files, and job driver console output. If you do not specify a staging bucket, Cloud Dataproc will determine a Cloud Storage location (US, ASIA, or EU) for your cluster's staging bucket according to the Compute Engine zone where your cluster is deployed, and then create and manage this project-level, per-location bucket (see Dataproc staging bucket (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)). This field requires a Cloud Storage bucket name, not a URI to a Cloud Storage bucket.
	ConfigBucket pulumi.StringPtrInput `pulumi:"configBucket"`
	// Optional. Encryption settings for the cluster.
	EncryptionConfig EncryptionConfigPtrInput `pulumi:"encryptionConfig"`
	// Optional. Port/endpoint configuration for this cluster
	EndpointConfig EndpointConfigPtrInput `pulumi:"endpointConfig"`
	// Optional. The shared Compute Engine config settings for all instances in a cluster.
	GceClusterConfig GceClusterConfigPtrInput `pulumi:"gceClusterConfig"`
	// Optional. The Kubernetes Engine config for Dataproc clusters deployed to Kubernetes. Setting this is considered mutually exclusive with Compute Engine-based options such as gce_cluster_config, master_config, worker_config, secondary_worker_config, and autoscaling_config.
	GkeClusterConfig GkeClusterConfigPtrInput `pulumi:"gkeClusterConfig"`
	// Optional. Commands to execute on each node after config is completed. By default, executables are run on master and all worker nodes. You can test a node's role metadata to run an executable on a master or worker node, as shown below using curl (you can also use wget): ROLE=$(curl -H Metadata-Flavor:Google http://metadata/computeMetadata/v1beta2/instance/attributes/dataproc-role) if [[ "${ROLE}" == 'Master' ]]; then ... master specific actions ... else ... worker specific actions ... fi
	InitializationActions NodeInitializationActionArrayInput `pulumi:"initializationActions"`
	// Optional. The config setting for auto delete cluster schedule.
	LifecycleConfig LifecycleConfigPtrInput `pulumi:"lifecycleConfig"`
	// Optional. The Compute Engine config settings for the master instance in a cluster.
	MasterConfig InstanceGroupConfigPtrInput `pulumi:"masterConfig"`
	// Optional. Metastore configuration.
	MetastoreConfig MetastoreConfigPtrInput `pulumi:"metastoreConfig"`
	// Optional. The Compute Engine config settings for additional worker instances in a cluster.
	SecondaryWorkerConfig InstanceGroupConfigPtrInput `pulumi:"secondaryWorkerConfig"`
	// Optional. Security related configuration.
	SecurityConfig SecurityConfigPtrInput `pulumi:"securityConfig"`
	// Optional. The config settings for software inside the cluster.
	SoftwareConfig SoftwareConfigPtrInput `pulumi:"softwareConfig"`
	// Optional. A Cloud Storage bucket used to store ephemeral cluster and jobs data, such as Spark and MapReduce history files. If you do not specify a temp bucket, Dataproc will determine a Cloud Storage location (US, ASIA, or EU) for your cluster's temp bucket according to the Compute Engine zone where your cluster is deployed, and then create and manage this project-level, per-location bucket. The default bucket has a TTL of 90 days, but you can use any TTL (or none) if you specify a bucket. This field requires a Cloud Storage bucket name, not a URI to a Cloud Storage bucket.
	TempBucket pulumi.StringPtrInput `pulumi:"tempBucket"`
	// Optional. The Compute Engine config settings for worker instances in a cluster.
	WorkerConfig InstanceGroupConfigPtrInput `pulumi:"workerConfig"`
}

func (ClusterConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterConfig)(nil)).Elem()
}

func (i ClusterConfigArgs) ToClusterConfigOutput() ClusterConfigOutput {
	return i.ToClusterConfigOutputWithContext(context.Background())
}

func (i ClusterConfigArgs) ToClusterConfigOutputWithContext(ctx context.Context) ClusterConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterConfigOutput)
}

func (i ClusterConfigArgs) ToClusterConfigPtrOutput() ClusterConfigPtrOutput {
	return i.ToClusterConfigPtrOutputWithContext(context.Background())
}

func (i ClusterConfigArgs) ToClusterConfigPtrOutputWithContext(ctx context.Context) ClusterConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterConfigOutput).ToClusterConfigPtrOutputWithContext(ctx)
}

// ClusterConfigPtrInput is an input type that accepts ClusterConfigArgs, ClusterConfigPtr and ClusterConfigPtrOutput values.
// You can construct a concrete instance of `ClusterConfigPtrInput` via:
//
//          ClusterConfigArgs{...}
//
//  or:
//
//          nil
type ClusterConfigPtrInput interface {
	pulumi.Input

	ToClusterConfigPtrOutput() ClusterConfigPtrOutput
	ToClusterConfigPtrOutputWithContext(context.Context) ClusterConfigPtrOutput
}

type clusterConfigPtrType ClusterConfigArgs

func ClusterConfigPtr(v *ClusterConfigArgs) ClusterConfigPtrInput {
	return (*clusterConfigPtrType)(v)
}

func (*clusterConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterConfig)(nil)).Elem()
}

func (i *clusterConfigPtrType) ToClusterConfigPtrOutput() ClusterConfigPtrOutput {
	return i.ToClusterConfigPtrOutputWithContext(context.Background())
}

func (i *clusterConfigPtrType) ToClusterConfigPtrOutputWithContext(ctx context.Context) ClusterConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterConfigPtrOutput)
}

// The cluster config.
type ClusterConfigOutput struct{ *pulumi.OutputState }

func (ClusterConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterConfig)(nil)).Elem()
}

func (o ClusterConfigOutput) ToClusterConfigOutput() ClusterConfigOutput {
	return o
}

func (o ClusterConfigOutput) ToClusterConfigOutputWithContext(ctx context.Context) ClusterConfigOutput {
	return o
}

func (o ClusterConfigOutput) ToClusterConfigPtrOutput() ClusterConfigPtrOutput {
	return o.ToClusterConfigPtrOutputWithContext(context.Background())
}

func (o ClusterConfigOutput) ToClusterConfigPtrOutputWithContext(ctx context.Context) ClusterConfigPtrOutput {
	return o.ApplyT(func(v ClusterConfig) *ClusterConfig {
		return &v
	}).(ClusterConfigPtrOutput)
}

// Optional. Autoscaling config for the policy associated with the cluster. Cluster does not autoscale if this field is unset.
func (o ClusterConfigOutput) AutoscalingConfig() AutoscalingConfigPtrOutput {
	return o.ApplyT(func(v ClusterConfig) *AutoscalingConfig { return v.AutoscalingConfig }).(AutoscalingConfigPtrOutput)
}

// Optional. A Cloud Storage bucket used to stage job dependencies, config files, and job driver console output. If you do not specify a staging bucket, Cloud Dataproc will determine a Cloud Storage location (US, ASIA, or EU) for your cluster's staging bucket according to the Compute Engine zone where your cluster is deployed, and then create and manage this project-level, per-location bucket (see Dataproc staging bucket (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)). This field requires a Cloud Storage bucket name, not a URI to a Cloud Storage bucket.
func (o ClusterConfigOutput) ConfigBucket() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterConfig) *string { return v.ConfigBucket }).(pulumi.StringPtrOutput)
}

// Optional. Encryption settings for the cluster.
func (o ClusterConfigOutput) EncryptionConfig() EncryptionConfigPtrOutput {
	return o.ApplyT(func(v ClusterConfig) *EncryptionConfig { return v.EncryptionConfig }).(EncryptionConfigPtrOutput)
}

// Optional. Port/endpoint configuration for this cluster
func (o ClusterConfigOutput) EndpointConfig() EndpointConfigPtrOutput {
	return o.ApplyT(func(v ClusterConfig) *EndpointConfig { return v.EndpointConfig }).(EndpointConfigPtrOutput)
}

// Optional. The shared Compute Engine config settings for all instances in a cluster.
func (o ClusterConfigOutput) GceClusterConfig() GceClusterConfigPtrOutput {
	return o.ApplyT(func(v ClusterConfig) *GceClusterConfig { return v.GceClusterConfig }).(GceClusterConfigPtrOutput)
}

// Optional. The Kubernetes Engine config for Dataproc clusters deployed to Kubernetes. Setting this is considered mutually exclusive with Compute Engine-based options such as gce_cluster_config, master_config, worker_config, secondary_worker_config, and autoscaling_config.
func (o ClusterConfigOutput) GkeClusterConfig() GkeClusterConfigPtrOutput {
	return o.ApplyT(func(v ClusterConfig) *GkeClusterConfig { return v.GkeClusterConfig }).(GkeClusterConfigPtrOutput)
}

// Optional. Commands to execute on each node after config is completed. By default, executables are run on master and all worker nodes. You can test a node's role metadata to run an executable on a master or worker node, as shown below using curl (you can also use wget): ROLE=$(curl -H Metadata-Flavor:Google http://metadata/computeMetadata/v1beta2/instance/attributes/dataproc-role) if [[ "${ROLE}" == 'Master' ]]; then ... master specific actions ... else ... worker specific actions ... fi
func (o ClusterConfigOutput) InitializationActions() NodeInitializationActionArrayOutput {
	return o.ApplyT(func(v ClusterConfig) []NodeInitializationAction { return v.InitializationActions }).(NodeInitializationActionArrayOutput)
}

// Optional. The config setting for auto delete cluster schedule.
func (o ClusterConfigOutput) LifecycleConfig() LifecycleConfigPtrOutput {
	return o.ApplyT(func(v ClusterConfig) *LifecycleConfig { return v.LifecycleConfig }).(LifecycleConfigPtrOutput)
}

// Optional. The Compute Engine config settings for the master instance in a cluster.
func (o ClusterConfigOutput) MasterConfig() InstanceGroupConfigPtrOutput {
	return o.ApplyT(func(v ClusterConfig) *InstanceGroupConfig { return v.MasterConfig }).(InstanceGroupConfigPtrOutput)
}

// Optional. Metastore configuration.
func (o ClusterConfigOutput) MetastoreConfig() MetastoreConfigPtrOutput {
	return o.ApplyT(func(v ClusterConfig) *MetastoreConfig { return v.MetastoreConfig }).(MetastoreConfigPtrOutput)
}

// Optional. The Compute Engine config settings for additional worker instances in a cluster.
func (o ClusterConfigOutput) SecondaryWorkerConfig() InstanceGroupConfigPtrOutput {
	return o.ApplyT(func(v ClusterConfig) *InstanceGroupConfig { return v.SecondaryWorkerConfig }).(InstanceGroupConfigPtrOutput)
}

// Optional. Security related configuration.
func (o ClusterConfigOutput) SecurityConfig() SecurityConfigPtrOutput {
	return o.ApplyT(func(v ClusterConfig) *SecurityConfig { return v.SecurityConfig }).(SecurityConfigPtrOutput)
}

// Optional. The config settings for software inside the cluster.
func (o ClusterConfigOutput) SoftwareConfig() SoftwareConfigPtrOutput {
	return o.ApplyT(func(v ClusterConfig) *SoftwareConfig { return v.SoftwareConfig }).(SoftwareConfigPtrOutput)
}

// Optional. A Cloud Storage bucket used to store ephemeral cluster and jobs data, such as Spark and MapReduce history files. If you do not specify a temp bucket, Dataproc will determine a Cloud Storage location (US, ASIA, or EU) for your cluster's temp bucket according to the Compute Engine zone where your cluster is deployed, and then create and manage this project-level, per-location bucket. The default bucket has a TTL of 90 days, but you can use any TTL (or none) if you specify a bucket. This field requires a Cloud Storage bucket name, not a URI to a Cloud Storage bucket.
func (o ClusterConfigOutput) TempBucket() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterConfig) *string { return v.TempBucket }).(pulumi.StringPtrOutput)
}

// Optional. The Compute Engine config settings for worker instances in a cluster.
func (o ClusterConfigOutput) WorkerConfig() InstanceGroupConfigPtrOutput {
	return o.ApplyT(func(v ClusterConfig) *InstanceGroupConfig { return v.WorkerConfig }).(InstanceGroupConfigPtrOutput)
}

type ClusterConfigPtrOutput struct{ *pulumi.OutputState }

func (ClusterConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterConfig)(nil)).Elem()
}

func (o ClusterConfigPtrOutput) ToClusterConfigPtrOutput() ClusterConfigPtrOutput {
	return o
}

func (o ClusterConfigPtrOutput) ToClusterConfigPtrOutputWithContext(ctx context.Context) ClusterConfigPtrOutput {
	return o
}

func (o ClusterConfigPtrOutput) Elem() ClusterConfigOutput {
	return o.ApplyT(func(v *ClusterConfig) ClusterConfig { return *v }).(ClusterConfigOutput)
}

// Optional. Autoscaling config for the policy associated with the cluster. Cluster does not autoscale if this field is unset.
func (o ClusterConfigPtrOutput) AutoscalingConfig() AutoscalingConfigPtrOutput {
	return o.ApplyT(func(v *ClusterConfig) *AutoscalingConfig {
		if v == nil {
			return nil
		}
		return v.AutoscalingConfig
	}).(AutoscalingConfigPtrOutput)
}

// Optional. A Cloud Storage bucket used to stage job dependencies, config files, and job driver console output. If you do not specify a staging bucket, Cloud Dataproc will determine a Cloud Storage location (US, ASIA, or EU) for your cluster's staging bucket according to the Compute Engine zone where your cluster is deployed, and then create and manage this project-level, per-location bucket (see Dataproc staging bucket (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)). This field requires a Cloud Storage bucket name, not a URI to a Cloud Storage bucket.
func (o ClusterConfigPtrOutput) ConfigBucket() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterConfig) *string {
		if v == nil {
			return nil
		}
		return v.ConfigBucket
	}).(pulumi.StringPtrOutput)
}

// Optional. Encryption settings for the cluster.
func (o ClusterConfigPtrOutput) EncryptionConfig() EncryptionConfigPtrOutput {
	return o.ApplyT(func(v *ClusterConfig) *EncryptionConfig {
		if v == nil {
			return nil
		}
		return v.EncryptionConfig
	}).(EncryptionConfigPtrOutput)
}

// Optional. Port/endpoint configuration for this cluster
func (o ClusterConfigPtrOutput) EndpointConfig() EndpointConfigPtrOutput {
	return o.ApplyT(func(v *ClusterConfig) *EndpointConfig {
		if v == nil {
			return nil
		}
		return v.EndpointConfig
	}).(EndpointConfigPtrOutput)
}

// Optional. The shared Compute Engine config settings for all instances in a cluster.
func (o ClusterConfigPtrOutput) GceClusterConfig() GceClusterConfigPtrOutput {
	return o.ApplyT(func(v *ClusterConfig) *GceClusterConfig {
		if v == nil {
			return nil
		}
		return v.GceClusterConfig
	}).(GceClusterConfigPtrOutput)
}

// Optional. The Kubernetes Engine config for Dataproc clusters deployed to Kubernetes. Setting this is considered mutually exclusive with Compute Engine-based options such as gce_cluster_config, master_config, worker_config, secondary_worker_config, and autoscaling_config.
func (o ClusterConfigPtrOutput) GkeClusterConfig() GkeClusterConfigPtrOutput {
	return o.ApplyT(func(v *ClusterConfig) *GkeClusterConfig {
		if v == nil {
			return nil
		}
		return v.GkeClusterConfig
	}).(GkeClusterConfigPtrOutput)
}

// Optional. Commands to execute on each node after config is completed. By default, executables are run on master and all worker nodes. You can test a node's role metadata to run an executable on a master or worker node, as shown below using curl (you can also use wget): ROLE=$(curl -H Metadata-Flavor:Google http://metadata/computeMetadata/v1beta2/instance/attributes/dataproc-role) if [[ "${ROLE}" == 'Master' ]]; then ... master specific actions ... else ... worker specific actions ... fi
func (o ClusterConfigPtrOutput) InitializationActions() NodeInitializationActionArrayOutput {
	return o.ApplyT(func(v *ClusterConfig) []NodeInitializationAction {
		if v == nil {
			return nil
		}
		return v.InitializationActions
	}).(NodeInitializationActionArrayOutput)
}

// Optional. The config setting for auto delete cluster schedule.
func (o ClusterConfigPtrOutput) LifecycleConfig() LifecycleConfigPtrOutput {
	return o.ApplyT(func(v *ClusterConfig) *LifecycleConfig {
		if v == nil {
			return nil
		}
		return v.LifecycleConfig
	}).(LifecycleConfigPtrOutput)
}

// Optional. The Compute Engine config settings for the master instance in a cluster.
func (o ClusterConfigPtrOutput) MasterConfig() InstanceGroupConfigPtrOutput {
	return o.ApplyT(func(v *ClusterConfig) *InstanceGroupConfig {
		if v == nil {
			return nil
		}
		return v.MasterConfig
	}).(InstanceGroupConfigPtrOutput)
}

// Optional. Metastore configuration.
func (o ClusterConfigPtrOutput) MetastoreConfig() MetastoreConfigPtrOutput {
	return o.ApplyT(func(v *ClusterConfig) *MetastoreConfig {
		if v == nil {
			return nil
		}
		return v.MetastoreConfig
	}).(MetastoreConfigPtrOutput)
}

// Optional. The Compute Engine config settings for additional worker instances in a cluster.
func (o ClusterConfigPtrOutput) SecondaryWorkerConfig() InstanceGroupConfigPtrOutput {
	return o.ApplyT(func(v *ClusterConfig) *InstanceGroupConfig {
		if v == nil {
			return nil
		}
		return v.SecondaryWorkerConfig
	}).(InstanceGroupConfigPtrOutput)
}

// Optional. Security related configuration.
func (o ClusterConfigPtrOutput) SecurityConfig() SecurityConfigPtrOutput {
	return o.ApplyT(func(v *ClusterConfig) *SecurityConfig {
		if v == nil {
			return nil
		}
		return v.SecurityConfig
	}).(SecurityConfigPtrOutput)
}

// Optional. The config settings for software inside the cluster.
func (o ClusterConfigPtrOutput) SoftwareConfig() SoftwareConfigPtrOutput {
	return o.ApplyT(func(v *ClusterConfig) *SoftwareConfig {
		if v == nil {
			return nil
		}
		return v.SoftwareConfig
	}).(SoftwareConfigPtrOutput)
}

// Optional. A Cloud Storage bucket used to store ephemeral cluster and jobs data, such as Spark and MapReduce history files. If you do not specify a temp bucket, Dataproc will determine a Cloud Storage location (US, ASIA, or EU) for your cluster's temp bucket according to the Compute Engine zone where your cluster is deployed, and then create and manage this project-level, per-location bucket. The default bucket has a TTL of 90 days, but you can use any TTL (or none) if you specify a bucket. This field requires a Cloud Storage bucket name, not a URI to a Cloud Storage bucket.
func (o ClusterConfigPtrOutput) TempBucket() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterConfig) *string {
		if v == nil {
			return nil
		}
		return v.TempBucket
	}).(pulumi.StringPtrOutput)
}

// Optional. The Compute Engine config settings for worker instances in a cluster.
func (o ClusterConfigPtrOutput) WorkerConfig() InstanceGroupConfigPtrOutput {
	return o.ApplyT(func(v *ClusterConfig) *InstanceGroupConfig {
		if v == nil {
			return nil
		}
		return v.WorkerConfig
	}).(InstanceGroupConfigPtrOutput)
}

// Contains cluster daemon metrics, such as HDFS and YARN stats.Beta Feature: This report is available for testing purposes only. It may be changed before final release.
type ClusterMetrics struct {
	// The HDFS metrics.
	HdfsMetrics map[string]string `pulumi:"hdfsMetrics"`
	// The YARN metrics.
	YarnMetrics map[string]string `pulumi:"yarnMetrics"`
}

// ClusterMetricsInput is an input type that accepts ClusterMetricsArgs and ClusterMetricsOutput values.
// You can construct a concrete instance of `ClusterMetricsInput` via:
//
//          ClusterMetricsArgs{...}
type ClusterMetricsInput interface {
	pulumi.Input

	ToClusterMetricsOutput() ClusterMetricsOutput
	ToClusterMetricsOutputWithContext(context.Context) ClusterMetricsOutput
}

// Contains cluster daemon metrics, such as HDFS and YARN stats.Beta Feature: This report is available for testing purposes only. It may be changed before final release.
type ClusterMetricsArgs struct {
	// The HDFS metrics.
	HdfsMetrics pulumi.StringMapInput `pulumi:"hdfsMetrics"`
	// The YARN metrics.
	YarnMetrics pulumi.StringMapInput `pulumi:"yarnMetrics"`
}

func (ClusterMetricsArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterMetrics)(nil)).Elem()
}

func (i ClusterMetricsArgs) ToClusterMetricsOutput() ClusterMetricsOutput {
	return i.ToClusterMetricsOutputWithContext(context.Background())
}

func (i ClusterMetricsArgs) ToClusterMetricsOutputWithContext(ctx context.Context) ClusterMetricsOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterMetricsOutput)
}

func (i ClusterMetricsArgs) ToClusterMetricsPtrOutput() ClusterMetricsPtrOutput {
	return i.ToClusterMetricsPtrOutputWithContext(context.Background())
}

func (i ClusterMetricsArgs) ToClusterMetricsPtrOutputWithContext(ctx context.Context) ClusterMetricsPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterMetricsOutput).ToClusterMetricsPtrOutputWithContext(ctx)
}

// ClusterMetricsPtrInput is an input type that accepts ClusterMetricsArgs, ClusterMetricsPtr and ClusterMetricsPtrOutput values.
// You can construct a concrete instance of `ClusterMetricsPtrInput` via:
//
//          ClusterMetricsArgs{...}
//
//  or:
//
//          nil
type ClusterMetricsPtrInput interface {
	pulumi.Input

	ToClusterMetricsPtrOutput() ClusterMetricsPtrOutput
	ToClusterMetricsPtrOutputWithContext(context.Context) ClusterMetricsPtrOutput
}

type clusterMetricsPtrType ClusterMetricsArgs

func ClusterMetricsPtr(v *ClusterMetricsArgs) ClusterMetricsPtrInput {
	return (*clusterMetricsPtrType)(v)
}

func (*clusterMetricsPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterMetrics)(nil)).Elem()
}

func (i *clusterMetricsPtrType) ToClusterMetricsPtrOutput() ClusterMetricsPtrOutput {
	return i.ToClusterMetricsPtrOutputWithContext(context.Background())
}

func (i *clusterMetricsPtrType) ToClusterMetricsPtrOutputWithContext(ctx context.Context) ClusterMetricsPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterMetricsPtrOutput)
}

// Contains cluster daemon metrics, such as HDFS and YARN stats.Beta Feature: This report is available for testing purposes only. It may be changed before final release.
type ClusterMetricsOutput struct{ *pulumi.OutputState }

func (ClusterMetricsOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterMetrics)(nil)).Elem()
}

func (o ClusterMetricsOutput) ToClusterMetricsOutput() ClusterMetricsOutput {
	return o
}

func (o ClusterMetricsOutput) ToClusterMetricsOutputWithContext(ctx context.Context) ClusterMetricsOutput {
	return o
}

func (o ClusterMetricsOutput) ToClusterMetricsPtrOutput() ClusterMetricsPtrOutput {
	return o.ToClusterMetricsPtrOutputWithContext(context.Background())
}

func (o ClusterMetricsOutput) ToClusterMetricsPtrOutputWithContext(ctx context.Context) ClusterMetricsPtrOutput {
	return o.ApplyT(func(v ClusterMetrics) *ClusterMetrics {
		return &v
	}).(ClusterMetricsPtrOutput)
}

// The HDFS metrics.
func (o ClusterMetricsOutput) HdfsMetrics() pulumi.StringMapOutput {
	return o.ApplyT(func(v ClusterMetrics) map[string]string { return v.HdfsMetrics }).(pulumi.StringMapOutput)
}

// The YARN metrics.
func (o ClusterMetricsOutput) YarnMetrics() pulumi.StringMapOutput {
	return o.ApplyT(func(v ClusterMetrics) map[string]string { return v.YarnMetrics }).(pulumi.StringMapOutput)
}

type ClusterMetricsPtrOutput struct{ *pulumi.OutputState }

func (ClusterMetricsPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterMetrics)(nil)).Elem()
}

func (o ClusterMetricsPtrOutput) ToClusterMetricsPtrOutput() ClusterMetricsPtrOutput {
	return o
}

func (o ClusterMetricsPtrOutput) ToClusterMetricsPtrOutputWithContext(ctx context.Context) ClusterMetricsPtrOutput {
	return o
}

func (o ClusterMetricsPtrOutput) Elem() ClusterMetricsOutput {
	return o.ApplyT(func(v *ClusterMetrics) ClusterMetrics { return *v }).(ClusterMetricsOutput)
}

// The HDFS metrics.
func (o ClusterMetricsPtrOutput) HdfsMetrics() pulumi.StringMapOutput {
	return o.ApplyT(func(v *ClusterMetrics) map[string]string {
		if v == nil {
			return nil
		}
		return v.HdfsMetrics
	}).(pulumi.StringMapOutput)
}

// The YARN metrics.
func (o ClusterMetricsPtrOutput) YarnMetrics() pulumi.StringMapOutput {
	return o.ApplyT(func(v *ClusterMetrics) map[string]string {
		if v == nil {
			return nil
		}
		return v.YarnMetrics
	}).(pulumi.StringMapOutput)
}

// A selector that chooses target cluster for jobs based on metadata.
type ClusterSelector struct {
	// Required. The cluster labels. Cluster must have all labels to match.
	ClusterLabels map[string]string `pulumi:"clusterLabels"`
	// Optional. The zone where workflow process executes. This parameter does not affect the selection of the cluster.If unspecified, the zone of the first cluster matching the selector is used.
	Zone *string `pulumi:"zone"`
}

// ClusterSelectorInput is an input type that accepts ClusterSelectorArgs and ClusterSelectorOutput values.
// You can construct a concrete instance of `ClusterSelectorInput` via:
//
//          ClusterSelectorArgs{...}
type ClusterSelectorInput interface {
	pulumi.Input

	ToClusterSelectorOutput() ClusterSelectorOutput
	ToClusterSelectorOutputWithContext(context.Context) ClusterSelectorOutput
}

// A selector that chooses target cluster for jobs based on metadata.
type ClusterSelectorArgs struct {
	// Required. The cluster labels. Cluster must have all labels to match.
	ClusterLabels pulumi.StringMapInput `pulumi:"clusterLabels"`
	// Optional. The zone where workflow process executes. This parameter does not affect the selection of the cluster.If unspecified, the zone of the first cluster matching the selector is used.
	Zone pulumi.StringPtrInput `pulumi:"zone"`
}

func (ClusterSelectorArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterSelector)(nil)).Elem()
}

func (i ClusterSelectorArgs) ToClusterSelectorOutput() ClusterSelectorOutput {
	return i.ToClusterSelectorOutputWithContext(context.Background())
}

func (i ClusterSelectorArgs) ToClusterSelectorOutputWithContext(ctx context.Context) ClusterSelectorOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterSelectorOutput)
}

func (i ClusterSelectorArgs) ToClusterSelectorPtrOutput() ClusterSelectorPtrOutput {
	return i.ToClusterSelectorPtrOutputWithContext(context.Background())
}

func (i ClusterSelectorArgs) ToClusterSelectorPtrOutputWithContext(ctx context.Context) ClusterSelectorPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterSelectorOutput).ToClusterSelectorPtrOutputWithContext(ctx)
}

// ClusterSelectorPtrInput is an input type that accepts ClusterSelectorArgs, ClusterSelectorPtr and ClusterSelectorPtrOutput values.
// You can construct a concrete instance of `ClusterSelectorPtrInput` via:
//
//          ClusterSelectorArgs{...}
//
//  or:
//
//          nil
type ClusterSelectorPtrInput interface {
	pulumi.Input

	ToClusterSelectorPtrOutput() ClusterSelectorPtrOutput
	ToClusterSelectorPtrOutputWithContext(context.Context) ClusterSelectorPtrOutput
}

type clusterSelectorPtrType ClusterSelectorArgs

func ClusterSelectorPtr(v *ClusterSelectorArgs) ClusterSelectorPtrInput {
	return (*clusterSelectorPtrType)(v)
}

func (*clusterSelectorPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterSelector)(nil)).Elem()
}

func (i *clusterSelectorPtrType) ToClusterSelectorPtrOutput() ClusterSelectorPtrOutput {
	return i.ToClusterSelectorPtrOutputWithContext(context.Background())
}

func (i *clusterSelectorPtrType) ToClusterSelectorPtrOutputWithContext(ctx context.Context) ClusterSelectorPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterSelectorPtrOutput)
}

// A selector that chooses target cluster for jobs based on metadata.
type ClusterSelectorOutput struct{ *pulumi.OutputState }

func (ClusterSelectorOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterSelector)(nil)).Elem()
}

func (o ClusterSelectorOutput) ToClusterSelectorOutput() ClusterSelectorOutput {
	return o
}

func (o ClusterSelectorOutput) ToClusterSelectorOutputWithContext(ctx context.Context) ClusterSelectorOutput {
	return o
}

func (o ClusterSelectorOutput) ToClusterSelectorPtrOutput() ClusterSelectorPtrOutput {
	return o.ToClusterSelectorPtrOutputWithContext(context.Background())
}

func (o ClusterSelectorOutput) ToClusterSelectorPtrOutputWithContext(ctx context.Context) ClusterSelectorPtrOutput {
	return o.ApplyT(func(v ClusterSelector) *ClusterSelector {
		return &v
	}).(ClusterSelectorPtrOutput)
}

// Required. The cluster labels. Cluster must have all labels to match.
func (o ClusterSelectorOutput) ClusterLabels() pulumi.StringMapOutput {
	return o.ApplyT(func(v ClusterSelector) map[string]string { return v.ClusterLabels }).(pulumi.StringMapOutput)
}

// Optional. The zone where workflow process executes. This parameter does not affect the selection of the cluster.If unspecified, the zone of the first cluster matching the selector is used.
func (o ClusterSelectorOutput) Zone() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterSelector) *string { return v.Zone }).(pulumi.StringPtrOutput)
}

type ClusterSelectorPtrOutput struct{ *pulumi.OutputState }

func (ClusterSelectorPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterSelector)(nil)).Elem()
}

func (o ClusterSelectorPtrOutput) ToClusterSelectorPtrOutput() ClusterSelectorPtrOutput {
	return o
}

func (o ClusterSelectorPtrOutput) ToClusterSelectorPtrOutputWithContext(ctx context.Context) ClusterSelectorPtrOutput {
	return o
}

func (o ClusterSelectorPtrOutput) Elem() ClusterSelectorOutput {
	return o.ApplyT(func(v *ClusterSelector) ClusterSelector { return *v }).(ClusterSelectorOutput)
}

// Required. The cluster labels. Cluster must have all labels to match.
func (o ClusterSelectorPtrOutput) ClusterLabels() pulumi.StringMapOutput {
	return o.ApplyT(func(v *ClusterSelector) map[string]string {
		if v == nil {
			return nil
		}
		return v.ClusterLabels
	}).(pulumi.StringMapOutput)
}

// Optional. The zone where workflow process executes. This parameter does not affect the selection of the cluster.If unspecified, the zone of the first cluster matching the selector is used.
func (o ClusterSelectorPtrOutput) Zone() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterSelector) *string {
		if v == nil {
			return nil
		}
		return v.Zone
	}).(pulumi.StringPtrOutput)
}

// The status of a cluster and its instances.
type ClusterStatus struct {
	// Output only. Optional details of cluster's state.
	Detail *string `pulumi:"detail"`
	// Output only. The cluster's state.
	State *string `pulumi:"state"`
	// Output only. Time when this state was entered (see JSON representation of Timestamp (https://developers.google.com/protocol-buffers/docs/proto3#json)).
	StateStartTime *string `pulumi:"stateStartTime"`
	// Output only. Additional state information that includes status reported by the agent.
	Substate *string `pulumi:"substate"`
}

// ClusterStatusInput is an input type that accepts ClusterStatusArgs and ClusterStatusOutput values.
// You can construct a concrete instance of `ClusterStatusInput` via:
//
//          ClusterStatusArgs{...}
type ClusterStatusInput interface {
	pulumi.Input

	ToClusterStatusOutput() ClusterStatusOutput
	ToClusterStatusOutputWithContext(context.Context) ClusterStatusOutput
}

// The status of a cluster and its instances.
type ClusterStatusArgs struct {
	// Output only. Optional details of cluster's state.
	Detail pulumi.StringPtrInput `pulumi:"detail"`
	// Output only. The cluster's state.
	State pulumi.StringPtrInput `pulumi:"state"`
	// Output only. Time when this state was entered (see JSON representation of Timestamp (https://developers.google.com/protocol-buffers/docs/proto3#json)).
	StateStartTime pulumi.StringPtrInput `pulumi:"stateStartTime"`
	// Output only. Additional state information that includes status reported by the agent.
	Substate pulumi.StringPtrInput `pulumi:"substate"`
}

func (ClusterStatusArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterStatus)(nil)).Elem()
}

func (i ClusterStatusArgs) ToClusterStatusOutput() ClusterStatusOutput {
	return i.ToClusterStatusOutputWithContext(context.Background())
}

func (i ClusterStatusArgs) ToClusterStatusOutputWithContext(ctx context.Context) ClusterStatusOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterStatusOutput)
}

func (i ClusterStatusArgs) ToClusterStatusPtrOutput() ClusterStatusPtrOutput {
	return i.ToClusterStatusPtrOutputWithContext(context.Background())
}

func (i ClusterStatusArgs) ToClusterStatusPtrOutputWithContext(ctx context.Context) ClusterStatusPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterStatusOutput).ToClusterStatusPtrOutputWithContext(ctx)
}

// ClusterStatusPtrInput is an input type that accepts ClusterStatusArgs, ClusterStatusPtr and ClusterStatusPtrOutput values.
// You can construct a concrete instance of `ClusterStatusPtrInput` via:
//
//          ClusterStatusArgs{...}
//
//  or:
//
//          nil
type ClusterStatusPtrInput interface {
	pulumi.Input

	ToClusterStatusPtrOutput() ClusterStatusPtrOutput
	ToClusterStatusPtrOutputWithContext(context.Context) ClusterStatusPtrOutput
}

type clusterStatusPtrType ClusterStatusArgs

func ClusterStatusPtr(v *ClusterStatusArgs) ClusterStatusPtrInput {
	return (*clusterStatusPtrType)(v)
}

func (*clusterStatusPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterStatus)(nil)).Elem()
}

func (i *clusterStatusPtrType) ToClusterStatusPtrOutput() ClusterStatusPtrOutput {
	return i.ToClusterStatusPtrOutputWithContext(context.Background())
}

func (i *clusterStatusPtrType) ToClusterStatusPtrOutputWithContext(ctx context.Context) ClusterStatusPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterStatusPtrOutput)
}

// ClusterStatusArrayInput is an input type that accepts ClusterStatusArray and ClusterStatusArrayOutput values.
// You can construct a concrete instance of `ClusterStatusArrayInput` via:
//
//          ClusterStatusArray{ ClusterStatusArgs{...} }
type ClusterStatusArrayInput interface {
	pulumi.Input

	ToClusterStatusArrayOutput() ClusterStatusArrayOutput
	ToClusterStatusArrayOutputWithContext(context.Context) ClusterStatusArrayOutput
}

type ClusterStatusArray []ClusterStatusInput

func (ClusterStatusArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]ClusterStatus)(nil)).Elem()
}

func (i ClusterStatusArray) ToClusterStatusArrayOutput() ClusterStatusArrayOutput {
	return i.ToClusterStatusArrayOutputWithContext(context.Background())
}

func (i ClusterStatusArray) ToClusterStatusArrayOutputWithContext(ctx context.Context) ClusterStatusArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ClusterStatusArrayOutput)
}

// The status of a cluster and its instances.
type ClusterStatusOutput struct{ *pulumi.OutputState }

func (ClusterStatusOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ClusterStatus)(nil)).Elem()
}

func (o ClusterStatusOutput) ToClusterStatusOutput() ClusterStatusOutput {
	return o
}

func (o ClusterStatusOutput) ToClusterStatusOutputWithContext(ctx context.Context) ClusterStatusOutput {
	return o
}

func (o ClusterStatusOutput) ToClusterStatusPtrOutput() ClusterStatusPtrOutput {
	return o.ToClusterStatusPtrOutputWithContext(context.Background())
}

func (o ClusterStatusOutput) ToClusterStatusPtrOutputWithContext(ctx context.Context) ClusterStatusPtrOutput {
	return o.ApplyT(func(v ClusterStatus) *ClusterStatus {
		return &v
	}).(ClusterStatusPtrOutput)
}

// Output only. Optional details of cluster's state.
func (o ClusterStatusOutput) Detail() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterStatus) *string { return v.Detail }).(pulumi.StringPtrOutput)
}

// Output only. The cluster's state.
func (o ClusterStatusOutput) State() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterStatus) *string { return v.State }).(pulumi.StringPtrOutput)
}

// Output only. Time when this state was entered (see JSON representation of Timestamp (https://developers.google.com/protocol-buffers/docs/proto3#json)).
func (o ClusterStatusOutput) StateStartTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterStatus) *string { return v.StateStartTime }).(pulumi.StringPtrOutput)
}

// Output only. Additional state information that includes status reported by the agent.
func (o ClusterStatusOutput) Substate() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ClusterStatus) *string { return v.Substate }).(pulumi.StringPtrOutput)
}

type ClusterStatusPtrOutput struct{ *pulumi.OutputState }

func (ClusterStatusPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ClusterStatus)(nil)).Elem()
}

func (o ClusterStatusPtrOutput) ToClusterStatusPtrOutput() ClusterStatusPtrOutput {
	return o
}

func (o ClusterStatusPtrOutput) ToClusterStatusPtrOutputWithContext(ctx context.Context) ClusterStatusPtrOutput {
	return o
}

func (o ClusterStatusPtrOutput) Elem() ClusterStatusOutput {
	return o.ApplyT(func(v *ClusterStatus) ClusterStatus { return *v }).(ClusterStatusOutput)
}

// Output only. Optional details of cluster's state.
func (o ClusterStatusPtrOutput) Detail() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterStatus) *string {
		if v == nil {
			return nil
		}
		return v.Detail
	}).(pulumi.StringPtrOutput)
}

// Output only. The cluster's state.
func (o ClusterStatusPtrOutput) State() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterStatus) *string {
		if v == nil {
			return nil
		}
		return v.State
	}).(pulumi.StringPtrOutput)
}

// Output only. Time when this state was entered (see JSON representation of Timestamp (https://developers.google.com/protocol-buffers/docs/proto3#json)).
func (o ClusterStatusPtrOutput) StateStartTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterStatus) *string {
		if v == nil {
			return nil
		}
		return v.StateStartTime
	}).(pulumi.StringPtrOutput)
}

// Output only. Additional state information that includes status reported by the agent.
func (o ClusterStatusPtrOutput) Substate() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ClusterStatus) *string {
		if v == nil {
			return nil
		}
		return v.Substate
	}).(pulumi.StringPtrOutput)
}

type ClusterStatusArrayOutput struct{ *pulumi.OutputState }

func (ClusterStatusArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]ClusterStatus)(nil)).Elem()
}

func (o ClusterStatusArrayOutput) ToClusterStatusArrayOutput() ClusterStatusArrayOutput {
	return o
}

func (o ClusterStatusArrayOutput) ToClusterStatusArrayOutputWithContext(ctx context.Context) ClusterStatusArrayOutput {
	return o
}

func (o ClusterStatusArrayOutput) Index(i pulumi.IntInput) ClusterStatusOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) ClusterStatus {
		return vs[0].([]ClusterStatus)[vs[1].(int)]
	}).(ClusterStatusOutput)
}

// Specifies the config of disk options for a group of VM instances.
type DiskConfig struct {
	// Optional. Size in GB of the boot disk (default is 500GB).
	BootDiskSizeGb *int `pulumi:"bootDiskSizeGb"`
	// Optional. Type of the boot disk (default is "pd-standard"). Valid values: "pd-balanced" (Persistent Disk Balanced Solid State Drive), "pd-ssd" (Persistent Disk Solid State Drive), or "pd-standard" (Persistent Disk Hard Disk Drive). See Disk types (https://cloud.google.com/compute/docs/disks#disk-types).
	BootDiskType *string `pulumi:"bootDiskType"`
	// Number of attached SSDs, from 0 to 4 (default is 0). If SSDs are not attached, the boot disk is used to store runtime logs and HDFS (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html) data. If one or more SSDs are attached, this runtime bulk data is spread across them, and the boot disk contains only basic config and installed binaries.
	NumLocalSsds *int `pulumi:"numLocalSsds"`
}

// DiskConfigInput is an input type that accepts DiskConfigArgs and DiskConfigOutput values.
// You can construct a concrete instance of `DiskConfigInput` via:
//
//          DiskConfigArgs{...}
type DiskConfigInput interface {
	pulumi.Input

	ToDiskConfigOutput() DiskConfigOutput
	ToDiskConfigOutputWithContext(context.Context) DiskConfigOutput
}

// Specifies the config of disk options for a group of VM instances.
type DiskConfigArgs struct {
	// Optional. Size in GB of the boot disk (default is 500GB).
	BootDiskSizeGb pulumi.IntPtrInput `pulumi:"bootDiskSizeGb"`
	// Optional. Type of the boot disk (default is "pd-standard"). Valid values: "pd-balanced" (Persistent Disk Balanced Solid State Drive), "pd-ssd" (Persistent Disk Solid State Drive), or "pd-standard" (Persistent Disk Hard Disk Drive). See Disk types (https://cloud.google.com/compute/docs/disks#disk-types).
	BootDiskType pulumi.StringPtrInput `pulumi:"bootDiskType"`
	// Number of attached SSDs, from 0 to 4 (default is 0). If SSDs are not attached, the boot disk is used to store runtime logs and HDFS (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html) data. If one or more SSDs are attached, this runtime bulk data is spread across them, and the boot disk contains only basic config and installed binaries.
	NumLocalSsds pulumi.IntPtrInput `pulumi:"numLocalSsds"`
}

func (DiskConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*DiskConfig)(nil)).Elem()
}

func (i DiskConfigArgs) ToDiskConfigOutput() DiskConfigOutput {
	return i.ToDiskConfigOutputWithContext(context.Background())
}

func (i DiskConfigArgs) ToDiskConfigOutputWithContext(ctx context.Context) DiskConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DiskConfigOutput)
}

func (i DiskConfigArgs) ToDiskConfigPtrOutput() DiskConfigPtrOutput {
	return i.ToDiskConfigPtrOutputWithContext(context.Background())
}

func (i DiskConfigArgs) ToDiskConfigPtrOutputWithContext(ctx context.Context) DiskConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DiskConfigOutput).ToDiskConfigPtrOutputWithContext(ctx)
}

// DiskConfigPtrInput is an input type that accepts DiskConfigArgs, DiskConfigPtr and DiskConfigPtrOutput values.
// You can construct a concrete instance of `DiskConfigPtrInput` via:
//
//          DiskConfigArgs{...}
//
//  or:
//
//          nil
type DiskConfigPtrInput interface {
	pulumi.Input

	ToDiskConfigPtrOutput() DiskConfigPtrOutput
	ToDiskConfigPtrOutputWithContext(context.Context) DiskConfigPtrOutput
}

type diskConfigPtrType DiskConfigArgs

func DiskConfigPtr(v *DiskConfigArgs) DiskConfigPtrInput {
	return (*diskConfigPtrType)(v)
}

func (*diskConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**DiskConfig)(nil)).Elem()
}

func (i *diskConfigPtrType) ToDiskConfigPtrOutput() DiskConfigPtrOutput {
	return i.ToDiskConfigPtrOutputWithContext(context.Background())
}

func (i *diskConfigPtrType) ToDiskConfigPtrOutputWithContext(ctx context.Context) DiskConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DiskConfigPtrOutput)
}

// Specifies the config of disk options for a group of VM instances.
type DiskConfigOutput struct{ *pulumi.OutputState }

func (DiskConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*DiskConfig)(nil)).Elem()
}

func (o DiskConfigOutput) ToDiskConfigOutput() DiskConfigOutput {
	return o
}

func (o DiskConfigOutput) ToDiskConfigOutputWithContext(ctx context.Context) DiskConfigOutput {
	return o
}

func (o DiskConfigOutput) ToDiskConfigPtrOutput() DiskConfigPtrOutput {
	return o.ToDiskConfigPtrOutputWithContext(context.Background())
}

func (o DiskConfigOutput) ToDiskConfigPtrOutputWithContext(ctx context.Context) DiskConfigPtrOutput {
	return o.ApplyT(func(v DiskConfig) *DiskConfig {
		return &v
	}).(DiskConfigPtrOutput)
}

// Optional. Size in GB of the boot disk (default is 500GB).
func (o DiskConfigOutput) BootDiskSizeGb() pulumi.IntPtrOutput {
	return o.ApplyT(func(v DiskConfig) *int { return v.BootDiskSizeGb }).(pulumi.IntPtrOutput)
}

// Optional. Type of the boot disk (default is "pd-standard"). Valid values: "pd-balanced" (Persistent Disk Balanced Solid State Drive), "pd-ssd" (Persistent Disk Solid State Drive), or "pd-standard" (Persistent Disk Hard Disk Drive). See Disk types (https://cloud.google.com/compute/docs/disks#disk-types).
func (o DiskConfigOutput) BootDiskType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v DiskConfig) *string { return v.BootDiskType }).(pulumi.StringPtrOutput)
}

// Number of attached SSDs, from 0 to 4 (default is 0). If SSDs are not attached, the boot disk is used to store runtime logs and HDFS (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html) data. If one or more SSDs are attached, this runtime bulk data is spread across them, and the boot disk contains only basic config and installed binaries.
func (o DiskConfigOutput) NumLocalSsds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v DiskConfig) *int { return v.NumLocalSsds }).(pulumi.IntPtrOutput)
}

type DiskConfigPtrOutput struct{ *pulumi.OutputState }

func (DiskConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**DiskConfig)(nil)).Elem()
}

func (o DiskConfigPtrOutput) ToDiskConfigPtrOutput() DiskConfigPtrOutput {
	return o
}

func (o DiskConfigPtrOutput) ToDiskConfigPtrOutputWithContext(ctx context.Context) DiskConfigPtrOutput {
	return o
}

func (o DiskConfigPtrOutput) Elem() DiskConfigOutput {
	return o.ApplyT(func(v *DiskConfig) DiskConfig { return *v }).(DiskConfigOutput)
}

// Optional. Size in GB of the boot disk (default is 500GB).
func (o DiskConfigPtrOutput) BootDiskSizeGb() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *DiskConfig) *int {
		if v == nil {
			return nil
		}
		return v.BootDiskSizeGb
	}).(pulumi.IntPtrOutput)
}

// Optional. Type of the boot disk (default is "pd-standard"). Valid values: "pd-balanced" (Persistent Disk Balanced Solid State Drive), "pd-ssd" (Persistent Disk Solid State Drive), or "pd-standard" (Persistent Disk Hard Disk Drive). See Disk types (https://cloud.google.com/compute/docs/disks#disk-types).
func (o DiskConfigPtrOutput) BootDiskType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DiskConfig) *string {
		if v == nil {
			return nil
		}
		return v.BootDiskType
	}).(pulumi.StringPtrOutput)
}

// Number of attached SSDs, from 0 to 4 (default is 0). If SSDs are not attached, the boot disk is used to store runtime logs and HDFS (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html) data. If one or more SSDs are attached, this runtime bulk data is spread across them, and the boot disk contains only basic config and installed binaries.
func (o DiskConfigPtrOutput) NumLocalSsds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *DiskConfig) *int {
		if v == nil {
			return nil
		}
		return v.NumLocalSsds
	}).(pulumi.IntPtrOutput)
}

// Encryption settings for the cluster.
type EncryptionConfig struct {
	// Optional. The Cloud KMS key name to use for PD disk encryption for all instances in the cluster.
	GcePdKmsKeyName *string `pulumi:"gcePdKmsKeyName"`
}

// EncryptionConfigInput is an input type that accepts EncryptionConfigArgs and EncryptionConfigOutput values.
// You can construct a concrete instance of `EncryptionConfigInput` via:
//
//          EncryptionConfigArgs{...}
type EncryptionConfigInput interface {
	pulumi.Input

	ToEncryptionConfigOutput() EncryptionConfigOutput
	ToEncryptionConfigOutputWithContext(context.Context) EncryptionConfigOutput
}

// Encryption settings for the cluster.
type EncryptionConfigArgs struct {
	// Optional. The Cloud KMS key name to use for PD disk encryption for all instances in the cluster.
	GcePdKmsKeyName pulumi.StringPtrInput `pulumi:"gcePdKmsKeyName"`
}

func (EncryptionConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*EncryptionConfig)(nil)).Elem()
}

func (i EncryptionConfigArgs) ToEncryptionConfigOutput() EncryptionConfigOutput {
	return i.ToEncryptionConfigOutputWithContext(context.Background())
}

func (i EncryptionConfigArgs) ToEncryptionConfigOutputWithContext(ctx context.Context) EncryptionConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(EncryptionConfigOutput)
}

func (i EncryptionConfigArgs) ToEncryptionConfigPtrOutput() EncryptionConfigPtrOutput {
	return i.ToEncryptionConfigPtrOutputWithContext(context.Background())
}

func (i EncryptionConfigArgs) ToEncryptionConfigPtrOutputWithContext(ctx context.Context) EncryptionConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(EncryptionConfigOutput).ToEncryptionConfigPtrOutputWithContext(ctx)
}

// EncryptionConfigPtrInput is an input type that accepts EncryptionConfigArgs, EncryptionConfigPtr and EncryptionConfigPtrOutput values.
// You can construct a concrete instance of `EncryptionConfigPtrInput` via:
//
//          EncryptionConfigArgs{...}
//
//  or:
//
//          nil
type EncryptionConfigPtrInput interface {
	pulumi.Input

	ToEncryptionConfigPtrOutput() EncryptionConfigPtrOutput
	ToEncryptionConfigPtrOutputWithContext(context.Context) EncryptionConfigPtrOutput
}

type encryptionConfigPtrType EncryptionConfigArgs

func EncryptionConfigPtr(v *EncryptionConfigArgs) EncryptionConfigPtrInput {
	return (*encryptionConfigPtrType)(v)
}

func (*encryptionConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**EncryptionConfig)(nil)).Elem()
}

func (i *encryptionConfigPtrType) ToEncryptionConfigPtrOutput() EncryptionConfigPtrOutput {
	return i.ToEncryptionConfigPtrOutputWithContext(context.Background())
}

func (i *encryptionConfigPtrType) ToEncryptionConfigPtrOutputWithContext(ctx context.Context) EncryptionConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(EncryptionConfigPtrOutput)
}

// Encryption settings for the cluster.
type EncryptionConfigOutput struct{ *pulumi.OutputState }

func (EncryptionConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*EncryptionConfig)(nil)).Elem()
}

func (o EncryptionConfigOutput) ToEncryptionConfigOutput() EncryptionConfigOutput {
	return o
}

func (o EncryptionConfigOutput) ToEncryptionConfigOutputWithContext(ctx context.Context) EncryptionConfigOutput {
	return o
}

func (o EncryptionConfigOutput) ToEncryptionConfigPtrOutput() EncryptionConfigPtrOutput {
	return o.ToEncryptionConfigPtrOutputWithContext(context.Background())
}

func (o EncryptionConfigOutput) ToEncryptionConfigPtrOutputWithContext(ctx context.Context) EncryptionConfigPtrOutput {
	return o.ApplyT(func(v EncryptionConfig) *EncryptionConfig {
		return &v
	}).(EncryptionConfigPtrOutput)
}

// Optional. The Cloud KMS key name to use for PD disk encryption for all instances in the cluster.
func (o EncryptionConfigOutput) GcePdKmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v EncryptionConfig) *string { return v.GcePdKmsKeyName }).(pulumi.StringPtrOutput)
}

type EncryptionConfigPtrOutput struct{ *pulumi.OutputState }

func (EncryptionConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**EncryptionConfig)(nil)).Elem()
}

func (o EncryptionConfigPtrOutput) ToEncryptionConfigPtrOutput() EncryptionConfigPtrOutput {
	return o
}

func (o EncryptionConfigPtrOutput) ToEncryptionConfigPtrOutputWithContext(ctx context.Context) EncryptionConfigPtrOutput {
	return o
}

func (o EncryptionConfigPtrOutput) Elem() EncryptionConfigOutput {
	return o.ApplyT(func(v *EncryptionConfig) EncryptionConfig { return *v }).(EncryptionConfigOutput)
}

// Optional. The Cloud KMS key name to use for PD disk encryption for all instances in the cluster.
func (o EncryptionConfigPtrOutput) GcePdKmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *EncryptionConfig) *string {
		if v == nil {
			return nil
		}
		return v.GcePdKmsKeyName
	}).(pulumi.StringPtrOutput)
}

// Endpoint config for this cluster
type EndpointConfig struct {
	// Optional. If true, enable http access to specific ports on the cluster from external sources. Defaults to false.
	EnableHttpPortAccess *bool `pulumi:"enableHttpPortAccess"`
	// Output only. The map of port descriptions to URLs. Will only be populated if enable_http_port_access is true.
	HttpPorts map[string]string `pulumi:"httpPorts"`
}

// EndpointConfigInput is an input type that accepts EndpointConfigArgs and EndpointConfigOutput values.
// You can construct a concrete instance of `EndpointConfigInput` via:
//
//          EndpointConfigArgs{...}
type EndpointConfigInput interface {
	pulumi.Input

	ToEndpointConfigOutput() EndpointConfigOutput
	ToEndpointConfigOutputWithContext(context.Context) EndpointConfigOutput
}

// Endpoint config for this cluster
type EndpointConfigArgs struct {
	// Optional. If true, enable http access to specific ports on the cluster from external sources. Defaults to false.
	EnableHttpPortAccess pulumi.BoolPtrInput `pulumi:"enableHttpPortAccess"`
	// Output only. The map of port descriptions to URLs. Will only be populated if enable_http_port_access is true.
	HttpPorts pulumi.StringMapInput `pulumi:"httpPorts"`
}

func (EndpointConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*EndpointConfig)(nil)).Elem()
}

func (i EndpointConfigArgs) ToEndpointConfigOutput() EndpointConfigOutput {
	return i.ToEndpointConfigOutputWithContext(context.Background())
}

func (i EndpointConfigArgs) ToEndpointConfigOutputWithContext(ctx context.Context) EndpointConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(EndpointConfigOutput)
}

func (i EndpointConfigArgs) ToEndpointConfigPtrOutput() EndpointConfigPtrOutput {
	return i.ToEndpointConfigPtrOutputWithContext(context.Background())
}

func (i EndpointConfigArgs) ToEndpointConfigPtrOutputWithContext(ctx context.Context) EndpointConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(EndpointConfigOutput).ToEndpointConfigPtrOutputWithContext(ctx)
}

// EndpointConfigPtrInput is an input type that accepts EndpointConfigArgs, EndpointConfigPtr and EndpointConfigPtrOutput values.
// You can construct a concrete instance of `EndpointConfigPtrInput` via:
//
//          EndpointConfigArgs{...}
//
//  or:
//
//          nil
type EndpointConfigPtrInput interface {
	pulumi.Input

	ToEndpointConfigPtrOutput() EndpointConfigPtrOutput
	ToEndpointConfigPtrOutputWithContext(context.Context) EndpointConfigPtrOutput
}

type endpointConfigPtrType EndpointConfigArgs

func EndpointConfigPtr(v *EndpointConfigArgs) EndpointConfigPtrInput {
	return (*endpointConfigPtrType)(v)
}

func (*endpointConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**EndpointConfig)(nil)).Elem()
}

func (i *endpointConfigPtrType) ToEndpointConfigPtrOutput() EndpointConfigPtrOutput {
	return i.ToEndpointConfigPtrOutputWithContext(context.Background())
}

func (i *endpointConfigPtrType) ToEndpointConfigPtrOutputWithContext(ctx context.Context) EndpointConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(EndpointConfigPtrOutput)
}

// Endpoint config for this cluster
type EndpointConfigOutput struct{ *pulumi.OutputState }

func (EndpointConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*EndpointConfig)(nil)).Elem()
}

func (o EndpointConfigOutput) ToEndpointConfigOutput() EndpointConfigOutput {
	return o
}

func (o EndpointConfigOutput) ToEndpointConfigOutputWithContext(ctx context.Context) EndpointConfigOutput {
	return o
}

func (o EndpointConfigOutput) ToEndpointConfigPtrOutput() EndpointConfigPtrOutput {
	return o.ToEndpointConfigPtrOutputWithContext(context.Background())
}

func (o EndpointConfigOutput) ToEndpointConfigPtrOutputWithContext(ctx context.Context) EndpointConfigPtrOutput {
	return o.ApplyT(func(v EndpointConfig) *EndpointConfig {
		return &v
	}).(EndpointConfigPtrOutput)
}

// Optional. If true, enable http access to specific ports on the cluster from external sources. Defaults to false.
func (o EndpointConfigOutput) EnableHttpPortAccess() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v EndpointConfig) *bool { return v.EnableHttpPortAccess }).(pulumi.BoolPtrOutput)
}

// Output only. The map of port descriptions to URLs. Will only be populated if enable_http_port_access is true.
func (o EndpointConfigOutput) HttpPorts() pulumi.StringMapOutput {
	return o.ApplyT(func(v EndpointConfig) map[string]string { return v.HttpPorts }).(pulumi.StringMapOutput)
}

type EndpointConfigPtrOutput struct{ *pulumi.OutputState }

func (EndpointConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**EndpointConfig)(nil)).Elem()
}

func (o EndpointConfigPtrOutput) ToEndpointConfigPtrOutput() EndpointConfigPtrOutput {
	return o
}

func (o EndpointConfigPtrOutput) ToEndpointConfigPtrOutputWithContext(ctx context.Context) EndpointConfigPtrOutput {
	return o
}

func (o EndpointConfigPtrOutput) Elem() EndpointConfigOutput {
	return o.ApplyT(func(v *EndpointConfig) EndpointConfig { return *v }).(EndpointConfigOutput)
}

// Optional. If true, enable http access to specific ports on the cluster from external sources. Defaults to false.
func (o EndpointConfigPtrOutput) EnableHttpPortAccess() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *EndpointConfig) *bool {
		if v == nil {
			return nil
		}
		return v.EnableHttpPortAccess
	}).(pulumi.BoolPtrOutput)
}

// Output only. The map of port descriptions to URLs. Will only be populated if enable_http_port_access is true.
func (o EndpointConfigPtrOutput) HttpPorts() pulumi.StringMapOutput {
	return o.ApplyT(func(v *EndpointConfig) map[string]string {
		if v == nil {
			return nil
		}
		return v.HttpPorts
	}).(pulumi.StringMapOutput)
}

// Represents a textual expression in the Common Expression Language (CEL) syntax. CEL is a C-like expression language. The syntax and semantics of CEL are documented at https://github.com/google/cel-spec.Example (Comparison): title: "Summary size limit" description: "Determines if a summary is less than 100 chars" expression: "document.summary.size() < 100" Example (Equality): title: "Requestor is owner" description: "Determines if requestor is the document owner" expression: "document.owner == request.auth.claims.email" Example (Logic): title: "Public documents" description: "Determine whether the document should be publicly visible" expression: "document.type != 'private' && document.type != 'internal'" Example (Data Manipulation): title: "Notification string" description: "Create a notification string with a timestamp." expression: "'New message received at ' + string(document.create_time)" The exact variables and functions that may be referenced within an expression are determined by the service that evaluates it. See the service documentation for additional information.
type Expr struct {
	// Optional. Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
	Description *string `pulumi:"description"`
	// Textual representation of an expression in Common Expression Language syntax.
	Expression *string `pulumi:"expression"`
	// Optional. String indicating the location of the expression for error reporting, e.g. a file name and a position in the file.
	Location *string `pulumi:"location"`
	// Optional. Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression.
	Title *string `pulumi:"title"`
}

// ExprInput is an input type that accepts ExprArgs and ExprOutput values.
// You can construct a concrete instance of `ExprInput` via:
//
//          ExprArgs{...}
type ExprInput interface {
	pulumi.Input

	ToExprOutput() ExprOutput
	ToExprOutputWithContext(context.Context) ExprOutput
}

// Represents a textual expression in the Common Expression Language (CEL) syntax. CEL is a C-like expression language. The syntax and semantics of CEL are documented at https://github.com/google/cel-spec.Example (Comparison): title: "Summary size limit" description: "Determines if a summary is less than 100 chars" expression: "document.summary.size() < 100" Example (Equality): title: "Requestor is owner" description: "Determines if requestor is the document owner" expression: "document.owner == request.auth.claims.email" Example (Logic): title: "Public documents" description: "Determine whether the document should be publicly visible" expression: "document.type != 'private' && document.type != 'internal'" Example (Data Manipulation): title: "Notification string" description: "Create a notification string with a timestamp." expression: "'New message received at ' + string(document.create_time)" The exact variables and functions that may be referenced within an expression are determined by the service that evaluates it. See the service documentation for additional information.
type ExprArgs struct {
	// Optional. Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
	Description pulumi.StringPtrInput `pulumi:"description"`
	// Textual representation of an expression in Common Expression Language syntax.
	Expression pulumi.StringPtrInput `pulumi:"expression"`
	// Optional. String indicating the location of the expression for error reporting, e.g. a file name and a position in the file.
	Location pulumi.StringPtrInput `pulumi:"location"`
	// Optional. Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression.
	Title pulumi.StringPtrInput `pulumi:"title"`
}

func (ExprArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*Expr)(nil)).Elem()
}

func (i ExprArgs) ToExprOutput() ExprOutput {
	return i.ToExprOutputWithContext(context.Background())
}

func (i ExprArgs) ToExprOutputWithContext(ctx context.Context) ExprOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ExprOutput)
}

func (i ExprArgs) ToExprPtrOutput() ExprPtrOutput {
	return i.ToExprPtrOutputWithContext(context.Background())
}

func (i ExprArgs) ToExprPtrOutputWithContext(ctx context.Context) ExprPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ExprOutput).ToExprPtrOutputWithContext(ctx)
}

// ExprPtrInput is an input type that accepts ExprArgs, ExprPtr and ExprPtrOutput values.
// You can construct a concrete instance of `ExprPtrInput` via:
//
//          ExprArgs{...}
//
//  or:
//
//          nil
type ExprPtrInput interface {
	pulumi.Input

	ToExprPtrOutput() ExprPtrOutput
	ToExprPtrOutputWithContext(context.Context) ExprPtrOutput
}

type exprPtrType ExprArgs

func ExprPtr(v *ExprArgs) ExprPtrInput {
	return (*exprPtrType)(v)
}

func (*exprPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**Expr)(nil)).Elem()
}

func (i *exprPtrType) ToExprPtrOutput() ExprPtrOutput {
	return i.ToExprPtrOutputWithContext(context.Background())
}

func (i *exprPtrType) ToExprPtrOutputWithContext(ctx context.Context) ExprPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ExprPtrOutput)
}

// Represents a textual expression in the Common Expression Language (CEL) syntax. CEL is a C-like expression language. The syntax and semantics of CEL are documented at https://github.com/google/cel-spec.Example (Comparison): title: "Summary size limit" description: "Determines if a summary is less than 100 chars" expression: "document.summary.size() < 100" Example (Equality): title: "Requestor is owner" description: "Determines if requestor is the document owner" expression: "document.owner == request.auth.claims.email" Example (Logic): title: "Public documents" description: "Determine whether the document should be publicly visible" expression: "document.type != 'private' && document.type != 'internal'" Example (Data Manipulation): title: "Notification string" description: "Create a notification string with a timestamp." expression: "'New message received at ' + string(document.create_time)" The exact variables and functions that may be referenced within an expression are determined by the service that evaluates it. See the service documentation for additional information.
type ExprOutput struct{ *pulumi.OutputState }

func (ExprOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*Expr)(nil)).Elem()
}

func (o ExprOutput) ToExprOutput() ExprOutput {
	return o
}

func (o ExprOutput) ToExprOutputWithContext(ctx context.Context) ExprOutput {
	return o
}

func (o ExprOutput) ToExprPtrOutput() ExprPtrOutput {
	return o.ToExprPtrOutputWithContext(context.Background())
}

func (o ExprOutput) ToExprPtrOutputWithContext(ctx context.Context) ExprPtrOutput {
	return o.ApplyT(func(v Expr) *Expr {
		return &v
	}).(ExprPtrOutput)
}

// Optional. Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
func (o ExprOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v Expr) *string { return v.Description }).(pulumi.StringPtrOutput)
}

// Textual representation of an expression in Common Expression Language syntax.
func (o ExprOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v Expr) *string { return v.Expression }).(pulumi.StringPtrOutput)
}

// Optional. String indicating the location of the expression for error reporting, e.g. a file name and a position in the file.
func (o ExprOutput) Location() pulumi.StringPtrOutput {
	return o.ApplyT(func(v Expr) *string { return v.Location }).(pulumi.StringPtrOutput)
}

// Optional. Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression.
func (o ExprOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v Expr) *string { return v.Title }).(pulumi.StringPtrOutput)
}

type ExprPtrOutput struct{ *pulumi.OutputState }

func (ExprPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**Expr)(nil)).Elem()
}

func (o ExprPtrOutput) ToExprPtrOutput() ExprPtrOutput {
	return o
}

func (o ExprPtrOutput) ToExprPtrOutputWithContext(ctx context.Context) ExprPtrOutput {
	return o
}

func (o ExprPtrOutput) Elem() ExprOutput {
	return o.ApplyT(func(v *Expr) Expr { return *v }).(ExprOutput)
}

// Optional. Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
func (o ExprPtrOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *Expr) *string {
		if v == nil {
			return nil
		}
		return v.Description
	}).(pulumi.StringPtrOutput)
}

// Textual representation of an expression in Common Expression Language syntax.
func (o ExprPtrOutput) Expression() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *Expr) *string {
		if v == nil {
			return nil
		}
		return v.Expression
	}).(pulumi.StringPtrOutput)
}

// Optional. String indicating the location of the expression for error reporting, e.g. a file name and a position in the file.
func (o ExprPtrOutput) Location() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *Expr) *string {
		if v == nil {
			return nil
		}
		return v.Location
	}).(pulumi.StringPtrOutput)
}

// Optional. Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression.
func (o ExprPtrOutput) Title() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *Expr) *string {
		if v == nil {
			return nil
		}
		return v.Title
	}).(pulumi.StringPtrOutput)
}

// Common config settings for resources of Compute Engine cluster instances, applicable to all instances in the cluster.
type GceClusterConfig struct {
	// Optional. If true, all instances in the cluster will only have internal IP addresses. By default, clusters are not restricted to internal IP addresses, and will have ephemeral external IP addresses assigned to each instance. This internal_ip_only restriction can only be enabled for subnetwork enabled networks, and all off-cluster dependencies must be configured to be accessible without external IP addresses.
	InternalIpOnly *bool `pulumi:"internalIpOnly"`
	// The Compute Engine metadata entries to add to all instances (see Project and instance metadata (https://cloud.google.com/compute/docs/storing-retrieving-metadata#project_and_instance_metadata)).
	Metadata map[string]string `pulumi:"metadata"`
	// Optional. The Compute Engine network to be used for machine communications. Cannot be specified with subnetwork_uri. If neither network_uri nor subnetwork_uri is specified, the "default" network of the project is used, if it exists. Cannot be a "Custom Subnet Network" (see Using Subnetworks (https://cloud.google.com/compute/docs/subnetworks) for more information).A full URL, partial URI, or short name are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/regions/global/default projects/[project_id]/regions/global/default default
	NetworkUri *string `pulumi:"networkUri"`
	// Optional. Node Group Affinity for sole-tenant clusters.
	NodeGroupAffinity *NodeGroupAffinity `pulumi:"nodeGroupAffinity"`
	// Optional. The type of IPv6 access for a cluster.
	PrivateIpv6GoogleAccess *string `pulumi:"privateIpv6GoogleAccess"`
	// Optional. Reservation Affinity for consuming Zonal reservation.
	ReservationAffinity *ReservationAffinity `pulumi:"reservationAffinity"`
	// Optional. The Dataproc service account (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/service-accounts#service_accounts_in_dataproc) (also see VM Data Plane identity (https://cloud.google.com/dataproc/docs/concepts/iam/dataproc-principals#vm_service_account_data_plane_identity)) used by Dataproc cluster VM instances to access Google Cloud Platform services.If not specified, the Compute Engine default service account (https://cloud.google.com/compute/docs/access/service-accounts#default_service_account) is used.
	ServiceAccount *string `pulumi:"serviceAccount"`
	// Optional. The URIs of service account scopes to be included in Compute Engine instances. The following base set of scopes is always included: https://www.googleapis.com/auth/cloud.useraccounts.readonly https://www.googleapis.com/auth/devstorage.read_write https://www.googleapis.com/auth/logging.writeIf no scopes are specified, the following defaults are also provided: https://www.googleapis.com/auth/bigquery https://www.googleapis.com/auth/bigtable.admin.table https://www.googleapis.com/auth/bigtable.data https://www.googleapis.com/auth/devstorage.full_control
	ServiceAccountScopes []string `pulumi:"serviceAccountScopes"`
	// Optional. Shielded Instance Config for clusters using Compute Engine Shielded VMs (https://cloud.google.com/security/shielded-cloud/shielded-vm).
	ShieldedInstanceConfig *ShieldedInstanceConfig `pulumi:"shieldedInstanceConfig"`
	// Optional. The Compute Engine subnetwork to be used for machine communications. Cannot be specified with network_uri.A full URL, partial URI, or short name are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/regions/us-east1/subnetworks/sub0 projects/[project_id]/regions/us-east1/subnetworks/sub0 sub0
	SubnetworkUri *string `pulumi:"subnetworkUri"`
	// The Compute Engine tags to add to all instances (see Tagging instances (https://cloud.google.com/compute/docs/label-or-tag-resources#tags)).
	Tags []string `pulumi:"tags"`
	// Optional. The zone where the Compute Engine cluster will be located. On a create request, it is required in the "global" region. If omitted in a non-global Dataproc region, the service will pick a zone in the corresponding Compute Engine region. On a get request, zone will always be present.A full URL, partial URI, or short name are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/zones/[zone] projects/[project_id]/zones/[zone] us-central1-f
	ZoneUri *string `pulumi:"zoneUri"`
}

// GceClusterConfigInput is an input type that accepts GceClusterConfigArgs and GceClusterConfigOutput values.
// You can construct a concrete instance of `GceClusterConfigInput` via:
//
//          GceClusterConfigArgs{...}
type GceClusterConfigInput interface {
	pulumi.Input

	ToGceClusterConfigOutput() GceClusterConfigOutput
	ToGceClusterConfigOutputWithContext(context.Context) GceClusterConfigOutput
}

// Common config settings for resources of Compute Engine cluster instances, applicable to all instances in the cluster.
type GceClusterConfigArgs struct {
	// Optional. If true, all instances in the cluster will only have internal IP addresses. By default, clusters are not restricted to internal IP addresses, and will have ephemeral external IP addresses assigned to each instance. This internal_ip_only restriction can only be enabled for subnetwork enabled networks, and all off-cluster dependencies must be configured to be accessible without external IP addresses.
	InternalIpOnly pulumi.BoolPtrInput `pulumi:"internalIpOnly"`
	// The Compute Engine metadata entries to add to all instances (see Project and instance metadata (https://cloud.google.com/compute/docs/storing-retrieving-metadata#project_and_instance_metadata)).
	Metadata pulumi.StringMapInput `pulumi:"metadata"`
	// Optional. The Compute Engine network to be used for machine communications. Cannot be specified with subnetwork_uri. If neither network_uri nor subnetwork_uri is specified, the "default" network of the project is used, if it exists. Cannot be a "Custom Subnet Network" (see Using Subnetworks (https://cloud.google.com/compute/docs/subnetworks) for more information).A full URL, partial URI, or short name are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/regions/global/default projects/[project_id]/regions/global/default default
	NetworkUri pulumi.StringPtrInput `pulumi:"networkUri"`
	// Optional. Node Group Affinity for sole-tenant clusters.
	NodeGroupAffinity NodeGroupAffinityPtrInput `pulumi:"nodeGroupAffinity"`
	// Optional. The type of IPv6 access for a cluster.
	PrivateIpv6GoogleAccess pulumi.StringPtrInput `pulumi:"privateIpv6GoogleAccess"`
	// Optional. Reservation Affinity for consuming Zonal reservation.
	ReservationAffinity ReservationAffinityPtrInput `pulumi:"reservationAffinity"`
	// Optional. The Dataproc service account (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/service-accounts#service_accounts_in_dataproc) (also see VM Data Plane identity (https://cloud.google.com/dataproc/docs/concepts/iam/dataproc-principals#vm_service_account_data_plane_identity)) used by Dataproc cluster VM instances to access Google Cloud Platform services.If not specified, the Compute Engine default service account (https://cloud.google.com/compute/docs/access/service-accounts#default_service_account) is used.
	ServiceAccount pulumi.StringPtrInput `pulumi:"serviceAccount"`
	// Optional. The URIs of service account scopes to be included in Compute Engine instances. The following base set of scopes is always included: https://www.googleapis.com/auth/cloud.useraccounts.readonly https://www.googleapis.com/auth/devstorage.read_write https://www.googleapis.com/auth/logging.writeIf no scopes are specified, the following defaults are also provided: https://www.googleapis.com/auth/bigquery https://www.googleapis.com/auth/bigtable.admin.table https://www.googleapis.com/auth/bigtable.data https://www.googleapis.com/auth/devstorage.full_control
	ServiceAccountScopes pulumi.StringArrayInput `pulumi:"serviceAccountScopes"`
	// Optional. Shielded Instance Config for clusters using Compute Engine Shielded VMs (https://cloud.google.com/security/shielded-cloud/shielded-vm).
	ShieldedInstanceConfig ShieldedInstanceConfigPtrInput `pulumi:"shieldedInstanceConfig"`
	// Optional. The Compute Engine subnetwork to be used for machine communications. Cannot be specified with network_uri.A full URL, partial URI, or short name are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/regions/us-east1/subnetworks/sub0 projects/[project_id]/regions/us-east1/subnetworks/sub0 sub0
	SubnetworkUri pulumi.StringPtrInput `pulumi:"subnetworkUri"`
	// The Compute Engine tags to add to all instances (see Tagging instances (https://cloud.google.com/compute/docs/label-or-tag-resources#tags)).
	Tags pulumi.StringArrayInput `pulumi:"tags"`
	// Optional. The zone where the Compute Engine cluster will be located. On a create request, it is required in the "global" region. If omitted in a non-global Dataproc region, the service will pick a zone in the corresponding Compute Engine region. On a get request, zone will always be present.A full URL, partial URI, or short name are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/zones/[zone] projects/[project_id]/zones/[zone] us-central1-f
	ZoneUri pulumi.StringPtrInput `pulumi:"zoneUri"`
}

func (GceClusterConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GceClusterConfig)(nil)).Elem()
}

func (i GceClusterConfigArgs) ToGceClusterConfigOutput() GceClusterConfigOutput {
	return i.ToGceClusterConfigOutputWithContext(context.Background())
}

func (i GceClusterConfigArgs) ToGceClusterConfigOutputWithContext(ctx context.Context) GceClusterConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GceClusterConfigOutput)
}

func (i GceClusterConfigArgs) ToGceClusterConfigPtrOutput() GceClusterConfigPtrOutput {
	return i.ToGceClusterConfigPtrOutputWithContext(context.Background())
}

func (i GceClusterConfigArgs) ToGceClusterConfigPtrOutputWithContext(ctx context.Context) GceClusterConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GceClusterConfigOutput).ToGceClusterConfigPtrOutputWithContext(ctx)
}

// GceClusterConfigPtrInput is an input type that accepts GceClusterConfigArgs, GceClusterConfigPtr and GceClusterConfigPtrOutput values.
// You can construct a concrete instance of `GceClusterConfigPtrInput` via:
//
//          GceClusterConfigArgs{...}
//
//  or:
//
//          nil
type GceClusterConfigPtrInput interface {
	pulumi.Input

	ToGceClusterConfigPtrOutput() GceClusterConfigPtrOutput
	ToGceClusterConfigPtrOutputWithContext(context.Context) GceClusterConfigPtrOutput
}

type gceClusterConfigPtrType GceClusterConfigArgs

func GceClusterConfigPtr(v *GceClusterConfigArgs) GceClusterConfigPtrInput {
	return (*gceClusterConfigPtrType)(v)
}

func (*gceClusterConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GceClusterConfig)(nil)).Elem()
}

func (i *gceClusterConfigPtrType) ToGceClusterConfigPtrOutput() GceClusterConfigPtrOutput {
	return i.ToGceClusterConfigPtrOutputWithContext(context.Background())
}

func (i *gceClusterConfigPtrType) ToGceClusterConfigPtrOutputWithContext(ctx context.Context) GceClusterConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GceClusterConfigPtrOutput)
}

// Common config settings for resources of Compute Engine cluster instances, applicable to all instances in the cluster.
type GceClusterConfigOutput struct{ *pulumi.OutputState }

func (GceClusterConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GceClusterConfig)(nil)).Elem()
}

func (o GceClusterConfigOutput) ToGceClusterConfigOutput() GceClusterConfigOutput {
	return o
}

func (o GceClusterConfigOutput) ToGceClusterConfigOutputWithContext(ctx context.Context) GceClusterConfigOutput {
	return o
}

func (o GceClusterConfigOutput) ToGceClusterConfigPtrOutput() GceClusterConfigPtrOutput {
	return o.ToGceClusterConfigPtrOutputWithContext(context.Background())
}

func (o GceClusterConfigOutput) ToGceClusterConfigPtrOutputWithContext(ctx context.Context) GceClusterConfigPtrOutput {
	return o.ApplyT(func(v GceClusterConfig) *GceClusterConfig {
		return &v
	}).(GceClusterConfigPtrOutput)
}

// Optional. If true, all instances in the cluster will only have internal IP addresses. By default, clusters are not restricted to internal IP addresses, and will have ephemeral external IP addresses assigned to each instance. This internal_ip_only restriction can only be enabled for subnetwork enabled networks, and all off-cluster dependencies must be configured to be accessible without external IP addresses.
func (o GceClusterConfigOutput) InternalIpOnly() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v GceClusterConfig) *bool { return v.InternalIpOnly }).(pulumi.BoolPtrOutput)
}

// The Compute Engine metadata entries to add to all instances (see Project and instance metadata (https://cloud.google.com/compute/docs/storing-retrieving-metadata#project_and_instance_metadata)).
func (o GceClusterConfigOutput) Metadata() pulumi.StringMapOutput {
	return o.ApplyT(func(v GceClusterConfig) map[string]string { return v.Metadata }).(pulumi.StringMapOutput)
}

// Optional. The Compute Engine network to be used for machine communications. Cannot be specified with subnetwork_uri. If neither network_uri nor subnetwork_uri is specified, the "default" network of the project is used, if it exists. Cannot be a "Custom Subnet Network" (see Using Subnetworks (https://cloud.google.com/compute/docs/subnetworks) for more information).A full URL, partial URI, or short name are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/regions/global/default projects/[project_id]/regions/global/default default
func (o GceClusterConfigOutput) NetworkUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GceClusterConfig) *string { return v.NetworkUri }).(pulumi.StringPtrOutput)
}

// Optional. Node Group Affinity for sole-tenant clusters.
func (o GceClusterConfigOutput) NodeGroupAffinity() NodeGroupAffinityPtrOutput {
	return o.ApplyT(func(v GceClusterConfig) *NodeGroupAffinity { return v.NodeGroupAffinity }).(NodeGroupAffinityPtrOutput)
}

// Optional. The type of IPv6 access for a cluster.
func (o GceClusterConfigOutput) PrivateIpv6GoogleAccess() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GceClusterConfig) *string { return v.PrivateIpv6GoogleAccess }).(pulumi.StringPtrOutput)
}

// Optional. Reservation Affinity for consuming Zonal reservation.
func (o GceClusterConfigOutput) ReservationAffinity() ReservationAffinityPtrOutput {
	return o.ApplyT(func(v GceClusterConfig) *ReservationAffinity { return v.ReservationAffinity }).(ReservationAffinityPtrOutput)
}

// Optional. The Dataproc service account (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/service-accounts#service_accounts_in_dataproc) (also see VM Data Plane identity (https://cloud.google.com/dataproc/docs/concepts/iam/dataproc-principals#vm_service_account_data_plane_identity)) used by Dataproc cluster VM instances to access Google Cloud Platform services.If not specified, the Compute Engine default service account (https://cloud.google.com/compute/docs/access/service-accounts#default_service_account) is used.
func (o GceClusterConfigOutput) ServiceAccount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GceClusterConfig) *string { return v.ServiceAccount }).(pulumi.StringPtrOutput)
}

// Optional. The URIs of service account scopes to be included in Compute Engine instances. The following base set of scopes is always included: https://www.googleapis.com/auth/cloud.useraccounts.readonly https://www.googleapis.com/auth/devstorage.read_write https://www.googleapis.com/auth/logging.writeIf no scopes are specified, the following defaults are also provided: https://www.googleapis.com/auth/bigquery https://www.googleapis.com/auth/bigtable.admin.table https://www.googleapis.com/auth/bigtable.data https://www.googleapis.com/auth/devstorage.full_control
func (o GceClusterConfigOutput) ServiceAccountScopes() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GceClusterConfig) []string { return v.ServiceAccountScopes }).(pulumi.StringArrayOutput)
}

// Optional. Shielded Instance Config for clusters using Compute Engine Shielded VMs (https://cloud.google.com/security/shielded-cloud/shielded-vm).
func (o GceClusterConfigOutput) ShieldedInstanceConfig() ShieldedInstanceConfigPtrOutput {
	return o.ApplyT(func(v GceClusterConfig) *ShieldedInstanceConfig { return v.ShieldedInstanceConfig }).(ShieldedInstanceConfigPtrOutput)
}

// Optional. The Compute Engine subnetwork to be used for machine communications. Cannot be specified with network_uri.A full URL, partial URI, or short name are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/regions/us-east1/subnetworks/sub0 projects/[project_id]/regions/us-east1/subnetworks/sub0 sub0
func (o GceClusterConfigOutput) SubnetworkUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GceClusterConfig) *string { return v.SubnetworkUri }).(pulumi.StringPtrOutput)
}

// The Compute Engine tags to add to all instances (see Tagging instances (https://cloud.google.com/compute/docs/label-or-tag-resources#tags)).
func (o GceClusterConfigOutput) Tags() pulumi.StringArrayOutput {
	return o.ApplyT(func(v GceClusterConfig) []string { return v.Tags }).(pulumi.StringArrayOutput)
}

// Optional. The zone where the Compute Engine cluster will be located. On a create request, it is required in the "global" region. If omitted in a non-global Dataproc region, the service will pick a zone in the corresponding Compute Engine region. On a get request, zone will always be present.A full URL, partial URI, or short name are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/zones/[zone] projects/[project_id]/zones/[zone] us-central1-f
func (o GceClusterConfigOutput) ZoneUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v GceClusterConfig) *string { return v.ZoneUri }).(pulumi.StringPtrOutput)
}

type GceClusterConfigPtrOutput struct{ *pulumi.OutputState }

func (GceClusterConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GceClusterConfig)(nil)).Elem()
}

func (o GceClusterConfigPtrOutput) ToGceClusterConfigPtrOutput() GceClusterConfigPtrOutput {
	return o
}

func (o GceClusterConfigPtrOutput) ToGceClusterConfigPtrOutputWithContext(ctx context.Context) GceClusterConfigPtrOutput {
	return o
}

func (o GceClusterConfigPtrOutput) Elem() GceClusterConfigOutput {
	return o.ApplyT(func(v *GceClusterConfig) GceClusterConfig { return *v }).(GceClusterConfigOutput)
}

// Optional. If true, all instances in the cluster will only have internal IP addresses. By default, clusters are not restricted to internal IP addresses, and will have ephemeral external IP addresses assigned to each instance. This internal_ip_only restriction can only be enabled for subnetwork enabled networks, and all off-cluster dependencies must be configured to be accessible without external IP addresses.
func (o GceClusterConfigPtrOutput) InternalIpOnly() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *GceClusterConfig) *bool {
		if v == nil {
			return nil
		}
		return v.InternalIpOnly
	}).(pulumi.BoolPtrOutput)
}

// The Compute Engine metadata entries to add to all instances (see Project and instance metadata (https://cloud.google.com/compute/docs/storing-retrieving-metadata#project_and_instance_metadata)).
func (o GceClusterConfigPtrOutput) Metadata() pulumi.StringMapOutput {
	return o.ApplyT(func(v *GceClusterConfig) map[string]string {
		if v == nil {
			return nil
		}
		return v.Metadata
	}).(pulumi.StringMapOutput)
}

// Optional. The Compute Engine network to be used for machine communications. Cannot be specified with subnetwork_uri. If neither network_uri nor subnetwork_uri is specified, the "default" network of the project is used, if it exists. Cannot be a "Custom Subnet Network" (see Using Subnetworks (https://cloud.google.com/compute/docs/subnetworks) for more information).A full URL, partial URI, or short name are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/regions/global/default projects/[project_id]/regions/global/default default
func (o GceClusterConfigPtrOutput) NetworkUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GceClusterConfig) *string {
		if v == nil {
			return nil
		}
		return v.NetworkUri
	}).(pulumi.StringPtrOutput)
}

// Optional. Node Group Affinity for sole-tenant clusters.
func (o GceClusterConfigPtrOutput) NodeGroupAffinity() NodeGroupAffinityPtrOutput {
	return o.ApplyT(func(v *GceClusterConfig) *NodeGroupAffinity {
		if v == nil {
			return nil
		}
		return v.NodeGroupAffinity
	}).(NodeGroupAffinityPtrOutput)
}

// Optional. The type of IPv6 access for a cluster.
func (o GceClusterConfigPtrOutput) PrivateIpv6GoogleAccess() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GceClusterConfig) *string {
		if v == nil {
			return nil
		}
		return v.PrivateIpv6GoogleAccess
	}).(pulumi.StringPtrOutput)
}

// Optional. Reservation Affinity for consuming Zonal reservation.
func (o GceClusterConfigPtrOutput) ReservationAffinity() ReservationAffinityPtrOutput {
	return o.ApplyT(func(v *GceClusterConfig) *ReservationAffinity {
		if v == nil {
			return nil
		}
		return v.ReservationAffinity
	}).(ReservationAffinityPtrOutput)
}

// Optional. The Dataproc service account (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/service-accounts#service_accounts_in_dataproc) (also see VM Data Plane identity (https://cloud.google.com/dataproc/docs/concepts/iam/dataproc-principals#vm_service_account_data_plane_identity)) used by Dataproc cluster VM instances to access Google Cloud Platform services.If not specified, the Compute Engine default service account (https://cloud.google.com/compute/docs/access/service-accounts#default_service_account) is used.
func (o GceClusterConfigPtrOutput) ServiceAccount() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GceClusterConfig) *string {
		if v == nil {
			return nil
		}
		return v.ServiceAccount
	}).(pulumi.StringPtrOutput)
}

// Optional. The URIs of service account scopes to be included in Compute Engine instances. The following base set of scopes is always included: https://www.googleapis.com/auth/cloud.useraccounts.readonly https://www.googleapis.com/auth/devstorage.read_write https://www.googleapis.com/auth/logging.writeIf no scopes are specified, the following defaults are also provided: https://www.googleapis.com/auth/bigquery https://www.googleapis.com/auth/bigtable.admin.table https://www.googleapis.com/auth/bigtable.data https://www.googleapis.com/auth/devstorage.full_control
func (o GceClusterConfigPtrOutput) ServiceAccountScopes() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GceClusterConfig) []string {
		if v == nil {
			return nil
		}
		return v.ServiceAccountScopes
	}).(pulumi.StringArrayOutput)
}

// Optional. Shielded Instance Config for clusters using Compute Engine Shielded VMs (https://cloud.google.com/security/shielded-cloud/shielded-vm).
func (o GceClusterConfigPtrOutput) ShieldedInstanceConfig() ShieldedInstanceConfigPtrOutput {
	return o.ApplyT(func(v *GceClusterConfig) *ShieldedInstanceConfig {
		if v == nil {
			return nil
		}
		return v.ShieldedInstanceConfig
	}).(ShieldedInstanceConfigPtrOutput)
}

// Optional. The Compute Engine subnetwork to be used for machine communications. Cannot be specified with network_uri.A full URL, partial URI, or short name are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/regions/us-east1/subnetworks/sub0 projects/[project_id]/regions/us-east1/subnetworks/sub0 sub0
func (o GceClusterConfigPtrOutput) SubnetworkUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GceClusterConfig) *string {
		if v == nil {
			return nil
		}
		return v.SubnetworkUri
	}).(pulumi.StringPtrOutput)
}

// The Compute Engine tags to add to all instances (see Tagging instances (https://cloud.google.com/compute/docs/label-or-tag-resources#tags)).
func (o GceClusterConfigPtrOutput) Tags() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *GceClusterConfig) []string {
		if v == nil {
			return nil
		}
		return v.Tags
	}).(pulumi.StringArrayOutput)
}

// Optional. The zone where the Compute Engine cluster will be located. On a create request, it is required in the "global" region. If omitted in a non-global Dataproc region, the service will pick a zone in the corresponding Compute Engine region. On a get request, zone will always be present.A full URL, partial URI, or short name are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/zones/[zone] projects/[project_id]/zones/[zone] us-central1-f
func (o GceClusterConfigPtrOutput) ZoneUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *GceClusterConfig) *string {
		if v == nil {
			return nil
		}
		return v.ZoneUri
	}).(pulumi.StringPtrOutput)
}

// The GKE config for this cluster.
type GkeClusterConfig struct {
	// Optional. A target for the deployment.
	NamespacedGkeDeploymentTarget *NamespacedGkeDeploymentTarget `pulumi:"namespacedGkeDeploymentTarget"`
}

// GkeClusterConfigInput is an input type that accepts GkeClusterConfigArgs and GkeClusterConfigOutput values.
// You can construct a concrete instance of `GkeClusterConfigInput` via:
//
//          GkeClusterConfigArgs{...}
type GkeClusterConfigInput interface {
	pulumi.Input

	ToGkeClusterConfigOutput() GkeClusterConfigOutput
	ToGkeClusterConfigOutputWithContext(context.Context) GkeClusterConfigOutput
}

// The GKE config for this cluster.
type GkeClusterConfigArgs struct {
	// Optional. A target for the deployment.
	NamespacedGkeDeploymentTarget NamespacedGkeDeploymentTargetPtrInput `pulumi:"namespacedGkeDeploymentTarget"`
}

func (GkeClusterConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*GkeClusterConfig)(nil)).Elem()
}

func (i GkeClusterConfigArgs) ToGkeClusterConfigOutput() GkeClusterConfigOutput {
	return i.ToGkeClusterConfigOutputWithContext(context.Background())
}

func (i GkeClusterConfigArgs) ToGkeClusterConfigOutputWithContext(ctx context.Context) GkeClusterConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GkeClusterConfigOutput)
}

func (i GkeClusterConfigArgs) ToGkeClusterConfigPtrOutput() GkeClusterConfigPtrOutput {
	return i.ToGkeClusterConfigPtrOutputWithContext(context.Background())
}

func (i GkeClusterConfigArgs) ToGkeClusterConfigPtrOutputWithContext(ctx context.Context) GkeClusterConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GkeClusterConfigOutput).ToGkeClusterConfigPtrOutputWithContext(ctx)
}

// GkeClusterConfigPtrInput is an input type that accepts GkeClusterConfigArgs, GkeClusterConfigPtr and GkeClusterConfigPtrOutput values.
// You can construct a concrete instance of `GkeClusterConfigPtrInput` via:
//
//          GkeClusterConfigArgs{...}
//
//  or:
//
//          nil
type GkeClusterConfigPtrInput interface {
	pulumi.Input

	ToGkeClusterConfigPtrOutput() GkeClusterConfigPtrOutput
	ToGkeClusterConfigPtrOutputWithContext(context.Context) GkeClusterConfigPtrOutput
}

type gkeClusterConfigPtrType GkeClusterConfigArgs

func GkeClusterConfigPtr(v *GkeClusterConfigArgs) GkeClusterConfigPtrInput {
	return (*gkeClusterConfigPtrType)(v)
}

func (*gkeClusterConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**GkeClusterConfig)(nil)).Elem()
}

func (i *gkeClusterConfigPtrType) ToGkeClusterConfigPtrOutput() GkeClusterConfigPtrOutput {
	return i.ToGkeClusterConfigPtrOutputWithContext(context.Background())
}

func (i *gkeClusterConfigPtrType) ToGkeClusterConfigPtrOutputWithContext(ctx context.Context) GkeClusterConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(GkeClusterConfigPtrOutput)
}

// The GKE config for this cluster.
type GkeClusterConfigOutput struct{ *pulumi.OutputState }

func (GkeClusterConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*GkeClusterConfig)(nil)).Elem()
}

func (o GkeClusterConfigOutput) ToGkeClusterConfigOutput() GkeClusterConfigOutput {
	return o
}

func (o GkeClusterConfigOutput) ToGkeClusterConfigOutputWithContext(ctx context.Context) GkeClusterConfigOutput {
	return o
}

func (o GkeClusterConfigOutput) ToGkeClusterConfigPtrOutput() GkeClusterConfigPtrOutput {
	return o.ToGkeClusterConfigPtrOutputWithContext(context.Background())
}

func (o GkeClusterConfigOutput) ToGkeClusterConfigPtrOutputWithContext(ctx context.Context) GkeClusterConfigPtrOutput {
	return o.ApplyT(func(v GkeClusterConfig) *GkeClusterConfig {
		return &v
	}).(GkeClusterConfigPtrOutput)
}

// Optional. A target for the deployment.
func (o GkeClusterConfigOutput) NamespacedGkeDeploymentTarget() NamespacedGkeDeploymentTargetPtrOutput {
	return o.ApplyT(func(v GkeClusterConfig) *NamespacedGkeDeploymentTarget { return v.NamespacedGkeDeploymentTarget }).(NamespacedGkeDeploymentTargetPtrOutput)
}

type GkeClusterConfigPtrOutput struct{ *pulumi.OutputState }

func (GkeClusterConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**GkeClusterConfig)(nil)).Elem()
}

func (o GkeClusterConfigPtrOutput) ToGkeClusterConfigPtrOutput() GkeClusterConfigPtrOutput {
	return o
}

func (o GkeClusterConfigPtrOutput) ToGkeClusterConfigPtrOutputWithContext(ctx context.Context) GkeClusterConfigPtrOutput {
	return o
}

func (o GkeClusterConfigPtrOutput) Elem() GkeClusterConfigOutput {
	return o.ApplyT(func(v *GkeClusterConfig) GkeClusterConfig { return *v }).(GkeClusterConfigOutput)
}

// Optional. A target for the deployment.
func (o GkeClusterConfigPtrOutput) NamespacedGkeDeploymentTarget() NamespacedGkeDeploymentTargetPtrOutput {
	return o.ApplyT(func(v *GkeClusterConfig) *NamespacedGkeDeploymentTarget {
		if v == nil {
			return nil
		}
		return v.NamespacedGkeDeploymentTarget
	}).(NamespacedGkeDeploymentTargetPtrOutput)
}

// A Dataproc job for running Apache Hadoop MapReduce (https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html) jobs on Apache Hadoop YARN (https://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-site/YARN.html).
type HadoopJob struct {
	// Optional. HCFS URIs of archives to be extracted in the working directory of Hadoop drivers and tasks. Supported file types: .jar, .tar, .tar.gz, .tgz, or .zip.
	ArchiveUris []string `pulumi:"archiveUris"`
	// Optional. The arguments to pass to the driver. Do not include arguments, such as -libjars or -Dfoo=bar, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
	Args []string `pulumi:"args"`
	// Optional. HCFS (Hadoop Compatible Filesystem) URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.
	FileUris []string `pulumi:"fileUris"`
	// Optional. Jar file URIs to add to the CLASSPATHs of the Hadoop driver and tasks.
	JarFileUris []string `pulumi:"jarFileUris"`
	// Optional. The runtime log config for job execution.
	LoggingConfig *LoggingConfig `pulumi:"loggingConfig"`
	// The name of the driver's main class. The jar file containing the class must be in the default CLASSPATH or specified in jar_file_uris.
	MainClass *string `pulumi:"mainClass"`
	// The HCFS URI of the jar file containing the main class. Examples: 'gs://foo-bucket/analytics-binaries/extract-useful-metrics-mr.jar' 'hdfs:/tmp/test-samples/custom-wordcount.jar' 'file:///home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'
	MainJarFileUri *string `pulumi:"mainJarFileUri"`
	// Optional. A mapping of property names to values, used to configure Hadoop. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site and classes in user code.
	Properties map[string]string `pulumi:"properties"`
}

// HadoopJobInput is an input type that accepts HadoopJobArgs and HadoopJobOutput values.
// You can construct a concrete instance of `HadoopJobInput` via:
//
//          HadoopJobArgs{...}
type HadoopJobInput interface {
	pulumi.Input

	ToHadoopJobOutput() HadoopJobOutput
	ToHadoopJobOutputWithContext(context.Context) HadoopJobOutput
}

// A Dataproc job for running Apache Hadoop MapReduce (https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html) jobs on Apache Hadoop YARN (https://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-site/YARN.html).
type HadoopJobArgs struct {
	// Optional. HCFS URIs of archives to be extracted in the working directory of Hadoop drivers and tasks. Supported file types: .jar, .tar, .tar.gz, .tgz, or .zip.
	ArchiveUris pulumi.StringArrayInput `pulumi:"archiveUris"`
	// Optional. The arguments to pass to the driver. Do not include arguments, such as -libjars or -Dfoo=bar, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
	Args pulumi.StringArrayInput `pulumi:"args"`
	// Optional. HCFS (Hadoop Compatible Filesystem) URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.
	FileUris pulumi.StringArrayInput `pulumi:"fileUris"`
	// Optional. Jar file URIs to add to the CLASSPATHs of the Hadoop driver and tasks.
	JarFileUris pulumi.StringArrayInput `pulumi:"jarFileUris"`
	// Optional. The runtime log config for job execution.
	LoggingConfig LoggingConfigPtrInput `pulumi:"loggingConfig"`
	// The name of the driver's main class. The jar file containing the class must be in the default CLASSPATH or specified in jar_file_uris.
	MainClass pulumi.StringPtrInput `pulumi:"mainClass"`
	// The HCFS URI of the jar file containing the main class. Examples: 'gs://foo-bucket/analytics-binaries/extract-useful-metrics-mr.jar' 'hdfs:/tmp/test-samples/custom-wordcount.jar' 'file:///home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'
	MainJarFileUri pulumi.StringPtrInput `pulumi:"mainJarFileUri"`
	// Optional. A mapping of property names to values, used to configure Hadoop. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site and classes in user code.
	Properties pulumi.StringMapInput `pulumi:"properties"`
}

func (HadoopJobArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*HadoopJob)(nil)).Elem()
}

func (i HadoopJobArgs) ToHadoopJobOutput() HadoopJobOutput {
	return i.ToHadoopJobOutputWithContext(context.Background())
}

func (i HadoopJobArgs) ToHadoopJobOutputWithContext(ctx context.Context) HadoopJobOutput {
	return pulumi.ToOutputWithContext(ctx, i).(HadoopJobOutput)
}

func (i HadoopJobArgs) ToHadoopJobPtrOutput() HadoopJobPtrOutput {
	return i.ToHadoopJobPtrOutputWithContext(context.Background())
}

func (i HadoopJobArgs) ToHadoopJobPtrOutputWithContext(ctx context.Context) HadoopJobPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(HadoopJobOutput).ToHadoopJobPtrOutputWithContext(ctx)
}

// HadoopJobPtrInput is an input type that accepts HadoopJobArgs, HadoopJobPtr and HadoopJobPtrOutput values.
// You can construct a concrete instance of `HadoopJobPtrInput` via:
//
//          HadoopJobArgs{...}
//
//  or:
//
//          nil
type HadoopJobPtrInput interface {
	pulumi.Input

	ToHadoopJobPtrOutput() HadoopJobPtrOutput
	ToHadoopJobPtrOutputWithContext(context.Context) HadoopJobPtrOutput
}

type hadoopJobPtrType HadoopJobArgs

func HadoopJobPtr(v *HadoopJobArgs) HadoopJobPtrInput {
	return (*hadoopJobPtrType)(v)
}

func (*hadoopJobPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**HadoopJob)(nil)).Elem()
}

func (i *hadoopJobPtrType) ToHadoopJobPtrOutput() HadoopJobPtrOutput {
	return i.ToHadoopJobPtrOutputWithContext(context.Background())
}

func (i *hadoopJobPtrType) ToHadoopJobPtrOutputWithContext(ctx context.Context) HadoopJobPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(HadoopJobPtrOutput)
}

// A Dataproc job for running Apache Hadoop MapReduce (https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html) jobs on Apache Hadoop YARN (https://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-site/YARN.html).
type HadoopJobOutput struct{ *pulumi.OutputState }

func (HadoopJobOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*HadoopJob)(nil)).Elem()
}

func (o HadoopJobOutput) ToHadoopJobOutput() HadoopJobOutput {
	return o
}

func (o HadoopJobOutput) ToHadoopJobOutputWithContext(ctx context.Context) HadoopJobOutput {
	return o
}

func (o HadoopJobOutput) ToHadoopJobPtrOutput() HadoopJobPtrOutput {
	return o.ToHadoopJobPtrOutputWithContext(context.Background())
}

func (o HadoopJobOutput) ToHadoopJobPtrOutputWithContext(ctx context.Context) HadoopJobPtrOutput {
	return o.ApplyT(func(v HadoopJob) *HadoopJob {
		return &v
	}).(HadoopJobPtrOutput)
}

// Optional. HCFS URIs of archives to be extracted in the working directory of Hadoop drivers and tasks. Supported file types: .jar, .tar, .tar.gz, .tgz, or .zip.
func (o HadoopJobOutput) ArchiveUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v HadoopJob) []string { return v.ArchiveUris }).(pulumi.StringArrayOutput)
}

// Optional. The arguments to pass to the driver. Do not include arguments, such as -libjars or -Dfoo=bar, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
func (o HadoopJobOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v HadoopJob) []string { return v.Args }).(pulumi.StringArrayOutput)
}

// Optional. HCFS (Hadoop Compatible Filesystem) URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.
func (o HadoopJobOutput) FileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v HadoopJob) []string { return v.FileUris }).(pulumi.StringArrayOutput)
}

// Optional. Jar file URIs to add to the CLASSPATHs of the Hadoop driver and tasks.
func (o HadoopJobOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v HadoopJob) []string { return v.JarFileUris }).(pulumi.StringArrayOutput)
}

// Optional. The runtime log config for job execution.
func (o HadoopJobOutput) LoggingConfig() LoggingConfigPtrOutput {
	return o.ApplyT(func(v HadoopJob) *LoggingConfig { return v.LoggingConfig }).(LoggingConfigPtrOutput)
}

// The name of the driver's main class. The jar file containing the class must be in the default CLASSPATH or specified in jar_file_uris.
func (o HadoopJobOutput) MainClass() pulumi.StringPtrOutput {
	return o.ApplyT(func(v HadoopJob) *string { return v.MainClass }).(pulumi.StringPtrOutput)
}

// The HCFS URI of the jar file containing the main class. Examples: 'gs://foo-bucket/analytics-binaries/extract-useful-metrics-mr.jar' 'hdfs:/tmp/test-samples/custom-wordcount.jar' 'file:///home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'
func (o HadoopJobOutput) MainJarFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v HadoopJob) *string { return v.MainJarFileUri }).(pulumi.StringPtrOutput)
}

// Optional. A mapping of property names to values, used to configure Hadoop. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site and classes in user code.
func (o HadoopJobOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v HadoopJob) map[string]string { return v.Properties }).(pulumi.StringMapOutput)
}

type HadoopJobPtrOutput struct{ *pulumi.OutputState }

func (HadoopJobPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**HadoopJob)(nil)).Elem()
}

func (o HadoopJobPtrOutput) ToHadoopJobPtrOutput() HadoopJobPtrOutput {
	return o
}

func (o HadoopJobPtrOutput) ToHadoopJobPtrOutputWithContext(ctx context.Context) HadoopJobPtrOutput {
	return o
}

func (o HadoopJobPtrOutput) Elem() HadoopJobOutput {
	return o.ApplyT(func(v *HadoopJob) HadoopJob { return *v }).(HadoopJobOutput)
}

// Optional. HCFS URIs of archives to be extracted in the working directory of Hadoop drivers and tasks. Supported file types: .jar, .tar, .tar.gz, .tgz, or .zip.
func (o HadoopJobPtrOutput) ArchiveUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *HadoopJob) []string {
		if v == nil {
			return nil
		}
		return v.ArchiveUris
	}).(pulumi.StringArrayOutput)
}

// Optional. The arguments to pass to the driver. Do not include arguments, such as -libjars or -Dfoo=bar, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
func (o HadoopJobPtrOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *HadoopJob) []string {
		if v == nil {
			return nil
		}
		return v.Args
	}).(pulumi.StringArrayOutput)
}

// Optional. HCFS (Hadoop Compatible Filesystem) URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.
func (o HadoopJobPtrOutput) FileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *HadoopJob) []string {
		if v == nil {
			return nil
		}
		return v.FileUris
	}).(pulumi.StringArrayOutput)
}

// Optional. Jar file URIs to add to the CLASSPATHs of the Hadoop driver and tasks.
func (o HadoopJobPtrOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *HadoopJob) []string {
		if v == nil {
			return nil
		}
		return v.JarFileUris
	}).(pulumi.StringArrayOutput)
}

// Optional. The runtime log config for job execution.
func (o HadoopJobPtrOutput) LoggingConfig() LoggingConfigPtrOutput {
	return o.ApplyT(func(v *HadoopJob) *LoggingConfig {
		if v == nil {
			return nil
		}
		return v.LoggingConfig
	}).(LoggingConfigPtrOutput)
}

// The name of the driver's main class. The jar file containing the class must be in the default CLASSPATH or specified in jar_file_uris.
func (o HadoopJobPtrOutput) MainClass() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *HadoopJob) *string {
		if v == nil {
			return nil
		}
		return v.MainClass
	}).(pulumi.StringPtrOutput)
}

// The HCFS URI of the jar file containing the main class. Examples: 'gs://foo-bucket/analytics-binaries/extract-useful-metrics-mr.jar' 'hdfs:/tmp/test-samples/custom-wordcount.jar' 'file:///home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'
func (o HadoopJobPtrOutput) MainJarFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *HadoopJob) *string {
		if v == nil {
			return nil
		}
		return v.MainJarFileUri
	}).(pulumi.StringPtrOutput)
}

// Optional. A mapping of property names to values, used to configure Hadoop. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site and classes in user code.
func (o HadoopJobPtrOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v *HadoopJob) map[string]string {
		if v == nil {
			return nil
		}
		return v.Properties
	}).(pulumi.StringMapOutput)
}

// A Dataproc job for running Apache Hive (https://hive.apache.org/) queries on YARN.
type HiveJob struct {
	// Optional. Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries.
	ContinueOnFailure *bool `pulumi:"continueOnFailure"`
	// Optional. HCFS URIs of jar files to add to the CLASSPATH of the Hive server and Hadoop MapReduce (MR) tasks. Can contain Hive SerDes and UDFs.
	JarFileUris []string `pulumi:"jarFileUris"`
	// Optional. A mapping of property names and values, used to configure Hive. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site.xml, /etc/hive/conf/hive-site.xml, and classes in user code.
	Properties map[string]string `pulumi:"properties"`
	// The HCFS URI of the script that contains Hive queries.
	QueryFileUri *string `pulumi:"queryFileUri"`
	// A list of queries.
	QueryList *QueryList `pulumi:"queryList"`
	// Optional. Mapping of query variable names to values (equivalent to the Hive command: SET name="value";).
	ScriptVariables map[string]string `pulumi:"scriptVariables"`
}

// HiveJobInput is an input type that accepts HiveJobArgs and HiveJobOutput values.
// You can construct a concrete instance of `HiveJobInput` via:
//
//          HiveJobArgs{...}
type HiveJobInput interface {
	pulumi.Input

	ToHiveJobOutput() HiveJobOutput
	ToHiveJobOutputWithContext(context.Context) HiveJobOutput
}

// A Dataproc job for running Apache Hive (https://hive.apache.org/) queries on YARN.
type HiveJobArgs struct {
	// Optional. Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries.
	ContinueOnFailure pulumi.BoolPtrInput `pulumi:"continueOnFailure"`
	// Optional. HCFS URIs of jar files to add to the CLASSPATH of the Hive server and Hadoop MapReduce (MR) tasks. Can contain Hive SerDes and UDFs.
	JarFileUris pulumi.StringArrayInput `pulumi:"jarFileUris"`
	// Optional. A mapping of property names and values, used to configure Hive. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site.xml, /etc/hive/conf/hive-site.xml, and classes in user code.
	Properties pulumi.StringMapInput `pulumi:"properties"`
	// The HCFS URI of the script that contains Hive queries.
	QueryFileUri pulumi.StringPtrInput `pulumi:"queryFileUri"`
	// A list of queries.
	QueryList QueryListPtrInput `pulumi:"queryList"`
	// Optional. Mapping of query variable names to values (equivalent to the Hive command: SET name="value";).
	ScriptVariables pulumi.StringMapInput `pulumi:"scriptVariables"`
}

func (HiveJobArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*HiveJob)(nil)).Elem()
}

func (i HiveJobArgs) ToHiveJobOutput() HiveJobOutput {
	return i.ToHiveJobOutputWithContext(context.Background())
}

func (i HiveJobArgs) ToHiveJobOutputWithContext(ctx context.Context) HiveJobOutput {
	return pulumi.ToOutputWithContext(ctx, i).(HiveJobOutput)
}

func (i HiveJobArgs) ToHiveJobPtrOutput() HiveJobPtrOutput {
	return i.ToHiveJobPtrOutputWithContext(context.Background())
}

func (i HiveJobArgs) ToHiveJobPtrOutputWithContext(ctx context.Context) HiveJobPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(HiveJobOutput).ToHiveJobPtrOutputWithContext(ctx)
}

// HiveJobPtrInput is an input type that accepts HiveJobArgs, HiveJobPtr and HiveJobPtrOutput values.
// You can construct a concrete instance of `HiveJobPtrInput` via:
//
//          HiveJobArgs{...}
//
//  or:
//
//          nil
type HiveJobPtrInput interface {
	pulumi.Input

	ToHiveJobPtrOutput() HiveJobPtrOutput
	ToHiveJobPtrOutputWithContext(context.Context) HiveJobPtrOutput
}

type hiveJobPtrType HiveJobArgs

func HiveJobPtr(v *HiveJobArgs) HiveJobPtrInput {
	return (*hiveJobPtrType)(v)
}

func (*hiveJobPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**HiveJob)(nil)).Elem()
}

func (i *hiveJobPtrType) ToHiveJobPtrOutput() HiveJobPtrOutput {
	return i.ToHiveJobPtrOutputWithContext(context.Background())
}

func (i *hiveJobPtrType) ToHiveJobPtrOutputWithContext(ctx context.Context) HiveJobPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(HiveJobPtrOutput)
}

// A Dataproc job for running Apache Hive (https://hive.apache.org/) queries on YARN.
type HiveJobOutput struct{ *pulumi.OutputState }

func (HiveJobOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*HiveJob)(nil)).Elem()
}

func (o HiveJobOutput) ToHiveJobOutput() HiveJobOutput {
	return o
}

func (o HiveJobOutput) ToHiveJobOutputWithContext(ctx context.Context) HiveJobOutput {
	return o
}

func (o HiveJobOutput) ToHiveJobPtrOutput() HiveJobPtrOutput {
	return o.ToHiveJobPtrOutputWithContext(context.Background())
}

func (o HiveJobOutput) ToHiveJobPtrOutputWithContext(ctx context.Context) HiveJobPtrOutput {
	return o.ApplyT(func(v HiveJob) *HiveJob {
		return &v
	}).(HiveJobPtrOutput)
}

// Optional. Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries.
func (o HiveJobOutput) ContinueOnFailure() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v HiveJob) *bool { return v.ContinueOnFailure }).(pulumi.BoolPtrOutput)
}

// Optional. HCFS URIs of jar files to add to the CLASSPATH of the Hive server and Hadoop MapReduce (MR) tasks. Can contain Hive SerDes and UDFs.
func (o HiveJobOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v HiveJob) []string { return v.JarFileUris }).(pulumi.StringArrayOutput)
}

// Optional. A mapping of property names and values, used to configure Hive. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site.xml, /etc/hive/conf/hive-site.xml, and classes in user code.
func (o HiveJobOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v HiveJob) map[string]string { return v.Properties }).(pulumi.StringMapOutput)
}

// The HCFS URI of the script that contains Hive queries.
func (o HiveJobOutput) QueryFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v HiveJob) *string { return v.QueryFileUri }).(pulumi.StringPtrOutput)
}

// A list of queries.
func (o HiveJobOutput) QueryList() QueryListPtrOutput {
	return o.ApplyT(func(v HiveJob) *QueryList { return v.QueryList }).(QueryListPtrOutput)
}

// Optional. Mapping of query variable names to values (equivalent to the Hive command: SET name="value";).
func (o HiveJobOutput) ScriptVariables() pulumi.StringMapOutput {
	return o.ApplyT(func(v HiveJob) map[string]string { return v.ScriptVariables }).(pulumi.StringMapOutput)
}

type HiveJobPtrOutput struct{ *pulumi.OutputState }

func (HiveJobPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**HiveJob)(nil)).Elem()
}

func (o HiveJobPtrOutput) ToHiveJobPtrOutput() HiveJobPtrOutput {
	return o
}

func (o HiveJobPtrOutput) ToHiveJobPtrOutputWithContext(ctx context.Context) HiveJobPtrOutput {
	return o
}

func (o HiveJobPtrOutput) Elem() HiveJobOutput {
	return o.ApplyT(func(v *HiveJob) HiveJob { return *v }).(HiveJobOutput)
}

// Optional. Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries.
func (o HiveJobPtrOutput) ContinueOnFailure() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *HiveJob) *bool {
		if v == nil {
			return nil
		}
		return v.ContinueOnFailure
	}).(pulumi.BoolPtrOutput)
}

// Optional. HCFS URIs of jar files to add to the CLASSPATH of the Hive server and Hadoop MapReduce (MR) tasks. Can contain Hive SerDes and UDFs.
func (o HiveJobPtrOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *HiveJob) []string {
		if v == nil {
			return nil
		}
		return v.JarFileUris
	}).(pulumi.StringArrayOutput)
}

// Optional. A mapping of property names and values, used to configure Hive. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site.xml, /etc/hive/conf/hive-site.xml, and classes in user code.
func (o HiveJobPtrOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v *HiveJob) map[string]string {
		if v == nil {
			return nil
		}
		return v.Properties
	}).(pulumi.StringMapOutput)
}

// The HCFS URI of the script that contains Hive queries.
func (o HiveJobPtrOutput) QueryFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *HiveJob) *string {
		if v == nil {
			return nil
		}
		return v.QueryFileUri
	}).(pulumi.StringPtrOutput)
}

// A list of queries.
func (o HiveJobPtrOutput) QueryList() QueryListPtrOutput {
	return o.ApplyT(func(v *HiveJob) *QueryList {
		if v == nil {
			return nil
		}
		return v.QueryList
	}).(QueryListPtrOutput)
}

// Optional. Mapping of query variable names to values (equivalent to the Hive command: SET name="value";).
func (o HiveJobPtrOutput) ScriptVariables() pulumi.StringMapOutput {
	return o.ApplyT(func(v *HiveJob) map[string]string {
		if v == nil {
			return nil
		}
		return v.ScriptVariables
	}).(pulumi.StringMapOutput)
}

// Configuration for the size bounds of an instance group, including its proportional size to other groups.
type InstanceGroupAutoscalingPolicyConfig struct {
	// Optional. Maximum number of instances for this group. Required for primary workers. Note that by default, clusters will not use secondary workers. Required for secondary workers if the minimum secondary instances is set.Primary workers - Bounds: [min_instances, ). Required. Secondary workers - Bounds: [min_instances, ). Default: 0.
	MaxInstances *int `pulumi:"maxInstances"`
	// Optional. Minimum number of instances for this group.Primary workers - Bounds: 2, max_instances. Default: 2. Secondary workers - Bounds: 0, max_instances. Default: 0.
	MinInstances *int `pulumi:"minInstances"`
	// Optional. Weight for the instance group, which is used to determine the fraction of total workers in the cluster from this instance group. For example, if primary workers have weight 2, and secondary workers have weight 1, the cluster will have approximately 2 primary workers for each secondary worker.The cluster may not reach the specified balance if constrained by min/max bounds or other autoscaling settings. For example, if max_instances for secondary workers is 0, then only primary workers will be added. The cluster can also be out of balance when created.If weight is not set on any instance group, the cluster will default to equal weight for all groups: the cluster will attempt to maintain an equal number of workers in each group within the configured size bounds for each group. If weight is set for one group only, the cluster will default to zero weight on the unset group. For example if weight is set only on primary workers, the cluster will use primary workers only and no secondary workers.
	Weight *int `pulumi:"weight"`
}

// InstanceGroupAutoscalingPolicyConfigInput is an input type that accepts InstanceGroupAutoscalingPolicyConfigArgs and InstanceGroupAutoscalingPolicyConfigOutput values.
// You can construct a concrete instance of `InstanceGroupAutoscalingPolicyConfigInput` via:
//
//          InstanceGroupAutoscalingPolicyConfigArgs{...}
type InstanceGroupAutoscalingPolicyConfigInput interface {
	pulumi.Input

	ToInstanceGroupAutoscalingPolicyConfigOutput() InstanceGroupAutoscalingPolicyConfigOutput
	ToInstanceGroupAutoscalingPolicyConfigOutputWithContext(context.Context) InstanceGroupAutoscalingPolicyConfigOutput
}

// Configuration for the size bounds of an instance group, including its proportional size to other groups.
type InstanceGroupAutoscalingPolicyConfigArgs struct {
	// Optional. Maximum number of instances for this group. Required for primary workers. Note that by default, clusters will not use secondary workers. Required for secondary workers if the minimum secondary instances is set.Primary workers - Bounds: [min_instances, ). Required. Secondary workers - Bounds: [min_instances, ). Default: 0.
	MaxInstances pulumi.IntPtrInput `pulumi:"maxInstances"`
	// Optional. Minimum number of instances for this group.Primary workers - Bounds: 2, max_instances. Default: 2. Secondary workers - Bounds: 0, max_instances. Default: 0.
	MinInstances pulumi.IntPtrInput `pulumi:"minInstances"`
	// Optional. Weight for the instance group, which is used to determine the fraction of total workers in the cluster from this instance group. For example, if primary workers have weight 2, and secondary workers have weight 1, the cluster will have approximately 2 primary workers for each secondary worker.The cluster may not reach the specified balance if constrained by min/max bounds or other autoscaling settings. For example, if max_instances for secondary workers is 0, then only primary workers will be added. The cluster can also be out of balance when created.If weight is not set on any instance group, the cluster will default to equal weight for all groups: the cluster will attempt to maintain an equal number of workers in each group within the configured size bounds for each group. If weight is set for one group only, the cluster will default to zero weight on the unset group. For example if weight is set only on primary workers, the cluster will use primary workers only and no secondary workers.
	Weight pulumi.IntPtrInput `pulumi:"weight"`
}

func (InstanceGroupAutoscalingPolicyConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*InstanceGroupAutoscalingPolicyConfig)(nil)).Elem()
}

func (i InstanceGroupAutoscalingPolicyConfigArgs) ToInstanceGroupAutoscalingPolicyConfigOutput() InstanceGroupAutoscalingPolicyConfigOutput {
	return i.ToInstanceGroupAutoscalingPolicyConfigOutputWithContext(context.Background())
}

func (i InstanceGroupAutoscalingPolicyConfigArgs) ToInstanceGroupAutoscalingPolicyConfigOutputWithContext(ctx context.Context) InstanceGroupAutoscalingPolicyConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(InstanceGroupAutoscalingPolicyConfigOutput)
}

func (i InstanceGroupAutoscalingPolicyConfigArgs) ToInstanceGroupAutoscalingPolicyConfigPtrOutput() InstanceGroupAutoscalingPolicyConfigPtrOutput {
	return i.ToInstanceGroupAutoscalingPolicyConfigPtrOutputWithContext(context.Background())
}

func (i InstanceGroupAutoscalingPolicyConfigArgs) ToInstanceGroupAutoscalingPolicyConfigPtrOutputWithContext(ctx context.Context) InstanceGroupAutoscalingPolicyConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(InstanceGroupAutoscalingPolicyConfigOutput).ToInstanceGroupAutoscalingPolicyConfigPtrOutputWithContext(ctx)
}

// InstanceGroupAutoscalingPolicyConfigPtrInput is an input type that accepts InstanceGroupAutoscalingPolicyConfigArgs, InstanceGroupAutoscalingPolicyConfigPtr and InstanceGroupAutoscalingPolicyConfigPtrOutput values.
// You can construct a concrete instance of `InstanceGroupAutoscalingPolicyConfigPtrInput` via:
//
//          InstanceGroupAutoscalingPolicyConfigArgs{...}
//
//  or:
//
//          nil
type InstanceGroupAutoscalingPolicyConfigPtrInput interface {
	pulumi.Input

	ToInstanceGroupAutoscalingPolicyConfigPtrOutput() InstanceGroupAutoscalingPolicyConfigPtrOutput
	ToInstanceGroupAutoscalingPolicyConfigPtrOutputWithContext(context.Context) InstanceGroupAutoscalingPolicyConfigPtrOutput
}

type instanceGroupAutoscalingPolicyConfigPtrType InstanceGroupAutoscalingPolicyConfigArgs

func InstanceGroupAutoscalingPolicyConfigPtr(v *InstanceGroupAutoscalingPolicyConfigArgs) InstanceGroupAutoscalingPolicyConfigPtrInput {
	return (*instanceGroupAutoscalingPolicyConfigPtrType)(v)
}

func (*instanceGroupAutoscalingPolicyConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**InstanceGroupAutoscalingPolicyConfig)(nil)).Elem()
}

func (i *instanceGroupAutoscalingPolicyConfigPtrType) ToInstanceGroupAutoscalingPolicyConfigPtrOutput() InstanceGroupAutoscalingPolicyConfigPtrOutput {
	return i.ToInstanceGroupAutoscalingPolicyConfigPtrOutputWithContext(context.Background())
}

func (i *instanceGroupAutoscalingPolicyConfigPtrType) ToInstanceGroupAutoscalingPolicyConfigPtrOutputWithContext(ctx context.Context) InstanceGroupAutoscalingPolicyConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(InstanceGroupAutoscalingPolicyConfigPtrOutput)
}

// Configuration for the size bounds of an instance group, including its proportional size to other groups.
type InstanceGroupAutoscalingPolicyConfigOutput struct{ *pulumi.OutputState }

func (InstanceGroupAutoscalingPolicyConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*InstanceGroupAutoscalingPolicyConfig)(nil)).Elem()
}

func (o InstanceGroupAutoscalingPolicyConfigOutput) ToInstanceGroupAutoscalingPolicyConfigOutput() InstanceGroupAutoscalingPolicyConfigOutput {
	return o
}

func (o InstanceGroupAutoscalingPolicyConfigOutput) ToInstanceGroupAutoscalingPolicyConfigOutputWithContext(ctx context.Context) InstanceGroupAutoscalingPolicyConfigOutput {
	return o
}

func (o InstanceGroupAutoscalingPolicyConfigOutput) ToInstanceGroupAutoscalingPolicyConfigPtrOutput() InstanceGroupAutoscalingPolicyConfigPtrOutput {
	return o.ToInstanceGroupAutoscalingPolicyConfigPtrOutputWithContext(context.Background())
}

func (o InstanceGroupAutoscalingPolicyConfigOutput) ToInstanceGroupAutoscalingPolicyConfigPtrOutputWithContext(ctx context.Context) InstanceGroupAutoscalingPolicyConfigPtrOutput {
	return o.ApplyT(func(v InstanceGroupAutoscalingPolicyConfig) *InstanceGroupAutoscalingPolicyConfig {
		return &v
	}).(InstanceGroupAutoscalingPolicyConfigPtrOutput)
}

// Optional. Maximum number of instances for this group. Required for primary workers. Note that by default, clusters will not use secondary workers. Required for secondary workers if the minimum secondary instances is set.Primary workers - Bounds: [min_instances, ). Required. Secondary workers - Bounds: [min_instances, ). Default: 0.
func (o InstanceGroupAutoscalingPolicyConfigOutput) MaxInstances() pulumi.IntPtrOutput {
	return o.ApplyT(func(v InstanceGroupAutoscalingPolicyConfig) *int { return v.MaxInstances }).(pulumi.IntPtrOutput)
}

// Optional. Minimum number of instances for this group.Primary workers - Bounds: 2, max_instances. Default: 2. Secondary workers - Bounds: 0, max_instances. Default: 0.
func (o InstanceGroupAutoscalingPolicyConfigOutput) MinInstances() pulumi.IntPtrOutput {
	return o.ApplyT(func(v InstanceGroupAutoscalingPolicyConfig) *int { return v.MinInstances }).(pulumi.IntPtrOutput)
}

// Optional. Weight for the instance group, which is used to determine the fraction of total workers in the cluster from this instance group. For example, if primary workers have weight 2, and secondary workers have weight 1, the cluster will have approximately 2 primary workers for each secondary worker.The cluster may not reach the specified balance if constrained by min/max bounds or other autoscaling settings. For example, if max_instances for secondary workers is 0, then only primary workers will be added. The cluster can also be out of balance when created.If weight is not set on any instance group, the cluster will default to equal weight for all groups: the cluster will attempt to maintain an equal number of workers in each group within the configured size bounds for each group. If weight is set for one group only, the cluster will default to zero weight on the unset group. For example if weight is set only on primary workers, the cluster will use primary workers only and no secondary workers.
func (o InstanceGroupAutoscalingPolicyConfigOutput) Weight() pulumi.IntPtrOutput {
	return o.ApplyT(func(v InstanceGroupAutoscalingPolicyConfig) *int { return v.Weight }).(pulumi.IntPtrOutput)
}

type InstanceGroupAutoscalingPolicyConfigPtrOutput struct{ *pulumi.OutputState }

func (InstanceGroupAutoscalingPolicyConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**InstanceGroupAutoscalingPolicyConfig)(nil)).Elem()
}

func (o InstanceGroupAutoscalingPolicyConfigPtrOutput) ToInstanceGroupAutoscalingPolicyConfigPtrOutput() InstanceGroupAutoscalingPolicyConfigPtrOutput {
	return o
}

func (o InstanceGroupAutoscalingPolicyConfigPtrOutput) ToInstanceGroupAutoscalingPolicyConfigPtrOutputWithContext(ctx context.Context) InstanceGroupAutoscalingPolicyConfigPtrOutput {
	return o
}

func (o InstanceGroupAutoscalingPolicyConfigPtrOutput) Elem() InstanceGroupAutoscalingPolicyConfigOutput {
	return o.ApplyT(func(v *InstanceGroupAutoscalingPolicyConfig) InstanceGroupAutoscalingPolicyConfig { return *v }).(InstanceGroupAutoscalingPolicyConfigOutput)
}

// Optional. Maximum number of instances for this group. Required for primary workers. Note that by default, clusters will not use secondary workers. Required for secondary workers if the minimum secondary instances is set.Primary workers - Bounds: [min_instances, ). Required. Secondary workers - Bounds: [min_instances, ). Default: 0.
func (o InstanceGroupAutoscalingPolicyConfigPtrOutput) MaxInstances() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *InstanceGroupAutoscalingPolicyConfig) *int {
		if v == nil {
			return nil
		}
		return v.MaxInstances
	}).(pulumi.IntPtrOutput)
}

// Optional. Minimum number of instances for this group.Primary workers - Bounds: 2, max_instances. Default: 2. Secondary workers - Bounds: 0, max_instances. Default: 0.
func (o InstanceGroupAutoscalingPolicyConfigPtrOutput) MinInstances() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *InstanceGroupAutoscalingPolicyConfig) *int {
		if v == nil {
			return nil
		}
		return v.MinInstances
	}).(pulumi.IntPtrOutput)
}

// Optional. Weight for the instance group, which is used to determine the fraction of total workers in the cluster from this instance group. For example, if primary workers have weight 2, and secondary workers have weight 1, the cluster will have approximately 2 primary workers for each secondary worker.The cluster may not reach the specified balance if constrained by min/max bounds or other autoscaling settings. For example, if max_instances for secondary workers is 0, then only primary workers will be added. The cluster can also be out of balance when created.If weight is not set on any instance group, the cluster will default to equal weight for all groups: the cluster will attempt to maintain an equal number of workers in each group within the configured size bounds for each group. If weight is set for one group only, the cluster will default to zero weight on the unset group. For example if weight is set only on primary workers, the cluster will use primary workers only and no secondary workers.
func (o InstanceGroupAutoscalingPolicyConfigPtrOutput) Weight() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *InstanceGroupAutoscalingPolicyConfig) *int {
		if v == nil {
			return nil
		}
		return v.Weight
	}).(pulumi.IntPtrOutput)
}

// The config settings for Compute Engine resources in an instance group, such as a master or worker group.
type InstanceGroupConfig struct {
	// Optional. The Compute Engine accelerator configuration for these instances.
	Accelerators []AcceleratorConfig `pulumi:"accelerators"`
	// Optional. Disk option config settings.
	DiskConfig *DiskConfig `pulumi:"diskConfig"`
	// Optional. The Compute Engine image resource used for cluster instances.The URI can represent an image or image family.Image examples: https://www.googleapis.com/compute/beta/projects/[project_id]/global/images/[image-id] projects/[project_id]/global/images/[image-id] image-idImage family examples. Dataproc will use the most recent image from the family: https://www.googleapis.com/compute/beta/projects/[project_id]/global/images/family/[custom-image-family-name] projects/[project_id]/global/images/family/[custom-image-family-name]If the URI is unspecified, it will be inferred from SoftwareConfig.image_version or the system default.
	ImageUri *string `pulumi:"imageUri"`
	// Output only. The list of instance names. Dataproc derives the names from cluster_name, num_instances, and the instance group.
	InstanceNames []string `pulumi:"instanceNames"`
	// Output only. List of references to Compute Engine instances.
	InstanceReferences []InstanceReference `pulumi:"instanceReferences"`
	// Output only. Specifies that this instance group contains preemptible instances.
	IsPreemptible *bool `pulumi:"isPreemptible"`
	// Optional. The Compute Engine machine type used for cluster instances.A full URL, partial URI, or short name are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/zones/us-east1-a/machineTypes/n1-standard-2 projects/[project_id]/zones/us-east1-a/machineTypes/n1-standard-2 n1-standard-2Auto Zone Exception: If you are using the Dataproc Auto Zone Placement (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement) feature, you must use the short name of the machine type resource, for example, n1-standard-2.
	MachineTypeUri *string `pulumi:"machineTypeUri"`
	// Output only. The config for Compute Engine Instance Group Manager that manages this group. This is only used for preemptible instance groups.
	ManagedGroupConfig *ManagedGroupConfig `pulumi:"managedGroupConfig"`
	// Specifies the minimum cpu platform for the Instance Group. See Dataproc -> Minimum CPU Platform (https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
	MinCpuPlatform *string `pulumi:"minCpuPlatform"`
	// Optional. The number of VM instances in the instance group. For HA cluster master_config groups, must be set to 3. For standard cluster master_config groups, must be set to 1.
	NumInstances *int `pulumi:"numInstances"`
	// Optional. Specifies the preemptibility of the instance group.The default value for master and worker groups is NON_PREEMPTIBLE. This default cannot be changed.The default value for secondary instances is PREEMPTIBLE.
	Preemptibility *string `pulumi:"preemptibility"`
}

// InstanceGroupConfigInput is an input type that accepts InstanceGroupConfigArgs and InstanceGroupConfigOutput values.
// You can construct a concrete instance of `InstanceGroupConfigInput` via:
//
//          InstanceGroupConfigArgs{...}
type InstanceGroupConfigInput interface {
	pulumi.Input

	ToInstanceGroupConfigOutput() InstanceGroupConfigOutput
	ToInstanceGroupConfigOutputWithContext(context.Context) InstanceGroupConfigOutput
}

// The config settings for Compute Engine resources in an instance group, such as a master or worker group.
type InstanceGroupConfigArgs struct {
	// Optional. The Compute Engine accelerator configuration for these instances.
	Accelerators AcceleratorConfigArrayInput `pulumi:"accelerators"`
	// Optional. Disk option config settings.
	DiskConfig DiskConfigPtrInput `pulumi:"diskConfig"`
	// Optional. The Compute Engine image resource used for cluster instances.The URI can represent an image or image family.Image examples: https://www.googleapis.com/compute/beta/projects/[project_id]/global/images/[image-id] projects/[project_id]/global/images/[image-id] image-idImage family examples. Dataproc will use the most recent image from the family: https://www.googleapis.com/compute/beta/projects/[project_id]/global/images/family/[custom-image-family-name] projects/[project_id]/global/images/family/[custom-image-family-name]If the URI is unspecified, it will be inferred from SoftwareConfig.image_version or the system default.
	ImageUri pulumi.StringPtrInput `pulumi:"imageUri"`
	// Output only. The list of instance names. Dataproc derives the names from cluster_name, num_instances, and the instance group.
	InstanceNames pulumi.StringArrayInput `pulumi:"instanceNames"`
	// Output only. List of references to Compute Engine instances.
	InstanceReferences InstanceReferenceArrayInput `pulumi:"instanceReferences"`
	// Output only. Specifies that this instance group contains preemptible instances.
	IsPreemptible pulumi.BoolPtrInput `pulumi:"isPreemptible"`
	// Optional. The Compute Engine machine type used for cluster instances.A full URL, partial URI, or short name are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/zones/us-east1-a/machineTypes/n1-standard-2 projects/[project_id]/zones/us-east1-a/machineTypes/n1-standard-2 n1-standard-2Auto Zone Exception: If you are using the Dataproc Auto Zone Placement (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement) feature, you must use the short name of the machine type resource, for example, n1-standard-2.
	MachineTypeUri pulumi.StringPtrInput `pulumi:"machineTypeUri"`
	// Output only. The config for Compute Engine Instance Group Manager that manages this group. This is only used for preemptible instance groups.
	ManagedGroupConfig ManagedGroupConfigPtrInput `pulumi:"managedGroupConfig"`
	// Specifies the minimum cpu platform for the Instance Group. See Dataproc -> Minimum CPU Platform (https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
	MinCpuPlatform pulumi.StringPtrInput `pulumi:"minCpuPlatform"`
	// Optional. The number of VM instances in the instance group. For HA cluster master_config groups, must be set to 3. For standard cluster master_config groups, must be set to 1.
	NumInstances pulumi.IntPtrInput `pulumi:"numInstances"`
	// Optional. Specifies the preemptibility of the instance group.The default value for master and worker groups is NON_PREEMPTIBLE. This default cannot be changed.The default value for secondary instances is PREEMPTIBLE.
	Preemptibility pulumi.StringPtrInput `pulumi:"preemptibility"`
}

func (InstanceGroupConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*InstanceGroupConfig)(nil)).Elem()
}

func (i InstanceGroupConfigArgs) ToInstanceGroupConfigOutput() InstanceGroupConfigOutput {
	return i.ToInstanceGroupConfigOutputWithContext(context.Background())
}

func (i InstanceGroupConfigArgs) ToInstanceGroupConfigOutputWithContext(ctx context.Context) InstanceGroupConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(InstanceGroupConfigOutput)
}

func (i InstanceGroupConfigArgs) ToInstanceGroupConfigPtrOutput() InstanceGroupConfigPtrOutput {
	return i.ToInstanceGroupConfigPtrOutputWithContext(context.Background())
}

func (i InstanceGroupConfigArgs) ToInstanceGroupConfigPtrOutputWithContext(ctx context.Context) InstanceGroupConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(InstanceGroupConfigOutput).ToInstanceGroupConfigPtrOutputWithContext(ctx)
}

// InstanceGroupConfigPtrInput is an input type that accepts InstanceGroupConfigArgs, InstanceGroupConfigPtr and InstanceGroupConfigPtrOutput values.
// You can construct a concrete instance of `InstanceGroupConfigPtrInput` via:
//
//          InstanceGroupConfigArgs{...}
//
//  or:
//
//          nil
type InstanceGroupConfigPtrInput interface {
	pulumi.Input

	ToInstanceGroupConfigPtrOutput() InstanceGroupConfigPtrOutput
	ToInstanceGroupConfigPtrOutputWithContext(context.Context) InstanceGroupConfigPtrOutput
}

type instanceGroupConfigPtrType InstanceGroupConfigArgs

func InstanceGroupConfigPtr(v *InstanceGroupConfigArgs) InstanceGroupConfigPtrInput {
	return (*instanceGroupConfigPtrType)(v)
}

func (*instanceGroupConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**InstanceGroupConfig)(nil)).Elem()
}

func (i *instanceGroupConfigPtrType) ToInstanceGroupConfigPtrOutput() InstanceGroupConfigPtrOutput {
	return i.ToInstanceGroupConfigPtrOutputWithContext(context.Background())
}

func (i *instanceGroupConfigPtrType) ToInstanceGroupConfigPtrOutputWithContext(ctx context.Context) InstanceGroupConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(InstanceGroupConfigPtrOutput)
}

// The config settings for Compute Engine resources in an instance group, such as a master or worker group.
type InstanceGroupConfigOutput struct{ *pulumi.OutputState }

func (InstanceGroupConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*InstanceGroupConfig)(nil)).Elem()
}

func (o InstanceGroupConfigOutput) ToInstanceGroupConfigOutput() InstanceGroupConfigOutput {
	return o
}

func (o InstanceGroupConfigOutput) ToInstanceGroupConfigOutputWithContext(ctx context.Context) InstanceGroupConfigOutput {
	return o
}

func (o InstanceGroupConfigOutput) ToInstanceGroupConfigPtrOutput() InstanceGroupConfigPtrOutput {
	return o.ToInstanceGroupConfigPtrOutputWithContext(context.Background())
}

func (o InstanceGroupConfigOutput) ToInstanceGroupConfigPtrOutputWithContext(ctx context.Context) InstanceGroupConfigPtrOutput {
	return o.ApplyT(func(v InstanceGroupConfig) *InstanceGroupConfig {
		return &v
	}).(InstanceGroupConfigPtrOutput)
}

// Optional. The Compute Engine accelerator configuration for these instances.
func (o InstanceGroupConfigOutput) Accelerators() AcceleratorConfigArrayOutput {
	return o.ApplyT(func(v InstanceGroupConfig) []AcceleratorConfig { return v.Accelerators }).(AcceleratorConfigArrayOutput)
}

// Optional. Disk option config settings.
func (o InstanceGroupConfigOutput) DiskConfig() DiskConfigPtrOutput {
	return o.ApplyT(func(v InstanceGroupConfig) *DiskConfig { return v.DiskConfig }).(DiskConfigPtrOutput)
}

// Optional. The Compute Engine image resource used for cluster instances.The URI can represent an image or image family.Image examples: https://www.googleapis.com/compute/beta/projects/[project_id]/global/images/[image-id] projects/[project_id]/global/images/[image-id] image-idImage family examples. Dataproc will use the most recent image from the family: https://www.googleapis.com/compute/beta/projects/[project_id]/global/images/family/[custom-image-family-name] projects/[project_id]/global/images/family/[custom-image-family-name]If the URI is unspecified, it will be inferred from SoftwareConfig.image_version or the system default.
func (o InstanceGroupConfigOutput) ImageUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v InstanceGroupConfig) *string { return v.ImageUri }).(pulumi.StringPtrOutput)
}

// Output only. The list of instance names. Dataproc derives the names from cluster_name, num_instances, and the instance group.
func (o InstanceGroupConfigOutput) InstanceNames() pulumi.StringArrayOutput {
	return o.ApplyT(func(v InstanceGroupConfig) []string { return v.InstanceNames }).(pulumi.StringArrayOutput)
}

// Output only. List of references to Compute Engine instances.
func (o InstanceGroupConfigOutput) InstanceReferences() InstanceReferenceArrayOutput {
	return o.ApplyT(func(v InstanceGroupConfig) []InstanceReference { return v.InstanceReferences }).(InstanceReferenceArrayOutput)
}

// Output only. Specifies that this instance group contains preemptible instances.
func (o InstanceGroupConfigOutput) IsPreemptible() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v InstanceGroupConfig) *bool { return v.IsPreemptible }).(pulumi.BoolPtrOutput)
}

// Optional. The Compute Engine machine type used for cluster instances.A full URL, partial URI, or short name are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/zones/us-east1-a/machineTypes/n1-standard-2 projects/[project_id]/zones/us-east1-a/machineTypes/n1-standard-2 n1-standard-2Auto Zone Exception: If you are using the Dataproc Auto Zone Placement (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement) feature, you must use the short name of the machine type resource, for example, n1-standard-2.
func (o InstanceGroupConfigOutput) MachineTypeUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v InstanceGroupConfig) *string { return v.MachineTypeUri }).(pulumi.StringPtrOutput)
}

// Output only. The config for Compute Engine Instance Group Manager that manages this group. This is only used for preemptible instance groups.
func (o InstanceGroupConfigOutput) ManagedGroupConfig() ManagedGroupConfigPtrOutput {
	return o.ApplyT(func(v InstanceGroupConfig) *ManagedGroupConfig { return v.ManagedGroupConfig }).(ManagedGroupConfigPtrOutput)
}

// Specifies the minimum cpu platform for the Instance Group. See Dataproc -> Minimum CPU Platform (https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
func (o InstanceGroupConfigOutput) MinCpuPlatform() pulumi.StringPtrOutput {
	return o.ApplyT(func(v InstanceGroupConfig) *string { return v.MinCpuPlatform }).(pulumi.StringPtrOutput)
}

// Optional. The number of VM instances in the instance group. For HA cluster master_config groups, must be set to 3. For standard cluster master_config groups, must be set to 1.
func (o InstanceGroupConfigOutput) NumInstances() pulumi.IntPtrOutput {
	return o.ApplyT(func(v InstanceGroupConfig) *int { return v.NumInstances }).(pulumi.IntPtrOutput)
}

// Optional. Specifies the preemptibility of the instance group.The default value for master and worker groups is NON_PREEMPTIBLE. This default cannot be changed.The default value for secondary instances is PREEMPTIBLE.
func (o InstanceGroupConfigOutput) Preemptibility() pulumi.StringPtrOutput {
	return o.ApplyT(func(v InstanceGroupConfig) *string { return v.Preemptibility }).(pulumi.StringPtrOutput)
}

type InstanceGroupConfigPtrOutput struct{ *pulumi.OutputState }

func (InstanceGroupConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**InstanceGroupConfig)(nil)).Elem()
}

func (o InstanceGroupConfigPtrOutput) ToInstanceGroupConfigPtrOutput() InstanceGroupConfigPtrOutput {
	return o
}

func (o InstanceGroupConfigPtrOutput) ToInstanceGroupConfigPtrOutputWithContext(ctx context.Context) InstanceGroupConfigPtrOutput {
	return o
}

func (o InstanceGroupConfigPtrOutput) Elem() InstanceGroupConfigOutput {
	return o.ApplyT(func(v *InstanceGroupConfig) InstanceGroupConfig { return *v }).(InstanceGroupConfigOutput)
}

// Optional. The Compute Engine accelerator configuration for these instances.
func (o InstanceGroupConfigPtrOutput) Accelerators() AcceleratorConfigArrayOutput {
	return o.ApplyT(func(v *InstanceGroupConfig) []AcceleratorConfig {
		if v == nil {
			return nil
		}
		return v.Accelerators
	}).(AcceleratorConfigArrayOutput)
}

// Optional. Disk option config settings.
func (o InstanceGroupConfigPtrOutput) DiskConfig() DiskConfigPtrOutput {
	return o.ApplyT(func(v *InstanceGroupConfig) *DiskConfig {
		if v == nil {
			return nil
		}
		return v.DiskConfig
	}).(DiskConfigPtrOutput)
}

// Optional. The Compute Engine image resource used for cluster instances.The URI can represent an image or image family.Image examples: https://www.googleapis.com/compute/beta/projects/[project_id]/global/images/[image-id] projects/[project_id]/global/images/[image-id] image-idImage family examples. Dataproc will use the most recent image from the family: https://www.googleapis.com/compute/beta/projects/[project_id]/global/images/family/[custom-image-family-name] projects/[project_id]/global/images/family/[custom-image-family-name]If the URI is unspecified, it will be inferred from SoftwareConfig.image_version or the system default.
func (o InstanceGroupConfigPtrOutput) ImageUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *InstanceGroupConfig) *string {
		if v == nil {
			return nil
		}
		return v.ImageUri
	}).(pulumi.StringPtrOutput)
}

// Output only. The list of instance names. Dataproc derives the names from cluster_name, num_instances, and the instance group.
func (o InstanceGroupConfigPtrOutput) InstanceNames() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *InstanceGroupConfig) []string {
		if v == nil {
			return nil
		}
		return v.InstanceNames
	}).(pulumi.StringArrayOutput)
}

// Output only. List of references to Compute Engine instances.
func (o InstanceGroupConfigPtrOutput) InstanceReferences() InstanceReferenceArrayOutput {
	return o.ApplyT(func(v *InstanceGroupConfig) []InstanceReference {
		if v == nil {
			return nil
		}
		return v.InstanceReferences
	}).(InstanceReferenceArrayOutput)
}

// Output only. Specifies that this instance group contains preemptible instances.
func (o InstanceGroupConfigPtrOutput) IsPreemptible() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *InstanceGroupConfig) *bool {
		if v == nil {
			return nil
		}
		return v.IsPreemptible
	}).(pulumi.BoolPtrOutput)
}

// Optional. The Compute Engine machine type used for cluster instances.A full URL, partial URI, or short name are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/zones/us-east1-a/machineTypes/n1-standard-2 projects/[project_id]/zones/us-east1-a/machineTypes/n1-standard-2 n1-standard-2Auto Zone Exception: If you are using the Dataproc Auto Zone Placement (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement) feature, you must use the short name of the machine type resource, for example, n1-standard-2.
func (o InstanceGroupConfigPtrOutput) MachineTypeUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *InstanceGroupConfig) *string {
		if v == nil {
			return nil
		}
		return v.MachineTypeUri
	}).(pulumi.StringPtrOutput)
}

// Output only. The config for Compute Engine Instance Group Manager that manages this group. This is only used for preemptible instance groups.
func (o InstanceGroupConfigPtrOutput) ManagedGroupConfig() ManagedGroupConfigPtrOutput {
	return o.ApplyT(func(v *InstanceGroupConfig) *ManagedGroupConfig {
		if v == nil {
			return nil
		}
		return v.ManagedGroupConfig
	}).(ManagedGroupConfigPtrOutput)
}

// Specifies the minimum cpu platform for the Instance Group. See Dataproc -> Minimum CPU Platform (https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
func (o InstanceGroupConfigPtrOutput) MinCpuPlatform() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *InstanceGroupConfig) *string {
		if v == nil {
			return nil
		}
		return v.MinCpuPlatform
	}).(pulumi.StringPtrOutput)
}

// Optional. The number of VM instances in the instance group. For HA cluster master_config groups, must be set to 3. For standard cluster master_config groups, must be set to 1.
func (o InstanceGroupConfigPtrOutput) NumInstances() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *InstanceGroupConfig) *int {
		if v == nil {
			return nil
		}
		return v.NumInstances
	}).(pulumi.IntPtrOutput)
}

// Optional. Specifies the preemptibility of the instance group.The default value for master and worker groups is NON_PREEMPTIBLE. This default cannot be changed.The default value for secondary instances is PREEMPTIBLE.
func (o InstanceGroupConfigPtrOutput) Preemptibility() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *InstanceGroupConfig) *string {
		if v == nil {
			return nil
		}
		return v.Preemptibility
	}).(pulumi.StringPtrOutput)
}

// A reference to a Compute Engine instance.
type InstanceReference struct {
	// The unique identifier of the Compute Engine instance.
	InstanceId *string `pulumi:"instanceId"`
	// The user-friendly name of the Compute Engine instance.
	InstanceName *string `pulumi:"instanceName"`
	// The public key used for sharing data with this instance.
	PublicKey *string `pulumi:"publicKey"`
}

// InstanceReferenceInput is an input type that accepts InstanceReferenceArgs and InstanceReferenceOutput values.
// You can construct a concrete instance of `InstanceReferenceInput` via:
//
//          InstanceReferenceArgs{...}
type InstanceReferenceInput interface {
	pulumi.Input

	ToInstanceReferenceOutput() InstanceReferenceOutput
	ToInstanceReferenceOutputWithContext(context.Context) InstanceReferenceOutput
}

// A reference to a Compute Engine instance.
type InstanceReferenceArgs struct {
	// The unique identifier of the Compute Engine instance.
	InstanceId pulumi.StringPtrInput `pulumi:"instanceId"`
	// The user-friendly name of the Compute Engine instance.
	InstanceName pulumi.StringPtrInput `pulumi:"instanceName"`
	// The public key used for sharing data with this instance.
	PublicKey pulumi.StringPtrInput `pulumi:"publicKey"`
}

func (InstanceReferenceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*InstanceReference)(nil)).Elem()
}

func (i InstanceReferenceArgs) ToInstanceReferenceOutput() InstanceReferenceOutput {
	return i.ToInstanceReferenceOutputWithContext(context.Background())
}

func (i InstanceReferenceArgs) ToInstanceReferenceOutputWithContext(ctx context.Context) InstanceReferenceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(InstanceReferenceOutput)
}

// InstanceReferenceArrayInput is an input type that accepts InstanceReferenceArray and InstanceReferenceArrayOutput values.
// You can construct a concrete instance of `InstanceReferenceArrayInput` via:
//
//          InstanceReferenceArray{ InstanceReferenceArgs{...} }
type InstanceReferenceArrayInput interface {
	pulumi.Input

	ToInstanceReferenceArrayOutput() InstanceReferenceArrayOutput
	ToInstanceReferenceArrayOutputWithContext(context.Context) InstanceReferenceArrayOutput
}

type InstanceReferenceArray []InstanceReferenceInput

func (InstanceReferenceArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]InstanceReference)(nil)).Elem()
}

func (i InstanceReferenceArray) ToInstanceReferenceArrayOutput() InstanceReferenceArrayOutput {
	return i.ToInstanceReferenceArrayOutputWithContext(context.Background())
}

func (i InstanceReferenceArray) ToInstanceReferenceArrayOutputWithContext(ctx context.Context) InstanceReferenceArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(InstanceReferenceArrayOutput)
}

// A reference to a Compute Engine instance.
type InstanceReferenceOutput struct{ *pulumi.OutputState }

func (InstanceReferenceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*InstanceReference)(nil)).Elem()
}

func (o InstanceReferenceOutput) ToInstanceReferenceOutput() InstanceReferenceOutput {
	return o
}

func (o InstanceReferenceOutput) ToInstanceReferenceOutputWithContext(ctx context.Context) InstanceReferenceOutput {
	return o
}

// The unique identifier of the Compute Engine instance.
func (o InstanceReferenceOutput) InstanceId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v InstanceReference) *string { return v.InstanceId }).(pulumi.StringPtrOutput)
}

// The user-friendly name of the Compute Engine instance.
func (o InstanceReferenceOutput) InstanceName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v InstanceReference) *string { return v.InstanceName }).(pulumi.StringPtrOutput)
}

// The public key used for sharing data with this instance.
func (o InstanceReferenceOutput) PublicKey() pulumi.StringPtrOutput {
	return o.ApplyT(func(v InstanceReference) *string { return v.PublicKey }).(pulumi.StringPtrOutput)
}

type InstanceReferenceArrayOutput struct{ *pulumi.OutputState }

func (InstanceReferenceArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]InstanceReference)(nil)).Elem()
}

func (o InstanceReferenceArrayOutput) ToInstanceReferenceArrayOutput() InstanceReferenceArrayOutput {
	return o
}

func (o InstanceReferenceArrayOutput) ToInstanceReferenceArrayOutputWithContext(ctx context.Context) InstanceReferenceArrayOutput {
	return o
}

func (o InstanceReferenceArrayOutput) Index(i pulumi.IntInput) InstanceReferenceOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) InstanceReference {
		return vs[0].([]InstanceReference)[vs[1].(int)]
	}).(InstanceReferenceOutput)
}

// Job scheduling options.
type JobScheduling struct {
	// Optional. Maximum number of times per hour a driver may be restarted as a result of driver terminating with non-zero code before job is reported failed.A job may be reported as thrashing if driver exits with non-zero code 4 times within 10 minute window.Maximum value is 10.
	MaxFailuresPerHour *int `pulumi:"maxFailuresPerHour"`
	// Optional. Maximum number of times in total a driver may be restarted as a result of driver exiting with non-zero code before job is reported failed. Maximum value is 240.
	MaxFailuresTotal *int `pulumi:"maxFailuresTotal"`
}

// JobSchedulingInput is an input type that accepts JobSchedulingArgs and JobSchedulingOutput values.
// You can construct a concrete instance of `JobSchedulingInput` via:
//
//          JobSchedulingArgs{...}
type JobSchedulingInput interface {
	pulumi.Input

	ToJobSchedulingOutput() JobSchedulingOutput
	ToJobSchedulingOutputWithContext(context.Context) JobSchedulingOutput
}

// Job scheduling options.
type JobSchedulingArgs struct {
	// Optional. Maximum number of times per hour a driver may be restarted as a result of driver terminating with non-zero code before job is reported failed.A job may be reported as thrashing if driver exits with non-zero code 4 times within 10 minute window.Maximum value is 10.
	MaxFailuresPerHour pulumi.IntPtrInput `pulumi:"maxFailuresPerHour"`
	// Optional. Maximum number of times in total a driver may be restarted as a result of driver exiting with non-zero code before job is reported failed. Maximum value is 240.
	MaxFailuresTotal pulumi.IntPtrInput `pulumi:"maxFailuresTotal"`
}

func (JobSchedulingArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*JobScheduling)(nil)).Elem()
}

func (i JobSchedulingArgs) ToJobSchedulingOutput() JobSchedulingOutput {
	return i.ToJobSchedulingOutputWithContext(context.Background())
}

func (i JobSchedulingArgs) ToJobSchedulingOutputWithContext(ctx context.Context) JobSchedulingOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobSchedulingOutput)
}

func (i JobSchedulingArgs) ToJobSchedulingPtrOutput() JobSchedulingPtrOutput {
	return i.ToJobSchedulingPtrOutputWithContext(context.Background())
}

func (i JobSchedulingArgs) ToJobSchedulingPtrOutputWithContext(ctx context.Context) JobSchedulingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobSchedulingOutput).ToJobSchedulingPtrOutputWithContext(ctx)
}

// JobSchedulingPtrInput is an input type that accepts JobSchedulingArgs, JobSchedulingPtr and JobSchedulingPtrOutput values.
// You can construct a concrete instance of `JobSchedulingPtrInput` via:
//
//          JobSchedulingArgs{...}
//
//  or:
//
//          nil
type JobSchedulingPtrInput interface {
	pulumi.Input

	ToJobSchedulingPtrOutput() JobSchedulingPtrOutput
	ToJobSchedulingPtrOutputWithContext(context.Context) JobSchedulingPtrOutput
}

type jobSchedulingPtrType JobSchedulingArgs

func JobSchedulingPtr(v *JobSchedulingArgs) JobSchedulingPtrInput {
	return (*jobSchedulingPtrType)(v)
}

func (*jobSchedulingPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**JobScheduling)(nil)).Elem()
}

func (i *jobSchedulingPtrType) ToJobSchedulingPtrOutput() JobSchedulingPtrOutput {
	return i.ToJobSchedulingPtrOutputWithContext(context.Background())
}

func (i *jobSchedulingPtrType) ToJobSchedulingPtrOutputWithContext(ctx context.Context) JobSchedulingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(JobSchedulingPtrOutput)
}

// Job scheduling options.
type JobSchedulingOutput struct{ *pulumi.OutputState }

func (JobSchedulingOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*JobScheduling)(nil)).Elem()
}

func (o JobSchedulingOutput) ToJobSchedulingOutput() JobSchedulingOutput {
	return o
}

func (o JobSchedulingOutput) ToJobSchedulingOutputWithContext(ctx context.Context) JobSchedulingOutput {
	return o
}

func (o JobSchedulingOutput) ToJobSchedulingPtrOutput() JobSchedulingPtrOutput {
	return o.ToJobSchedulingPtrOutputWithContext(context.Background())
}

func (o JobSchedulingOutput) ToJobSchedulingPtrOutputWithContext(ctx context.Context) JobSchedulingPtrOutput {
	return o.ApplyT(func(v JobScheduling) *JobScheduling {
		return &v
	}).(JobSchedulingPtrOutput)
}

// Optional. Maximum number of times per hour a driver may be restarted as a result of driver terminating with non-zero code before job is reported failed.A job may be reported as thrashing if driver exits with non-zero code 4 times within 10 minute window.Maximum value is 10.
func (o JobSchedulingOutput) MaxFailuresPerHour() pulumi.IntPtrOutput {
	return o.ApplyT(func(v JobScheduling) *int { return v.MaxFailuresPerHour }).(pulumi.IntPtrOutput)
}

// Optional. Maximum number of times in total a driver may be restarted as a result of driver exiting with non-zero code before job is reported failed. Maximum value is 240.
func (o JobSchedulingOutput) MaxFailuresTotal() pulumi.IntPtrOutput {
	return o.ApplyT(func(v JobScheduling) *int { return v.MaxFailuresTotal }).(pulumi.IntPtrOutput)
}

type JobSchedulingPtrOutput struct{ *pulumi.OutputState }

func (JobSchedulingPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**JobScheduling)(nil)).Elem()
}

func (o JobSchedulingPtrOutput) ToJobSchedulingPtrOutput() JobSchedulingPtrOutput {
	return o
}

func (o JobSchedulingPtrOutput) ToJobSchedulingPtrOutputWithContext(ctx context.Context) JobSchedulingPtrOutput {
	return o
}

func (o JobSchedulingPtrOutput) Elem() JobSchedulingOutput {
	return o.ApplyT(func(v *JobScheduling) JobScheduling { return *v }).(JobSchedulingOutput)
}

// Optional. Maximum number of times per hour a driver may be restarted as a result of driver terminating with non-zero code before job is reported failed.A job may be reported as thrashing if driver exits with non-zero code 4 times within 10 minute window.Maximum value is 10.
func (o JobSchedulingPtrOutput) MaxFailuresPerHour() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *JobScheduling) *int {
		if v == nil {
			return nil
		}
		return v.MaxFailuresPerHour
	}).(pulumi.IntPtrOutput)
}

// Optional. Maximum number of times in total a driver may be restarted as a result of driver exiting with non-zero code before job is reported failed. Maximum value is 240.
func (o JobSchedulingPtrOutput) MaxFailuresTotal() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *JobScheduling) *int {
		if v == nil {
			return nil
		}
		return v.MaxFailuresTotal
	}).(pulumi.IntPtrOutput)
}

// Specifies Kerberos related configuration.
type KerberosConfig struct {
	// Optional. The admin server (IP or hostname) for the remote trusted realm in a cross realm trust relationship.
	CrossRealmTrustAdminServer *string `pulumi:"crossRealmTrustAdminServer"`
	// Optional. The KDC (IP or hostname) for the remote trusted realm in a cross realm trust relationship.
	CrossRealmTrustKdc *string `pulumi:"crossRealmTrustKdc"`
	// Optional. The remote realm the Dataproc on-cluster KDC will trust, should the user enable cross realm trust.
	CrossRealmTrustRealm *string `pulumi:"crossRealmTrustRealm"`
	// Optional. The Cloud Storage URI of a KMS encrypted file containing the shared password between the on-cluster Kerberos realm and the remote trusted realm, in a cross realm trust relationship.
	CrossRealmTrustSharedPasswordUri *string `pulumi:"crossRealmTrustSharedPasswordUri"`
	// Optional. Flag to indicate whether to Kerberize the cluster (default: false). Set this field to true to enable Kerberos on a cluster.
	EnableKerberos *bool `pulumi:"enableKerberos"`
	// Optional. The Cloud Storage URI of a KMS encrypted file containing the master key of the KDC database.
	KdcDbKeyUri *string `pulumi:"kdcDbKeyUri"`
	// Optional. The Cloud Storage URI of a KMS encrypted file containing the password to the user provided key. For the self-signed certificate, this password is generated by Dataproc.
	KeyPasswordUri *string `pulumi:"keyPasswordUri"`
	// Optional. The Cloud Storage URI of a KMS encrypted file containing the password to the user provided keystore. For the self-signed certificate, this password is generated by Dataproc.
	KeystorePasswordUri *string `pulumi:"keystorePasswordUri"`
	// Optional. The Cloud Storage URI of the keystore file used for SSL encryption. If not provided, Dataproc will provide a self-signed certificate.
	KeystoreUri *string `pulumi:"keystoreUri"`
	// Optional. The uri of the KMS key used to encrypt various sensitive files.
	KmsKeyUri *string `pulumi:"kmsKeyUri"`
	// Optional. The name of the on-cluster Kerberos realm. If not specified, the uppercased domain of hostnames will be the realm.
	Realm *string `pulumi:"realm"`
	// Optional. The Cloud Storage URI of a KMS encrypted file containing the root principal password.
	RootPrincipalPasswordUri *string `pulumi:"rootPrincipalPasswordUri"`
	// Optional. The lifetime of the ticket granting ticket, in hours. If not specified, or user specifies 0, then default value 10 will be used.
	TgtLifetimeHours *int `pulumi:"tgtLifetimeHours"`
	// Optional. The Cloud Storage URI of a KMS encrypted file containing the password to the user provided truststore. For the self-signed certificate, this password is generated by Dataproc.
	TruststorePasswordUri *string `pulumi:"truststorePasswordUri"`
	// Optional. The Cloud Storage URI of the truststore file used for SSL encryption. If not provided, Dataproc will provide a self-signed certificate.
	TruststoreUri *string `pulumi:"truststoreUri"`
}

// KerberosConfigInput is an input type that accepts KerberosConfigArgs and KerberosConfigOutput values.
// You can construct a concrete instance of `KerberosConfigInput` via:
//
//          KerberosConfigArgs{...}
type KerberosConfigInput interface {
	pulumi.Input

	ToKerberosConfigOutput() KerberosConfigOutput
	ToKerberosConfigOutputWithContext(context.Context) KerberosConfigOutput
}

// Specifies Kerberos related configuration.
type KerberosConfigArgs struct {
	// Optional. The admin server (IP or hostname) for the remote trusted realm in a cross realm trust relationship.
	CrossRealmTrustAdminServer pulumi.StringPtrInput `pulumi:"crossRealmTrustAdminServer"`
	// Optional. The KDC (IP or hostname) for the remote trusted realm in a cross realm trust relationship.
	CrossRealmTrustKdc pulumi.StringPtrInput `pulumi:"crossRealmTrustKdc"`
	// Optional. The remote realm the Dataproc on-cluster KDC will trust, should the user enable cross realm trust.
	CrossRealmTrustRealm pulumi.StringPtrInput `pulumi:"crossRealmTrustRealm"`
	// Optional. The Cloud Storage URI of a KMS encrypted file containing the shared password between the on-cluster Kerberos realm and the remote trusted realm, in a cross realm trust relationship.
	CrossRealmTrustSharedPasswordUri pulumi.StringPtrInput `pulumi:"crossRealmTrustSharedPasswordUri"`
	// Optional. Flag to indicate whether to Kerberize the cluster (default: false). Set this field to true to enable Kerberos on a cluster.
	EnableKerberos pulumi.BoolPtrInput `pulumi:"enableKerberos"`
	// Optional. The Cloud Storage URI of a KMS encrypted file containing the master key of the KDC database.
	KdcDbKeyUri pulumi.StringPtrInput `pulumi:"kdcDbKeyUri"`
	// Optional. The Cloud Storage URI of a KMS encrypted file containing the password to the user provided key. For the self-signed certificate, this password is generated by Dataproc.
	KeyPasswordUri pulumi.StringPtrInput `pulumi:"keyPasswordUri"`
	// Optional. The Cloud Storage URI of a KMS encrypted file containing the password to the user provided keystore. For the self-signed certificate, this password is generated by Dataproc.
	KeystorePasswordUri pulumi.StringPtrInput `pulumi:"keystorePasswordUri"`
	// Optional. The Cloud Storage URI of the keystore file used for SSL encryption. If not provided, Dataproc will provide a self-signed certificate.
	KeystoreUri pulumi.StringPtrInput `pulumi:"keystoreUri"`
	// Optional. The uri of the KMS key used to encrypt various sensitive files.
	KmsKeyUri pulumi.StringPtrInput `pulumi:"kmsKeyUri"`
	// Optional. The name of the on-cluster Kerberos realm. If not specified, the uppercased domain of hostnames will be the realm.
	Realm pulumi.StringPtrInput `pulumi:"realm"`
	// Optional. The Cloud Storage URI of a KMS encrypted file containing the root principal password.
	RootPrincipalPasswordUri pulumi.StringPtrInput `pulumi:"rootPrincipalPasswordUri"`
	// Optional. The lifetime of the ticket granting ticket, in hours. If not specified, or user specifies 0, then default value 10 will be used.
	TgtLifetimeHours pulumi.IntPtrInput `pulumi:"tgtLifetimeHours"`
	// Optional. The Cloud Storage URI of a KMS encrypted file containing the password to the user provided truststore. For the self-signed certificate, this password is generated by Dataproc.
	TruststorePasswordUri pulumi.StringPtrInput `pulumi:"truststorePasswordUri"`
	// Optional. The Cloud Storage URI of the truststore file used for SSL encryption. If not provided, Dataproc will provide a self-signed certificate.
	TruststoreUri pulumi.StringPtrInput `pulumi:"truststoreUri"`
}

func (KerberosConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*KerberosConfig)(nil)).Elem()
}

func (i KerberosConfigArgs) ToKerberosConfigOutput() KerberosConfigOutput {
	return i.ToKerberosConfigOutputWithContext(context.Background())
}

func (i KerberosConfigArgs) ToKerberosConfigOutputWithContext(ctx context.Context) KerberosConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(KerberosConfigOutput)
}

func (i KerberosConfigArgs) ToKerberosConfigPtrOutput() KerberosConfigPtrOutput {
	return i.ToKerberosConfigPtrOutputWithContext(context.Background())
}

func (i KerberosConfigArgs) ToKerberosConfigPtrOutputWithContext(ctx context.Context) KerberosConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(KerberosConfigOutput).ToKerberosConfigPtrOutputWithContext(ctx)
}

// KerberosConfigPtrInput is an input type that accepts KerberosConfigArgs, KerberosConfigPtr and KerberosConfigPtrOutput values.
// You can construct a concrete instance of `KerberosConfigPtrInput` via:
//
//          KerberosConfigArgs{...}
//
//  or:
//
//          nil
type KerberosConfigPtrInput interface {
	pulumi.Input

	ToKerberosConfigPtrOutput() KerberosConfigPtrOutput
	ToKerberosConfigPtrOutputWithContext(context.Context) KerberosConfigPtrOutput
}

type kerberosConfigPtrType KerberosConfigArgs

func KerberosConfigPtr(v *KerberosConfigArgs) KerberosConfigPtrInput {
	return (*kerberosConfigPtrType)(v)
}

func (*kerberosConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**KerberosConfig)(nil)).Elem()
}

func (i *kerberosConfigPtrType) ToKerberosConfigPtrOutput() KerberosConfigPtrOutput {
	return i.ToKerberosConfigPtrOutputWithContext(context.Background())
}

func (i *kerberosConfigPtrType) ToKerberosConfigPtrOutputWithContext(ctx context.Context) KerberosConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(KerberosConfigPtrOutput)
}

// Specifies Kerberos related configuration.
type KerberosConfigOutput struct{ *pulumi.OutputState }

func (KerberosConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*KerberosConfig)(nil)).Elem()
}

func (o KerberosConfigOutput) ToKerberosConfigOutput() KerberosConfigOutput {
	return o
}

func (o KerberosConfigOutput) ToKerberosConfigOutputWithContext(ctx context.Context) KerberosConfigOutput {
	return o
}

func (o KerberosConfigOutput) ToKerberosConfigPtrOutput() KerberosConfigPtrOutput {
	return o.ToKerberosConfigPtrOutputWithContext(context.Background())
}

func (o KerberosConfigOutput) ToKerberosConfigPtrOutputWithContext(ctx context.Context) KerberosConfigPtrOutput {
	return o.ApplyT(func(v KerberosConfig) *KerberosConfig {
		return &v
	}).(KerberosConfigPtrOutput)
}

// Optional. The admin server (IP or hostname) for the remote trusted realm in a cross realm trust relationship.
func (o KerberosConfigOutput) CrossRealmTrustAdminServer() pulumi.StringPtrOutput {
	return o.ApplyT(func(v KerberosConfig) *string { return v.CrossRealmTrustAdminServer }).(pulumi.StringPtrOutput)
}

// Optional. The KDC (IP or hostname) for the remote trusted realm in a cross realm trust relationship.
func (o KerberosConfigOutput) CrossRealmTrustKdc() pulumi.StringPtrOutput {
	return o.ApplyT(func(v KerberosConfig) *string { return v.CrossRealmTrustKdc }).(pulumi.StringPtrOutput)
}

// Optional. The remote realm the Dataproc on-cluster KDC will trust, should the user enable cross realm trust.
func (o KerberosConfigOutput) CrossRealmTrustRealm() pulumi.StringPtrOutput {
	return o.ApplyT(func(v KerberosConfig) *string { return v.CrossRealmTrustRealm }).(pulumi.StringPtrOutput)
}

// Optional. The Cloud Storage URI of a KMS encrypted file containing the shared password between the on-cluster Kerberos realm and the remote trusted realm, in a cross realm trust relationship.
func (o KerberosConfigOutput) CrossRealmTrustSharedPasswordUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v KerberosConfig) *string { return v.CrossRealmTrustSharedPasswordUri }).(pulumi.StringPtrOutput)
}

// Optional. Flag to indicate whether to Kerberize the cluster (default: false). Set this field to true to enable Kerberos on a cluster.
func (o KerberosConfigOutput) EnableKerberos() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v KerberosConfig) *bool { return v.EnableKerberos }).(pulumi.BoolPtrOutput)
}

// Optional. The Cloud Storage URI of a KMS encrypted file containing the master key of the KDC database.
func (o KerberosConfigOutput) KdcDbKeyUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v KerberosConfig) *string { return v.KdcDbKeyUri }).(pulumi.StringPtrOutput)
}

// Optional. The Cloud Storage URI of a KMS encrypted file containing the password to the user provided key. For the self-signed certificate, this password is generated by Dataproc.
func (o KerberosConfigOutput) KeyPasswordUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v KerberosConfig) *string { return v.KeyPasswordUri }).(pulumi.StringPtrOutput)
}

// Optional. The Cloud Storage URI of a KMS encrypted file containing the password to the user provided keystore. For the self-signed certificate, this password is generated by Dataproc.
func (o KerberosConfigOutput) KeystorePasswordUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v KerberosConfig) *string { return v.KeystorePasswordUri }).(pulumi.StringPtrOutput)
}

// Optional. The Cloud Storage URI of the keystore file used for SSL encryption. If not provided, Dataproc will provide a self-signed certificate.
func (o KerberosConfigOutput) KeystoreUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v KerberosConfig) *string { return v.KeystoreUri }).(pulumi.StringPtrOutput)
}

// Optional. The uri of the KMS key used to encrypt various sensitive files.
func (o KerberosConfigOutput) KmsKeyUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v KerberosConfig) *string { return v.KmsKeyUri }).(pulumi.StringPtrOutput)
}

// Optional. The name of the on-cluster Kerberos realm. If not specified, the uppercased domain of hostnames will be the realm.
func (o KerberosConfigOutput) Realm() pulumi.StringPtrOutput {
	return o.ApplyT(func(v KerberosConfig) *string { return v.Realm }).(pulumi.StringPtrOutput)
}

// Optional. The Cloud Storage URI of a KMS encrypted file containing the root principal password.
func (o KerberosConfigOutput) RootPrincipalPasswordUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v KerberosConfig) *string { return v.RootPrincipalPasswordUri }).(pulumi.StringPtrOutput)
}

// Optional. The lifetime of the ticket granting ticket, in hours. If not specified, or user specifies 0, then default value 10 will be used.
func (o KerberosConfigOutput) TgtLifetimeHours() pulumi.IntPtrOutput {
	return o.ApplyT(func(v KerberosConfig) *int { return v.TgtLifetimeHours }).(pulumi.IntPtrOutput)
}

// Optional. The Cloud Storage URI of a KMS encrypted file containing the password to the user provided truststore. For the self-signed certificate, this password is generated by Dataproc.
func (o KerberosConfigOutput) TruststorePasswordUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v KerberosConfig) *string { return v.TruststorePasswordUri }).(pulumi.StringPtrOutput)
}

// Optional. The Cloud Storage URI of the truststore file used for SSL encryption. If not provided, Dataproc will provide a self-signed certificate.
func (o KerberosConfigOutput) TruststoreUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v KerberosConfig) *string { return v.TruststoreUri }).(pulumi.StringPtrOutput)
}

type KerberosConfigPtrOutput struct{ *pulumi.OutputState }

func (KerberosConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**KerberosConfig)(nil)).Elem()
}

func (o KerberosConfigPtrOutput) ToKerberosConfigPtrOutput() KerberosConfigPtrOutput {
	return o
}

func (o KerberosConfigPtrOutput) ToKerberosConfigPtrOutputWithContext(ctx context.Context) KerberosConfigPtrOutput {
	return o
}

func (o KerberosConfigPtrOutput) Elem() KerberosConfigOutput {
	return o.ApplyT(func(v *KerberosConfig) KerberosConfig { return *v }).(KerberosConfigOutput)
}

// Optional. The admin server (IP or hostname) for the remote trusted realm in a cross realm trust relationship.
func (o KerberosConfigPtrOutput) CrossRealmTrustAdminServer() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *KerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.CrossRealmTrustAdminServer
	}).(pulumi.StringPtrOutput)
}

// Optional. The KDC (IP or hostname) for the remote trusted realm in a cross realm trust relationship.
func (o KerberosConfigPtrOutput) CrossRealmTrustKdc() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *KerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.CrossRealmTrustKdc
	}).(pulumi.StringPtrOutput)
}

// Optional. The remote realm the Dataproc on-cluster KDC will trust, should the user enable cross realm trust.
func (o KerberosConfigPtrOutput) CrossRealmTrustRealm() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *KerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.CrossRealmTrustRealm
	}).(pulumi.StringPtrOutput)
}

// Optional. The Cloud Storage URI of a KMS encrypted file containing the shared password between the on-cluster Kerberos realm and the remote trusted realm, in a cross realm trust relationship.
func (o KerberosConfigPtrOutput) CrossRealmTrustSharedPasswordUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *KerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.CrossRealmTrustSharedPasswordUri
	}).(pulumi.StringPtrOutput)
}

// Optional. Flag to indicate whether to Kerberize the cluster (default: false). Set this field to true to enable Kerberos on a cluster.
func (o KerberosConfigPtrOutput) EnableKerberos() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *KerberosConfig) *bool {
		if v == nil {
			return nil
		}
		return v.EnableKerberos
	}).(pulumi.BoolPtrOutput)
}

// Optional. The Cloud Storage URI of a KMS encrypted file containing the master key of the KDC database.
func (o KerberosConfigPtrOutput) KdcDbKeyUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *KerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.KdcDbKeyUri
	}).(pulumi.StringPtrOutput)
}

// Optional. The Cloud Storage URI of a KMS encrypted file containing the password to the user provided key. For the self-signed certificate, this password is generated by Dataproc.
func (o KerberosConfigPtrOutput) KeyPasswordUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *KerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.KeyPasswordUri
	}).(pulumi.StringPtrOutput)
}

// Optional. The Cloud Storage URI of a KMS encrypted file containing the password to the user provided keystore. For the self-signed certificate, this password is generated by Dataproc.
func (o KerberosConfigPtrOutput) KeystorePasswordUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *KerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.KeystorePasswordUri
	}).(pulumi.StringPtrOutput)
}

// Optional. The Cloud Storage URI of the keystore file used for SSL encryption. If not provided, Dataproc will provide a self-signed certificate.
func (o KerberosConfigPtrOutput) KeystoreUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *KerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.KeystoreUri
	}).(pulumi.StringPtrOutput)
}

// Optional. The uri of the KMS key used to encrypt various sensitive files.
func (o KerberosConfigPtrOutput) KmsKeyUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *KerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.KmsKeyUri
	}).(pulumi.StringPtrOutput)
}

// Optional. The name of the on-cluster Kerberos realm. If not specified, the uppercased domain of hostnames will be the realm.
func (o KerberosConfigPtrOutput) Realm() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *KerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.Realm
	}).(pulumi.StringPtrOutput)
}

// Optional. The Cloud Storage URI of a KMS encrypted file containing the root principal password.
func (o KerberosConfigPtrOutput) RootPrincipalPasswordUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *KerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.RootPrincipalPasswordUri
	}).(pulumi.StringPtrOutput)
}

// Optional. The lifetime of the ticket granting ticket, in hours. If not specified, or user specifies 0, then default value 10 will be used.
func (o KerberosConfigPtrOutput) TgtLifetimeHours() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *KerberosConfig) *int {
		if v == nil {
			return nil
		}
		return v.TgtLifetimeHours
	}).(pulumi.IntPtrOutput)
}

// Optional. The Cloud Storage URI of a KMS encrypted file containing the password to the user provided truststore. For the self-signed certificate, this password is generated by Dataproc.
func (o KerberosConfigPtrOutput) TruststorePasswordUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *KerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.TruststorePasswordUri
	}).(pulumi.StringPtrOutput)
}

// Optional. The Cloud Storage URI of the truststore file used for SSL encryption. If not provided, Dataproc will provide a self-signed certificate.
func (o KerberosConfigPtrOutput) TruststoreUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *KerberosConfig) *string {
		if v == nil {
			return nil
		}
		return v.TruststoreUri
	}).(pulumi.StringPtrOutput)
}

// Specifies the cluster auto-delete schedule configuration.
type LifecycleConfig struct {
	// Optional. The time when cluster will be auto-deleted. (see JSON representation of Timestamp (https://developers.google.com/protocol-buffers/docs/proto3#json)).
	AutoDeleteTime *string `pulumi:"autoDeleteTime"`
	// Optional. The lifetime duration of cluster. The cluster will be auto-deleted at the end of this period. Minimum value is 10 minutes; maximum value is 14 days (see JSON representation of Duration (https://developers.google.com/protocol-buffers/docs/proto3#json)).
	AutoDeleteTtl *string `pulumi:"autoDeleteTtl"`
	// Optional. The duration to keep the cluster alive while idling (when no jobs are running). Passing this threshold will cause the cluster to be deleted. Minimum value is 5 minutes; maximum value is 14 days (see JSON representation of Duration (https://developers.google.com/protocol-buffers/docs/proto3#json)).
	IdleDeleteTtl *string `pulumi:"idleDeleteTtl"`
	// Output only. The time when cluster became idle (most recent job finished) and became eligible for deletion due to idleness (see JSON representation of Timestamp (https://developers.google.com/protocol-buffers/docs/proto3#json)).
	IdleStartTime *string `pulumi:"idleStartTime"`
}

// LifecycleConfigInput is an input type that accepts LifecycleConfigArgs and LifecycleConfigOutput values.
// You can construct a concrete instance of `LifecycleConfigInput` via:
//
//          LifecycleConfigArgs{...}
type LifecycleConfigInput interface {
	pulumi.Input

	ToLifecycleConfigOutput() LifecycleConfigOutput
	ToLifecycleConfigOutputWithContext(context.Context) LifecycleConfigOutput
}

// Specifies the cluster auto-delete schedule configuration.
type LifecycleConfigArgs struct {
	// Optional. The time when cluster will be auto-deleted. (see JSON representation of Timestamp (https://developers.google.com/protocol-buffers/docs/proto3#json)).
	AutoDeleteTime pulumi.StringPtrInput `pulumi:"autoDeleteTime"`
	// Optional. The lifetime duration of cluster. The cluster will be auto-deleted at the end of this period. Minimum value is 10 minutes; maximum value is 14 days (see JSON representation of Duration (https://developers.google.com/protocol-buffers/docs/proto3#json)).
	AutoDeleteTtl pulumi.StringPtrInput `pulumi:"autoDeleteTtl"`
	// Optional. The duration to keep the cluster alive while idling (when no jobs are running). Passing this threshold will cause the cluster to be deleted. Minimum value is 5 minutes; maximum value is 14 days (see JSON representation of Duration (https://developers.google.com/protocol-buffers/docs/proto3#json)).
	IdleDeleteTtl pulumi.StringPtrInput `pulumi:"idleDeleteTtl"`
	// Output only. The time when cluster became idle (most recent job finished) and became eligible for deletion due to idleness (see JSON representation of Timestamp (https://developers.google.com/protocol-buffers/docs/proto3#json)).
	IdleStartTime pulumi.StringPtrInput `pulumi:"idleStartTime"`
}

func (LifecycleConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*LifecycleConfig)(nil)).Elem()
}

func (i LifecycleConfigArgs) ToLifecycleConfigOutput() LifecycleConfigOutput {
	return i.ToLifecycleConfigOutputWithContext(context.Background())
}

func (i LifecycleConfigArgs) ToLifecycleConfigOutputWithContext(ctx context.Context) LifecycleConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(LifecycleConfigOutput)
}

func (i LifecycleConfigArgs) ToLifecycleConfigPtrOutput() LifecycleConfigPtrOutput {
	return i.ToLifecycleConfigPtrOutputWithContext(context.Background())
}

func (i LifecycleConfigArgs) ToLifecycleConfigPtrOutputWithContext(ctx context.Context) LifecycleConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(LifecycleConfigOutput).ToLifecycleConfigPtrOutputWithContext(ctx)
}

// LifecycleConfigPtrInput is an input type that accepts LifecycleConfigArgs, LifecycleConfigPtr and LifecycleConfigPtrOutput values.
// You can construct a concrete instance of `LifecycleConfigPtrInput` via:
//
//          LifecycleConfigArgs{...}
//
//  or:
//
//          nil
type LifecycleConfigPtrInput interface {
	pulumi.Input

	ToLifecycleConfigPtrOutput() LifecycleConfigPtrOutput
	ToLifecycleConfigPtrOutputWithContext(context.Context) LifecycleConfigPtrOutput
}

type lifecycleConfigPtrType LifecycleConfigArgs

func LifecycleConfigPtr(v *LifecycleConfigArgs) LifecycleConfigPtrInput {
	return (*lifecycleConfigPtrType)(v)
}

func (*lifecycleConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**LifecycleConfig)(nil)).Elem()
}

func (i *lifecycleConfigPtrType) ToLifecycleConfigPtrOutput() LifecycleConfigPtrOutput {
	return i.ToLifecycleConfigPtrOutputWithContext(context.Background())
}

func (i *lifecycleConfigPtrType) ToLifecycleConfigPtrOutputWithContext(ctx context.Context) LifecycleConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(LifecycleConfigPtrOutput)
}

// Specifies the cluster auto-delete schedule configuration.
type LifecycleConfigOutput struct{ *pulumi.OutputState }

func (LifecycleConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*LifecycleConfig)(nil)).Elem()
}

func (o LifecycleConfigOutput) ToLifecycleConfigOutput() LifecycleConfigOutput {
	return o
}

func (o LifecycleConfigOutput) ToLifecycleConfigOutputWithContext(ctx context.Context) LifecycleConfigOutput {
	return o
}

func (o LifecycleConfigOutput) ToLifecycleConfigPtrOutput() LifecycleConfigPtrOutput {
	return o.ToLifecycleConfigPtrOutputWithContext(context.Background())
}

func (o LifecycleConfigOutput) ToLifecycleConfigPtrOutputWithContext(ctx context.Context) LifecycleConfigPtrOutput {
	return o.ApplyT(func(v LifecycleConfig) *LifecycleConfig {
		return &v
	}).(LifecycleConfigPtrOutput)
}

// Optional. The time when cluster will be auto-deleted. (see JSON representation of Timestamp (https://developers.google.com/protocol-buffers/docs/proto3#json)).
func (o LifecycleConfigOutput) AutoDeleteTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v LifecycleConfig) *string { return v.AutoDeleteTime }).(pulumi.StringPtrOutput)
}

// Optional. The lifetime duration of cluster. The cluster will be auto-deleted at the end of this period. Minimum value is 10 minutes; maximum value is 14 days (see JSON representation of Duration (https://developers.google.com/protocol-buffers/docs/proto3#json)).
func (o LifecycleConfigOutput) AutoDeleteTtl() pulumi.StringPtrOutput {
	return o.ApplyT(func(v LifecycleConfig) *string { return v.AutoDeleteTtl }).(pulumi.StringPtrOutput)
}

// Optional. The duration to keep the cluster alive while idling (when no jobs are running). Passing this threshold will cause the cluster to be deleted. Minimum value is 5 minutes; maximum value is 14 days (see JSON representation of Duration (https://developers.google.com/protocol-buffers/docs/proto3#json)).
func (o LifecycleConfigOutput) IdleDeleteTtl() pulumi.StringPtrOutput {
	return o.ApplyT(func(v LifecycleConfig) *string { return v.IdleDeleteTtl }).(pulumi.StringPtrOutput)
}

// Output only. The time when cluster became idle (most recent job finished) and became eligible for deletion due to idleness (see JSON representation of Timestamp (https://developers.google.com/protocol-buffers/docs/proto3#json)).
func (o LifecycleConfigOutput) IdleStartTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v LifecycleConfig) *string { return v.IdleStartTime }).(pulumi.StringPtrOutput)
}

type LifecycleConfigPtrOutput struct{ *pulumi.OutputState }

func (LifecycleConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**LifecycleConfig)(nil)).Elem()
}

func (o LifecycleConfigPtrOutput) ToLifecycleConfigPtrOutput() LifecycleConfigPtrOutput {
	return o
}

func (o LifecycleConfigPtrOutput) ToLifecycleConfigPtrOutputWithContext(ctx context.Context) LifecycleConfigPtrOutput {
	return o
}

func (o LifecycleConfigPtrOutput) Elem() LifecycleConfigOutput {
	return o.ApplyT(func(v *LifecycleConfig) LifecycleConfig { return *v }).(LifecycleConfigOutput)
}

// Optional. The time when cluster will be auto-deleted. (see JSON representation of Timestamp (https://developers.google.com/protocol-buffers/docs/proto3#json)).
func (o LifecycleConfigPtrOutput) AutoDeleteTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *LifecycleConfig) *string {
		if v == nil {
			return nil
		}
		return v.AutoDeleteTime
	}).(pulumi.StringPtrOutput)
}

// Optional. The lifetime duration of cluster. The cluster will be auto-deleted at the end of this period. Minimum value is 10 minutes; maximum value is 14 days (see JSON representation of Duration (https://developers.google.com/protocol-buffers/docs/proto3#json)).
func (o LifecycleConfigPtrOutput) AutoDeleteTtl() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *LifecycleConfig) *string {
		if v == nil {
			return nil
		}
		return v.AutoDeleteTtl
	}).(pulumi.StringPtrOutput)
}

// Optional. The duration to keep the cluster alive while idling (when no jobs are running). Passing this threshold will cause the cluster to be deleted. Minimum value is 5 minutes; maximum value is 14 days (see JSON representation of Duration (https://developers.google.com/protocol-buffers/docs/proto3#json)).
func (o LifecycleConfigPtrOutput) IdleDeleteTtl() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *LifecycleConfig) *string {
		if v == nil {
			return nil
		}
		return v.IdleDeleteTtl
	}).(pulumi.StringPtrOutput)
}

// Output only. The time when cluster became idle (most recent job finished) and became eligible for deletion due to idleness (see JSON representation of Timestamp (https://developers.google.com/protocol-buffers/docs/proto3#json)).
func (o LifecycleConfigPtrOutput) IdleStartTime() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *LifecycleConfig) *string {
		if v == nil {
			return nil
		}
		return v.IdleStartTime
	}).(pulumi.StringPtrOutput)
}

// The runtime logging config of the job.
type LoggingConfig struct {
	// The per-package log levels for the driver. This may include "root" package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
	DriverLogLevels map[string]string `pulumi:"driverLogLevels"`
}

// LoggingConfigInput is an input type that accepts LoggingConfigArgs and LoggingConfigOutput values.
// You can construct a concrete instance of `LoggingConfigInput` via:
//
//          LoggingConfigArgs{...}
type LoggingConfigInput interface {
	pulumi.Input

	ToLoggingConfigOutput() LoggingConfigOutput
	ToLoggingConfigOutputWithContext(context.Context) LoggingConfigOutput
}

// The runtime logging config of the job.
type LoggingConfigArgs struct {
	// The per-package log levels for the driver. This may include "root" package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
	DriverLogLevels pulumi.StringMapInput `pulumi:"driverLogLevels"`
}

func (LoggingConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*LoggingConfig)(nil)).Elem()
}

func (i LoggingConfigArgs) ToLoggingConfigOutput() LoggingConfigOutput {
	return i.ToLoggingConfigOutputWithContext(context.Background())
}

func (i LoggingConfigArgs) ToLoggingConfigOutputWithContext(ctx context.Context) LoggingConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(LoggingConfigOutput)
}

func (i LoggingConfigArgs) ToLoggingConfigPtrOutput() LoggingConfigPtrOutput {
	return i.ToLoggingConfigPtrOutputWithContext(context.Background())
}

func (i LoggingConfigArgs) ToLoggingConfigPtrOutputWithContext(ctx context.Context) LoggingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(LoggingConfigOutput).ToLoggingConfigPtrOutputWithContext(ctx)
}

// LoggingConfigPtrInput is an input type that accepts LoggingConfigArgs, LoggingConfigPtr and LoggingConfigPtrOutput values.
// You can construct a concrete instance of `LoggingConfigPtrInput` via:
//
//          LoggingConfigArgs{...}
//
//  or:
//
//          nil
type LoggingConfigPtrInput interface {
	pulumi.Input

	ToLoggingConfigPtrOutput() LoggingConfigPtrOutput
	ToLoggingConfigPtrOutputWithContext(context.Context) LoggingConfigPtrOutput
}

type loggingConfigPtrType LoggingConfigArgs

func LoggingConfigPtr(v *LoggingConfigArgs) LoggingConfigPtrInput {
	return (*loggingConfigPtrType)(v)
}

func (*loggingConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**LoggingConfig)(nil)).Elem()
}

func (i *loggingConfigPtrType) ToLoggingConfigPtrOutput() LoggingConfigPtrOutput {
	return i.ToLoggingConfigPtrOutputWithContext(context.Background())
}

func (i *loggingConfigPtrType) ToLoggingConfigPtrOutputWithContext(ctx context.Context) LoggingConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(LoggingConfigPtrOutput)
}

// The runtime logging config of the job.
type LoggingConfigOutput struct{ *pulumi.OutputState }

func (LoggingConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*LoggingConfig)(nil)).Elem()
}

func (o LoggingConfigOutput) ToLoggingConfigOutput() LoggingConfigOutput {
	return o
}

func (o LoggingConfigOutput) ToLoggingConfigOutputWithContext(ctx context.Context) LoggingConfigOutput {
	return o
}

func (o LoggingConfigOutput) ToLoggingConfigPtrOutput() LoggingConfigPtrOutput {
	return o.ToLoggingConfigPtrOutputWithContext(context.Background())
}

func (o LoggingConfigOutput) ToLoggingConfigPtrOutputWithContext(ctx context.Context) LoggingConfigPtrOutput {
	return o.ApplyT(func(v LoggingConfig) *LoggingConfig {
		return &v
	}).(LoggingConfigPtrOutput)
}

// The per-package log levels for the driver. This may include "root" package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
func (o LoggingConfigOutput) DriverLogLevels() pulumi.StringMapOutput {
	return o.ApplyT(func(v LoggingConfig) map[string]string { return v.DriverLogLevels }).(pulumi.StringMapOutput)
}

type LoggingConfigPtrOutput struct{ *pulumi.OutputState }

func (LoggingConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**LoggingConfig)(nil)).Elem()
}

func (o LoggingConfigPtrOutput) ToLoggingConfigPtrOutput() LoggingConfigPtrOutput {
	return o
}

func (o LoggingConfigPtrOutput) ToLoggingConfigPtrOutputWithContext(ctx context.Context) LoggingConfigPtrOutput {
	return o
}

func (o LoggingConfigPtrOutput) Elem() LoggingConfigOutput {
	return o.ApplyT(func(v *LoggingConfig) LoggingConfig { return *v }).(LoggingConfigOutput)
}

// The per-package log levels for the driver. This may include "root" package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
func (o LoggingConfigPtrOutput) DriverLogLevels() pulumi.StringMapOutput {
	return o.ApplyT(func(v *LoggingConfig) map[string]string {
		if v == nil {
			return nil
		}
		return v.DriverLogLevels
	}).(pulumi.StringMapOutput)
}

// Cluster that is managed by the workflow.
type ManagedCluster struct {
	// Required. The cluster name prefix. A unique cluster name will be formed by appending a random suffix.The name must contain only lower-case letters (a-z), numbers (0-9), and hyphens (-). Must begin with a letter. Cannot begin or end with hyphen. Must consist of between 2 and 35 characters.
	ClusterName *string `pulumi:"clusterName"`
	// Required. The cluster configuration.
	Config *ClusterConfig `pulumi:"config"`
	// Optional. The labels to associate with this cluster.Label keys must be between 1 and 63 characters long, and must conform to the following PCRE regular expression: \p{Ll}\p{Lo}{0,62}Label values must be between 1 and 63 characters long, and must conform to the following PCRE regular expression: \p{Ll}\p{Lo}\p{N}_-{0,63}No more than 32 labels can be associated with a given cluster.
	Labels map[string]string `pulumi:"labels"`
}

// ManagedClusterInput is an input type that accepts ManagedClusterArgs and ManagedClusterOutput values.
// You can construct a concrete instance of `ManagedClusterInput` via:
//
//          ManagedClusterArgs{...}
type ManagedClusterInput interface {
	pulumi.Input

	ToManagedClusterOutput() ManagedClusterOutput
	ToManagedClusterOutputWithContext(context.Context) ManagedClusterOutput
}

// Cluster that is managed by the workflow.
type ManagedClusterArgs struct {
	// Required. The cluster name prefix. A unique cluster name will be formed by appending a random suffix.The name must contain only lower-case letters (a-z), numbers (0-9), and hyphens (-). Must begin with a letter. Cannot begin or end with hyphen. Must consist of between 2 and 35 characters.
	ClusterName pulumi.StringPtrInput `pulumi:"clusterName"`
	// Required. The cluster configuration.
	Config ClusterConfigPtrInput `pulumi:"config"`
	// Optional. The labels to associate with this cluster.Label keys must be between 1 and 63 characters long, and must conform to the following PCRE regular expression: \p{Ll}\p{Lo}{0,62}Label values must be between 1 and 63 characters long, and must conform to the following PCRE regular expression: \p{Ll}\p{Lo}\p{N}_-{0,63}No more than 32 labels can be associated with a given cluster.
	Labels pulumi.StringMapInput `pulumi:"labels"`
}

func (ManagedClusterArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ManagedCluster)(nil)).Elem()
}

func (i ManagedClusterArgs) ToManagedClusterOutput() ManagedClusterOutput {
	return i.ToManagedClusterOutputWithContext(context.Background())
}

func (i ManagedClusterArgs) ToManagedClusterOutputWithContext(ctx context.Context) ManagedClusterOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ManagedClusterOutput)
}

func (i ManagedClusterArgs) ToManagedClusterPtrOutput() ManagedClusterPtrOutput {
	return i.ToManagedClusterPtrOutputWithContext(context.Background())
}

func (i ManagedClusterArgs) ToManagedClusterPtrOutputWithContext(ctx context.Context) ManagedClusterPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ManagedClusterOutput).ToManagedClusterPtrOutputWithContext(ctx)
}

// ManagedClusterPtrInput is an input type that accepts ManagedClusterArgs, ManagedClusterPtr and ManagedClusterPtrOutput values.
// You can construct a concrete instance of `ManagedClusterPtrInput` via:
//
//          ManagedClusterArgs{...}
//
//  or:
//
//          nil
type ManagedClusterPtrInput interface {
	pulumi.Input

	ToManagedClusterPtrOutput() ManagedClusterPtrOutput
	ToManagedClusterPtrOutputWithContext(context.Context) ManagedClusterPtrOutput
}

type managedClusterPtrType ManagedClusterArgs

func ManagedClusterPtr(v *ManagedClusterArgs) ManagedClusterPtrInput {
	return (*managedClusterPtrType)(v)
}

func (*managedClusterPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ManagedCluster)(nil)).Elem()
}

func (i *managedClusterPtrType) ToManagedClusterPtrOutput() ManagedClusterPtrOutput {
	return i.ToManagedClusterPtrOutputWithContext(context.Background())
}

func (i *managedClusterPtrType) ToManagedClusterPtrOutputWithContext(ctx context.Context) ManagedClusterPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ManagedClusterPtrOutput)
}

// Cluster that is managed by the workflow.
type ManagedClusterOutput struct{ *pulumi.OutputState }

func (ManagedClusterOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ManagedCluster)(nil)).Elem()
}

func (o ManagedClusterOutput) ToManagedClusterOutput() ManagedClusterOutput {
	return o
}

func (o ManagedClusterOutput) ToManagedClusterOutputWithContext(ctx context.Context) ManagedClusterOutput {
	return o
}

func (o ManagedClusterOutput) ToManagedClusterPtrOutput() ManagedClusterPtrOutput {
	return o.ToManagedClusterPtrOutputWithContext(context.Background())
}

func (o ManagedClusterOutput) ToManagedClusterPtrOutputWithContext(ctx context.Context) ManagedClusterPtrOutput {
	return o.ApplyT(func(v ManagedCluster) *ManagedCluster {
		return &v
	}).(ManagedClusterPtrOutput)
}

// Required. The cluster name prefix. A unique cluster name will be formed by appending a random suffix.The name must contain only lower-case letters (a-z), numbers (0-9), and hyphens (-). Must begin with a letter. Cannot begin or end with hyphen. Must consist of between 2 and 35 characters.
func (o ManagedClusterOutput) ClusterName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ManagedCluster) *string { return v.ClusterName }).(pulumi.StringPtrOutput)
}

// Required. The cluster configuration.
func (o ManagedClusterOutput) Config() ClusterConfigPtrOutput {
	return o.ApplyT(func(v ManagedCluster) *ClusterConfig { return v.Config }).(ClusterConfigPtrOutput)
}

// Optional. The labels to associate with this cluster.Label keys must be between 1 and 63 characters long, and must conform to the following PCRE regular expression: \p{Ll}\p{Lo}{0,62}Label values must be between 1 and 63 characters long, and must conform to the following PCRE regular expression: \p{Ll}\p{Lo}\p{N}_-{0,63}No more than 32 labels can be associated with a given cluster.
func (o ManagedClusterOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v ManagedCluster) map[string]string { return v.Labels }).(pulumi.StringMapOutput)
}

type ManagedClusterPtrOutput struct{ *pulumi.OutputState }

func (ManagedClusterPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ManagedCluster)(nil)).Elem()
}

func (o ManagedClusterPtrOutput) ToManagedClusterPtrOutput() ManagedClusterPtrOutput {
	return o
}

func (o ManagedClusterPtrOutput) ToManagedClusterPtrOutputWithContext(ctx context.Context) ManagedClusterPtrOutput {
	return o
}

func (o ManagedClusterPtrOutput) Elem() ManagedClusterOutput {
	return o.ApplyT(func(v *ManagedCluster) ManagedCluster { return *v }).(ManagedClusterOutput)
}

// Required. The cluster name prefix. A unique cluster name will be formed by appending a random suffix.The name must contain only lower-case letters (a-z), numbers (0-9), and hyphens (-). Must begin with a letter. Cannot begin or end with hyphen. Must consist of between 2 and 35 characters.
func (o ManagedClusterPtrOutput) ClusterName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ManagedCluster) *string {
		if v == nil {
			return nil
		}
		return v.ClusterName
	}).(pulumi.StringPtrOutput)
}

// Required. The cluster configuration.
func (o ManagedClusterPtrOutput) Config() ClusterConfigPtrOutput {
	return o.ApplyT(func(v *ManagedCluster) *ClusterConfig {
		if v == nil {
			return nil
		}
		return v.Config
	}).(ClusterConfigPtrOutput)
}

// Optional. The labels to associate with this cluster.Label keys must be between 1 and 63 characters long, and must conform to the following PCRE regular expression: \p{Ll}\p{Lo}{0,62}Label values must be between 1 and 63 characters long, and must conform to the following PCRE regular expression: \p{Ll}\p{Lo}\p{N}_-{0,63}No more than 32 labels can be associated with a given cluster.
func (o ManagedClusterPtrOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v *ManagedCluster) map[string]string {
		if v == nil {
			return nil
		}
		return v.Labels
	}).(pulumi.StringMapOutput)
}

// Specifies the resources used to actively manage an instance group.
type ManagedGroupConfig struct {
	// Output only. The name of the Instance Group Manager for this group.
	InstanceGroupManagerName *string `pulumi:"instanceGroupManagerName"`
	// Output only. The name of the Instance Template used for the Managed Instance Group.
	InstanceTemplateName *string `pulumi:"instanceTemplateName"`
}

// ManagedGroupConfigInput is an input type that accepts ManagedGroupConfigArgs and ManagedGroupConfigOutput values.
// You can construct a concrete instance of `ManagedGroupConfigInput` via:
//
//          ManagedGroupConfigArgs{...}
type ManagedGroupConfigInput interface {
	pulumi.Input

	ToManagedGroupConfigOutput() ManagedGroupConfigOutput
	ToManagedGroupConfigOutputWithContext(context.Context) ManagedGroupConfigOutput
}

// Specifies the resources used to actively manage an instance group.
type ManagedGroupConfigArgs struct {
	// Output only. The name of the Instance Group Manager for this group.
	InstanceGroupManagerName pulumi.StringPtrInput `pulumi:"instanceGroupManagerName"`
	// Output only. The name of the Instance Template used for the Managed Instance Group.
	InstanceTemplateName pulumi.StringPtrInput `pulumi:"instanceTemplateName"`
}

func (ManagedGroupConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ManagedGroupConfig)(nil)).Elem()
}

func (i ManagedGroupConfigArgs) ToManagedGroupConfigOutput() ManagedGroupConfigOutput {
	return i.ToManagedGroupConfigOutputWithContext(context.Background())
}

func (i ManagedGroupConfigArgs) ToManagedGroupConfigOutputWithContext(ctx context.Context) ManagedGroupConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ManagedGroupConfigOutput)
}

func (i ManagedGroupConfigArgs) ToManagedGroupConfigPtrOutput() ManagedGroupConfigPtrOutput {
	return i.ToManagedGroupConfigPtrOutputWithContext(context.Background())
}

func (i ManagedGroupConfigArgs) ToManagedGroupConfigPtrOutputWithContext(ctx context.Context) ManagedGroupConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ManagedGroupConfigOutput).ToManagedGroupConfigPtrOutputWithContext(ctx)
}

// ManagedGroupConfigPtrInput is an input type that accepts ManagedGroupConfigArgs, ManagedGroupConfigPtr and ManagedGroupConfigPtrOutput values.
// You can construct a concrete instance of `ManagedGroupConfigPtrInput` via:
//
//          ManagedGroupConfigArgs{...}
//
//  or:
//
//          nil
type ManagedGroupConfigPtrInput interface {
	pulumi.Input

	ToManagedGroupConfigPtrOutput() ManagedGroupConfigPtrOutput
	ToManagedGroupConfigPtrOutputWithContext(context.Context) ManagedGroupConfigPtrOutput
}

type managedGroupConfigPtrType ManagedGroupConfigArgs

func ManagedGroupConfigPtr(v *ManagedGroupConfigArgs) ManagedGroupConfigPtrInput {
	return (*managedGroupConfigPtrType)(v)
}

func (*managedGroupConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ManagedGroupConfig)(nil)).Elem()
}

func (i *managedGroupConfigPtrType) ToManagedGroupConfigPtrOutput() ManagedGroupConfigPtrOutput {
	return i.ToManagedGroupConfigPtrOutputWithContext(context.Background())
}

func (i *managedGroupConfigPtrType) ToManagedGroupConfigPtrOutputWithContext(ctx context.Context) ManagedGroupConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ManagedGroupConfigPtrOutput)
}

// Specifies the resources used to actively manage an instance group.
type ManagedGroupConfigOutput struct{ *pulumi.OutputState }

func (ManagedGroupConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ManagedGroupConfig)(nil)).Elem()
}

func (o ManagedGroupConfigOutput) ToManagedGroupConfigOutput() ManagedGroupConfigOutput {
	return o
}

func (o ManagedGroupConfigOutput) ToManagedGroupConfigOutputWithContext(ctx context.Context) ManagedGroupConfigOutput {
	return o
}

func (o ManagedGroupConfigOutput) ToManagedGroupConfigPtrOutput() ManagedGroupConfigPtrOutput {
	return o.ToManagedGroupConfigPtrOutputWithContext(context.Background())
}

func (o ManagedGroupConfigOutput) ToManagedGroupConfigPtrOutputWithContext(ctx context.Context) ManagedGroupConfigPtrOutput {
	return o.ApplyT(func(v ManagedGroupConfig) *ManagedGroupConfig {
		return &v
	}).(ManagedGroupConfigPtrOutput)
}

// Output only. The name of the Instance Group Manager for this group.
func (o ManagedGroupConfigOutput) InstanceGroupManagerName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ManagedGroupConfig) *string { return v.InstanceGroupManagerName }).(pulumi.StringPtrOutput)
}

// Output only. The name of the Instance Template used for the Managed Instance Group.
func (o ManagedGroupConfigOutput) InstanceTemplateName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ManagedGroupConfig) *string { return v.InstanceTemplateName }).(pulumi.StringPtrOutput)
}

type ManagedGroupConfigPtrOutput struct{ *pulumi.OutputState }

func (ManagedGroupConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ManagedGroupConfig)(nil)).Elem()
}

func (o ManagedGroupConfigPtrOutput) ToManagedGroupConfigPtrOutput() ManagedGroupConfigPtrOutput {
	return o
}

func (o ManagedGroupConfigPtrOutput) ToManagedGroupConfigPtrOutputWithContext(ctx context.Context) ManagedGroupConfigPtrOutput {
	return o
}

func (o ManagedGroupConfigPtrOutput) Elem() ManagedGroupConfigOutput {
	return o.ApplyT(func(v *ManagedGroupConfig) ManagedGroupConfig { return *v }).(ManagedGroupConfigOutput)
}

// Output only. The name of the Instance Group Manager for this group.
func (o ManagedGroupConfigPtrOutput) InstanceGroupManagerName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ManagedGroupConfig) *string {
		if v == nil {
			return nil
		}
		return v.InstanceGroupManagerName
	}).(pulumi.StringPtrOutput)
}

// Output only. The name of the Instance Template used for the Managed Instance Group.
func (o ManagedGroupConfigPtrOutput) InstanceTemplateName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ManagedGroupConfig) *string {
		if v == nil {
			return nil
		}
		return v.InstanceTemplateName
	}).(pulumi.StringPtrOutput)
}

// Specifies a Metastore configuration.
type MetastoreConfig struct {
	// Required. Resource name of an existing Dataproc Metastore service.Example: projects/[project_id]/locations/[dataproc_region]/services/[service-name]
	DataprocMetastoreService *string `pulumi:"dataprocMetastoreService"`
}

// MetastoreConfigInput is an input type that accepts MetastoreConfigArgs and MetastoreConfigOutput values.
// You can construct a concrete instance of `MetastoreConfigInput` via:
//
//          MetastoreConfigArgs{...}
type MetastoreConfigInput interface {
	pulumi.Input

	ToMetastoreConfigOutput() MetastoreConfigOutput
	ToMetastoreConfigOutputWithContext(context.Context) MetastoreConfigOutput
}

// Specifies a Metastore configuration.
type MetastoreConfigArgs struct {
	// Required. Resource name of an existing Dataproc Metastore service.Example: projects/[project_id]/locations/[dataproc_region]/services/[service-name]
	DataprocMetastoreService pulumi.StringPtrInput `pulumi:"dataprocMetastoreService"`
}

func (MetastoreConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*MetastoreConfig)(nil)).Elem()
}

func (i MetastoreConfigArgs) ToMetastoreConfigOutput() MetastoreConfigOutput {
	return i.ToMetastoreConfigOutputWithContext(context.Background())
}

func (i MetastoreConfigArgs) ToMetastoreConfigOutputWithContext(ctx context.Context) MetastoreConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(MetastoreConfigOutput)
}

func (i MetastoreConfigArgs) ToMetastoreConfigPtrOutput() MetastoreConfigPtrOutput {
	return i.ToMetastoreConfigPtrOutputWithContext(context.Background())
}

func (i MetastoreConfigArgs) ToMetastoreConfigPtrOutputWithContext(ctx context.Context) MetastoreConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(MetastoreConfigOutput).ToMetastoreConfigPtrOutputWithContext(ctx)
}

// MetastoreConfigPtrInput is an input type that accepts MetastoreConfigArgs, MetastoreConfigPtr and MetastoreConfigPtrOutput values.
// You can construct a concrete instance of `MetastoreConfigPtrInput` via:
//
//          MetastoreConfigArgs{...}
//
//  or:
//
//          nil
type MetastoreConfigPtrInput interface {
	pulumi.Input

	ToMetastoreConfigPtrOutput() MetastoreConfigPtrOutput
	ToMetastoreConfigPtrOutputWithContext(context.Context) MetastoreConfigPtrOutput
}

type metastoreConfigPtrType MetastoreConfigArgs

func MetastoreConfigPtr(v *MetastoreConfigArgs) MetastoreConfigPtrInput {
	return (*metastoreConfigPtrType)(v)
}

func (*metastoreConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**MetastoreConfig)(nil)).Elem()
}

func (i *metastoreConfigPtrType) ToMetastoreConfigPtrOutput() MetastoreConfigPtrOutput {
	return i.ToMetastoreConfigPtrOutputWithContext(context.Background())
}

func (i *metastoreConfigPtrType) ToMetastoreConfigPtrOutputWithContext(ctx context.Context) MetastoreConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(MetastoreConfigPtrOutput)
}

// Specifies a Metastore configuration.
type MetastoreConfigOutput struct{ *pulumi.OutputState }

func (MetastoreConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*MetastoreConfig)(nil)).Elem()
}

func (o MetastoreConfigOutput) ToMetastoreConfigOutput() MetastoreConfigOutput {
	return o
}

func (o MetastoreConfigOutput) ToMetastoreConfigOutputWithContext(ctx context.Context) MetastoreConfigOutput {
	return o
}

func (o MetastoreConfigOutput) ToMetastoreConfigPtrOutput() MetastoreConfigPtrOutput {
	return o.ToMetastoreConfigPtrOutputWithContext(context.Background())
}

func (o MetastoreConfigOutput) ToMetastoreConfigPtrOutputWithContext(ctx context.Context) MetastoreConfigPtrOutput {
	return o.ApplyT(func(v MetastoreConfig) *MetastoreConfig {
		return &v
	}).(MetastoreConfigPtrOutput)
}

// Required. Resource name of an existing Dataproc Metastore service.Example: projects/[project_id]/locations/[dataproc_region]/services/[service-name]
func (o MetastoreConfigOutput) DataprocMetastoreService() pulumi.StringPtrOutput {
	return o.ApplyT(func(v MetastoreConfig) *string { return v.DataprocMetastoreService }).(pulumi.StringPtrOutput)
}

type MetastoreConfigPtrOutput struct{ *pulumi.OutputState }

func (MetastoreConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**MetastoreConfig)(nil)).Elem()
}

func (o MetastoreConfigPtrOutput) ToMetastoreConfigPtrOutput() MetastoreConfigPtrOutput {
	return o
}

func (o MetastoreConfigPtrOutput) ToMetastoreConfigPtrOutputWithContext(ctx context.Context) MetastoreConfigPtrOutput {
	return o
}

func (o MetastoreConfigPtrOutput) Elem() MetastoreConfigOutput {
	return o.ApplyT(func(v *MetastoreConfig) MetastoreConfig { return *v }).(MetastoreConfigOutput)
}

// Required. Resource name of an existing Dataproc Metastore service.Example: projects/[project_id]/locations/[dataproc_region]/services/[service-name]
func (o MetastoreConfigPtrOutput) DataprocMetastoreService() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *MetastoreConfig) *string {
		if v == nil {
			return nil
		}
		return v.DataprocMetastoreService
	}).(pulumi.StringPtrOutput)
}

// A full, namespace-isolated deployment target for an existing GKE cluster.
type NamespacedGkeDeploymentTarget struct {
	// Optional. A namespace within the GKE cluster to deploy into.
	ClusterNamespace *string `pulumi:"clusterNamespace"`
	// Optional. The target GKE cluster to deploy to. Format: 'projects/{project}/locations/{location}/clusters/{cluster_id}'
	TargetGkeCluster *string `pulumi:"targetGkeCluster"`
}

// NamespacedGkeDeploymentTargetInput is an input type that accepts NamespacedGkeDeploymentTargetArgs and NamespacedGkeDeploymentTargetOutput values.
// You can construct a concrete instance of `NamespacedGkeDeploymentTargetInput` via:
//
//          NamespacedGkeDeploymentTargetArgs{...}
type NamespacedGkeDeploymentTargetInput interface {
	pulumi.Input

	ToNamespacedGkeDeploymentTargetOutput() NamespacedGkeDeploymentTargetOutput
	ToNamespacedGkeDeploymentTargetOutputWithContext(context.Context) NamespacedGkeDeploymentTargetOutput
}

// A full, namespace-isolated deployment target for an existing GKE cluster.
type NamespacedGkeDeploymentTargetArgs struct {
	// Optional. A namespace within the GKE cluster to deploy into.
	ClusterNamespace pulumi.StringPtrInput `pulumi:"clusterNamespace"`
	// Optional. The target GKE cluster to deploy to. Format: 'projects/{project}/locations/{location}/clusters/{cluster_id}'
	TargetGkeCluster pulumi.StringPtrInput `pulumi:"targetGkeCluster"`
}

func (NamespacedGkeDeploymentTargetArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*NamespacedGkeDeploymentTarget)(nil)).Elem()
}

func (i NamespacedGkeDeploymentTargetArgs) ToNamespacedGkeDeploymentTargetOutput() NamespacedGkeDeploymentTargetOutput {
	return i.ToNamespacedGkeDeploymentTargetOutputWithContext(context.Background())
}

func (i NamespacedGkeDeploymentTargetArgs) ToNamespacedGkeDeploymentTargetOutputWithContext(ctx context.Context) NamespacedGkeDeploymentTargetOutput {
	return pulumi.ToOutputWithContext(ctx, i).(NamespacedGkeDeploymentTargetOutput)
}

func (i NamespacedGkeDeploymentTargetArgs) ToNamespacedGkeDeploymentTargetPtrOutput() NamespacedGkeDeploymentTargetPtrOutput {
	return i.ToNamespacedGkeDeploymentTargetPtrOutputWithContext(context.Background())
}

func (i NamespacedGkeDeploymentTargetArgs) ToNamespacedGkeDeploymentTargetPtrOutputWithContext(ctx context.Context) NamespacedGkeDeploymentTargetPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(NamespacedGkeDeploymentTargetOutput).ToNamespacedGkeDeploymentTargetPtrOutputWithContext(ctx)
}

// NamespacedGkeDeploymentTargetPtrInput is an input type that accepts NamespacedGkeDeploymentTargetArgs, NamespacedGkeDeploymentTargetPtr and NamespacedGkeDeploymentTargetPtrOutput values.
// You can construct a concrete instance of `NamespacedGkeDeploymentTargetPtrInput` via:
//
//          NamespacedGkeDeploymentTargetArgs{...}
//
//  or:
//
//          nil
type NamespacedGkeDeploymentTargetPtrInput interface {
	pulumi.Input

	ToNamespacedGkeDeploymentTargetPtrOutput() NamespacedGkeDeploymentTargetPtrOutput
	ToNamespacedGkeDeploymentTargetPtrOutputWithContext(context.Context) NamespacedGkeDeploymentTargetPtrOutput
}

type namespacedGkeDeploymentTargetPtrType NamespacedGkeDeploymentTargetArgs

func NamespacedGkeDeploymentTargetPtr(v *NamespacedGkeDeploymentTargetArgs) NamespacedGkeDeploymentTargetPtrInput {
	return (*namespacedGkeDeploymentTargetPtrType)(v)
}

func (*namespacedGkeDeploymentTargetPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**NamespacedGkeDeploymentTarget)(nil)).Elem()
}

func (i *namespacedGkeDeploymentTargetPtrType) ToNamespacedGkeDeploymentTargetPtrOutput() NamespacedGkeDeploymentTargetPtrOutput {
	return i.ToNamespacedGkeDeploymentTargetPtrOutputWithContext(context.Background())
}

func (i *namespacedGkeDeploymentTargetPtrType) ToNamespacedGkeDeploymentTargetPtrOutputWithContext(ctx context.Context) NamespacedGkeDeploymentTargetPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(NamespacedGkeDeploymentTargetPtrOutput)
}

// A full, namespace-isolated deployment target for an existing GKE cluster.
type NamespacedGkeDeploymentTargetOutput struct{ *pulumi.OutputState }

func (NamespacedGkeDeploymentTargetOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*NamespacedGkeDeploymentTarget)(nil)).Elem()
}

func (o NamespacedGkeDeploymentTargetOutput) ToNamespacedGkeDeploymentTargetOutput() NamespacedGkeDeploymentTargetOutput {
	return o
}

func (o NamespacedGkeDeploymentTargetOutput) ToNamespacedGkeDeploymentTargetOutputWithContext(ctx context.Context) NamespacedGkeDeploymentTargetOutput {
	return o
}

func (o NamespacedGkeDeploymentTargetOutput) ToNamespacedGkeDeploymentTargetPtrOutput() NamespacedGkeDeploymentTargetPtrOutput {
	return o.ToNamespacedGkeDeploymentTargetPtrOutputWithContext(context.Background())
}

func (o NamespacedGkeDeploymentTargetOutput) ToNamespacedGkeDeploymentTargetPtrOutputWithContext(ctx context.Context) NamespacedGkeDeploymentTargetPtrOutput {
	return o.ApplyT(func(v NamespacedGkeDeploymentTarget) *NamespacedGkeDeploymentTarget {
		return &v
	}).(NamespacedGkeDeploymentTargetPtrOutput)
}

// Optional. A namespace within the GKE cluster to deploy into.
func (o NamespacedGkeDeploymentTargetOutput) ClusterNamespace() pulumi.StringPtrOutput {
	return o.ApplyT(func(v NamespacedGkeDeploymentTarget) *string { return v.ClusterNamespace }).(pulumi.StringPtrOutput)
}

// Optional. The target GKE cluster to deploy to. Format: 'projects/{project}/locations/{location}/clusters/{cluster_id}'
func (o NamespacedGkeDeploymentTargetOutput) TargetGkeCluster() pulumi.StringPtrOutput {
	return o.ApplyT(func(v NamespacedGkeDeploymentTarget) *string { return v.TargetGkeCluster }).(pulumi.StringPtrOutput)
}

type NamespacedGkeDeploymentTargetPtrOutput struct{ *pulumi.OutputState }

func (NamespacedGkeDeploymentTargetPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**NamespacedGkeDeploymentTarget)(nil)).Elem()
}

func (o NamespacedGkeDeploymentTargetPtrOutput) ToNamespacedGkeDeploymentTargetPtrOutput() NamespacedGkeDeploymentTargetPtrOutput {
	return o
}

func (o NamespacedGkeDeploymentTargetPtrOutput) ToNamespacedGkeDeploymentTargetPtrOutputWithContext(ctx context.Context) NamespacedGkeDeploymentTargetPtrOutput {
	return o
}

func (o NamespacedGkeDeploymentTargetPtrOutput) Elem() NamespacedGkeDeploymentTargetOutput {
	return o.ApplyT(func(v *NamespacedGkeDeploymentTarget) NamespacedGkeDeploymentTarget { return *v }).(NamespacedGkeDeploymentTargetOutput)
}

// Optional. A namespace within the GKE cluster to deploy into.
func (o NamespacedGkeDeploymentTargetPtrOutput) ClusterNamespace() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *NamespacedGkeDeploymentTarget) *string {
		if v == nil {
			return nil
		}
		return v.ClusterNamespace
	}).(pulumi.StringPtrOutput)
}

// Optional. The target GKE cluster to deploy to. Format: 'projects/{project}/locations/{location}/clusters/{cluster_id}'
func (o NamespacedGkeDeploymentTargetPtrOutput) TargetGkeCluster() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *NamespacedGkeDeploymentTarget) *string {
		if v == nil {
			return nil
		}
		return v.TargetGkeCluster
	}).(pulumi.StringPtrOutput)
}

// Node Group Affinity for clusters using sole-tenant node groups.
type NodeGroupAffinity struct {
	// Required. The URI of a sole-tenant node group resource (https://cloud.google.com/compute/docs/reference/rest/v1/nodeGroups) that the cluster will be created on.A full URL, partial URI, or node group name are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/zones/us-central1-a/nodeGroups/node-group-1 projects/[project_id]/zones/us-central1-a/nodeGroups/node-group-1 node-group-1
	NodeGroupUri *string `pulumi:"nodeGroupUri"`
}

// NodeGroupAffinityInput is an input type that accepts NodeGroupAffinityArgs and NodeGroupAffinityOutput values.
// You can construct a concrete instance of `NodeGroupAffinityInput` via:
//
//          NodeGroupAffinityArgs{...}
type NodeGroupAffinityInput interface {
	pulumi.Input

	ToNodeGroupAffinityOutput() NodeGroupAffinityOutput
	ToNodeGroupAffinityOutputWithContext(context.Context) NodeGroupAffinityOutput
}

// Node Group Affinity for clusters using sole-tenant node groups.
type NodeGroupAffinityArgs struct {
	// Required. The URI of a sole-tenant node group resource (https://cloud.google.com/compute/docs/reference/rest/v1/nodeGroups) that the cluster will be created on.A full URL, partial URI, or node group name are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/zones/us-central1-a/nodeGroups/node-group-1 projects/[project_id]/zones/us-central1-a/nodeGroups/node-group-1 node-group-1
	NodeGroupUri pulumi.StringPtrInput `pulumi:"nodeGroupUri"`
}

func (NodeGroupAffinityArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*NodeGroupAffinity)(nil)).Elem()
}

func (i NodeGroupAffinityArgs) ToNodeGroupAffinityOutput() NodeGroupAffinityOutput {
	return i.ToNodeGroupAffinityOutputWithContext(context.Background())
}

func (i NodeGroupAffinityArgs) ToNodeGroupAffinityOutputWithContext(ctx context.Context) NodeGroupAffinityOutput {
	return pulumi.ToOutputWithContext(ctx, i).(NodeGroupAffinityOutput)
}

func (i NodeGroupAffinityArgs) ToNodeGroupAffinityPtrOutput() NodeGroupAffinityPtrOutput {
	return i.ToNodeGroupAffinityPtrOutputWithContext(context.Background())
}

func (i NodeGroupAffinityArgs) ToNodeGroupAffinityPtrOutputWithContext(ctx context.Context) NodeGroupAffinityPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(NodeGroupAffinityOutput).ToNodeGroupAffinityPtrOutputWithContext(ctx)
}

// NodeGroupAffinityPtrInput is an input type that accepts NodeGroupAffinityArgs, NodeGroupAffinityPtr and NodeGroupAffinityPtrOutput values.
// You can construct a concrete instance of `NodeGroupAffinityPtrInput` via:
//
//          NodeGroupAffinityArgs{...}
//
//  or:
//
//          nil
type NodeGroupAffinityPtrInput interface {
	pulumi.Input

	ToNodeGroupAffinityPtrOutput() NodeGroupAffinityPtrOutput
	ToNodeGroupAffinityPtrOutputWithContext(context.Context) NodeGroupAffinityPtrOutput
}

type nodeGroupAffinityPtrType NodeGroupAffinityArgs

func NodeGroupAffinityPtr(v *NodeGroupAffinityArgs) NodeGroupAffinityPtrInput {
	return (*nodeGroupAffinityPtrType)(v)
}

func (*nodeGroupAffinityPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**NodeGroupAffinity)(nil)).Elem()
}

func (i *nodeGroupAffinityPtrType) ToNodeGroupAffinityPtrOutput() NodeGroupAffinityPtrOutput {
	return i.ToNodeGroupAffinityPtrOutputWithContext(context.Background())
}

func (i *nodeGroupAffinityPtrType) ToNodeGroupAffinityPtrOutputWithContext(ctx context.Context) NodeGroupAffinityPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(NodeGroupAffinityPtrOutput)
}

// Node Group Affinity for clusters using sole-tenant node groups.
type NodeGroupAffinityOutput struct{ *pulumi.OutputState }

func (NodeGroupAffinityOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*NodeGroupAffinity)(nil)).Elem()
}

func (o NodeGroupAffinityOutput) ToNodeGroupAffinityOutput() NodeGroupAffinityOutput {
	return o
}

func (o NodeGroupAffinityOutput) ToNodeGroupAffinityOutputWithContext(ctx context.Context) NodeGroupAffinityOutput {
	return o
}

func (o NodeGroupAffinityOutput) ToNodeGroupAffinityPtrOutput() NodeGroupAffinityPtrOutput {
	return o.ToNodeGroupAffinityPtrOutputWithContext(context.Background())
}

func (o NodeGroupAffinityOutput) ToNodeGroupAffinityPtrOutputWithContext(ctx context.Context) NodeGroupAffinityPtrOutput {
	return o.ApplyT(func(v NodeGroupAffinity) *NodeGroupAffinity {
		return &v
	}).(NodeGroupAffinityPtrOutput)
}

// Required. The URI of a sole-tenant node group resource (https://cloud.google.com/compute/docs/reference/rest/v1/nodeGroups) that the cluster will be created on.A full URL, partial URI, or node group name are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/zones/us-central1-a/nodeGroups/node-group-1 projects/[project_id]/zones/us-central1-a/nodeGroups/node-group-1 node-group-1
func (o NodeGroupAffinityOutput) NodeGroupUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v NodeGroupAffinity) *string { return v.NodeGroupUri }).(pulumi.StringPtrOutput)
}

type NodeGroupAffinityPtrOutput struct{ *pulumi.OutputState }

func (NodeGroupAffinityPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**NodeGroupAffinity)(nil)).Elem()
}

func (o NodeGroupAffinityPtrOutput) ToNodeGroupAffinityPtrOutput() NodeGroupAffinityPtrOutput {
	return o
}

func (o NodeGroupAffinityPtrOutput) ToNodeGroupAffinityPtrOutputWithContext(ctx context.Context) NodeGroupAffinityPtrOutput {
	return o
}

func (o NodeGroupAffinityPtrOutput) Elem() NodeGroupAffinityOutput {
	return o.ApplyT(func(v *NodeGroupAffinity) NodeGroupAffinity { return *v }).(NodeGroupAffinityOutput)
}

// Required. The URI of a sole-tenant node group resource (https://cloud.google.com/compute/docs/reference/rest/v1/nodeGroups) that the cluster will be created on.A full URL, partial URI, or node group name are valid. Examples: https://www.googleapis.com/compute/v1/projects/[project_id]/zones/us-central1-a/nodeGroups/node-group-1 projects/[project_id]/zones/us-central1-a/nodeGroups/node-group-1 node-group-1
func (o NodeGroupAffinityPtrOutput) NodeGroupUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *NodeGroupAffinity) *string {
		if v == nil {
			return nil
		}
		return v.NodeGroupUri
	}).(pulumi.StringPtrOutput)
}

// Specifies an executable to run on a fully configured node and a timeout period for executable completion.
type NodeInitializationAction struct {
	// Required. Cloud Storage URI of executable file.
	ExecutableFile *string `pulumi:"executableFile"`
	// Optional. Amount of time executable has to complete. Default is 10 minutes (see JSON representation of Duration (https://developers.google.com/protocol-buffers/docs/proto3#json)).Cluster creation fails with an explanatory error message (the name of the executable that caused the error and the exceeded timeout period) if the executable is not completed at end of the timeout period.
	ExecutionTimeout *string `pulumi:"executionTimeout"`
}

// NodeInitializationActionInput is an input type that accepts NodeInitializationActionArgs and NodeInitializationActionOutput values.
// You can construct a concrete instance of `NodeInitializationActionInput` via:
//
//          NodeInitializationActionArgs{...}
type NodeInitializationActionInput interface {
	pulumi.Input

	ToNodeInitializationActionOutput() NodeInitializationActionOutput
	ToNodeInitializationActionOutputWithContext(context.Context) NodeInitializationActionOutput
}

// Specifies an executable to run on a fully configured node and a timeout period for executable completion.
type NodeInitializationActionArgs struct {
	// Required. Cloud Storage URI of executable file.
	ExecutableFile pulumi.StringPtrInput `pulumi:"executableFile"`
	// Optional. Amount of time executable has to complete. Default is 10 minutes (see JSON representation of Duration (https://developers.google.com/protocol-buffers/docs/proto3#json)).Cluster creation fails with an explanatory error message (the name of the executable that caused the error and the exceeded timeout period) if the executable is not completed at end of the timeout period.
	ExecutionTimeout pulumi.StringPtrInput `pulumi:"executionTimeout"`
}

func (NodeInitializationActionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*NodeInitializationAction)(nil)).Elem()
}

func (i NodeInitializationActionArgs) ToNodeInitializationActionOutput() NodeInitializationActionOutput {
	return i.ToNodeInitializationActionOutputWithContext(context.Background())
}

func (i NodeInitializationActionArgs) ToNodeInitializationActionOutputWithContext(ctx context.Context) NodeInitializationActionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(NodeInitializationActionOutput)
}

// NodeInitializationActionArrayInput is an input type that accepts NodeInitializationActionArray and NodeInitializationActionArrayOutput values.
// You can construct a concrete instance of `NodeInitializationActionArrayInput` via:
//
//          NodeInitializationActionArray{ NodeInitializationActionArgs{...} }
type NodeInitializationActionArrayInput interface {
	pulumi.Input

	ToNodeInitializationActionArrayOutput() NodeInitializationActionArrayOutput
	ToNodeInitializationActionArrayOutputWithContext(context.Context) NodeInitializationActionArrayOutput
}

type NodeInitializationActionArray []NodeInitializationActionInput

func (NodeInitializationActionArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]NodeInitializationAction)(nil)).Elem()
}

func (i NodeInitializationActionArray) ToNodeInitializationActionArrayOutput() NodeInitializationActionArrayOutput {
	return i.ToNodeInitializationActionArrayOutputWithContext(context.Background())
}

func (i NodeInitializationActionArray) ToNodeInitializationActionArrayOutputWithContext(ctx context.Context) NodeInitializationActionArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(NodeInitializationActionArrayOutput)
}

// Specifies an executable to run on a fully configured node and a timeout period for executable completion.
type NodeInitializationActionOutput struct{ *pulumi.OutputState }

func (NodeInitializationActionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*NodeInitializationAction)(nil)).Elem()
}

func (o NodeInitializationActionOutput) ToNodeInitializationActionOutput() NodeInitializationActionOutput {
	return o
}

func (o NodeInitializationActionOutput) ToNodeInitializationActionOutputWithContext(ctx context.Context) NodeInitializationActionOutput {
	return o
}

// Required. Cloud Storage URI of executable file.
func (o NodeInitializationActionOutput) ExecutableFile() pulumi.StringPtrOutput {
	return o.ApplyT(func(v NodeInitializationAction) *string { return v.ExecutableFile }).(pulumi.StringPtrOutput)
}

// Optional. Amount of time executable has to complete. Default is 10 minutes (see JSON representation of Duration (https://developers.google.com/protocol-buffers/docs/proto3#json)).Cluster creation fails with an explanatory error message (the name of the executable that caused the error and the exceeded timeout period) if the executable is not completed at end of the timeout period.
func (o NodeInitializationActionOutput) ExecutionTimeout() pulumi.StringPtrOutput {
	return o.ApplyT(func(v NodeInitializationAction) *string { return v.ExecutionTimeout }).(pulumi.StringPtrOutput)
}

type NodeInitializationActionArrayOutput struct{ *pulumi.OutputState }

func (NodeInitializationActionArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]NodeInitializationAction)(nil)).Elem()
}

func (o NodeInitializationActionArrayOutput) ToNodeInitializationActionArrayOutput() NodeInitializationActionArrayOutput {
	return o
}

func (o NodeInitializationActionArrayOutput) ToNodeInitializationActionArrayOutputWithContext(ctx context.Context) NodeInitializationActionArrayOutput {
	return o
}

func (o NodeInitializationActionArrayOutput) Index(i pulumi.IntInput) NodeInitializationActionOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) NodeInitializationAction {
		return vs[0].([]NodeInitializationAction)[vs[1].(int)]
	}).(NodeInitializationActionOutput)
}

// A job executed by the workflow.
type OrderedJob struct {
	// Optional. Job is a Hadoop job.
	HadoopJob *HadoopJob `pulumi:"hadoopJob"`
	// Optional. Job is a Hive job.
	HiveJob *HiveJob `pulumi:"hiveJob"`
	// Optional. The labels to associate with this job.Label keys must be between 1 and 63 characters long, and must conform to the following regular expression: \p{Ll}\p{Lo}{0,62}Label values must be between 1 and 63 characters long, and must conform to the following regular expression: \p{Ll}\p{Lo}\p{N}_-{0,63}No more than 32 labels can be associated with a given job.
	Labels map[string]string `pulumi:"labels"`
	// Optional. Job is a Pig job.
	PigJob *PigJob `pulumi:"pigJob"`
	// Optional. The optional list of prerequisite job step_ids. If not specified, the job will start at the beginning of workflow.
	PrerequisiteStepIds []string `pulumi:"prerequisiteStepIds"`
	// Optional. Job is a Presto job.
	PrestoJob *PrestoJob `pulumi:"prestoJob"`
	// Optional. Job is a PySpark job.
	PysparkJob *PySparkJob `pulumi:"pysparkJob"`
	// Optional. Job scheduling configuration.
	Scheduling *JobScheduling `pulumi:"scheduling"`
	// Optional. Job is a Spark job.
	SparkJob *SparkJob `pulumi:"sparkJob"`
	// Optional. Job is a SparkR job.
	SparkRJob *SparkRJob `pulumi:"sparkRJob"`
	// Optional. Job is a SparkSql job.
	SparkSqlJob *SparkSqlJob `pulumi:"sparkSqlJob"`
	// Required. The step id. The id must be unique among all jobs within the template.The step id is used as prefix for job id, as job goog-dataproc-workflow-step-id label, and in prerequisiteStepIds field from other steps.The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_), and hyphens (-). Cannot begin or end with underscore or hyphen. Must consist of between 3 and 50 characters.
	StepId *string `pulumi:"stepId"`
}

// OrderedJobInput is an input type that accepts OrderedJobArgs and OrderedJobOutput values.
// You can construct a concrete instance of `OrderedJobInput` via:
//
//          OrderedJobArgs{...}
type OrderedJobInput interface {
	pulumi.Input

	ToOrderedJobOutput() OrderedJobOutput
	ToOrderedJobOutputWithContext(context.Context) OrderedJobOutput
}

// A job executed by the workflow.
type OrderedJobArgs struct {
	// Optional. Job is a Hadoop job.
	HadoopJob HadoopJobPtrInput `pulumi:"hadoopJob"`
	// Optional. Job is a Hive job.
	HiveJob HiveJobPtrInput `pulumi:"hiveJob"`
	// Optional. The labels to associate with this job.Label keys must be between 1 and 63 characters long, and must conform to the following regular expression: \p{Ll}\p{Lo}{0,62}Label values must be between 1 and 63 characters long, and must conform to the following regular expression: \p{Ll}\p{Lo}\p{N}_-{0,63}No more than 32 labels can be associated with a given job.
	Labels pulumi.StringMapInput `pulumi:"labels"`
	// Optional. Job is a Pig job.
	PigJob PigJobPtrInput `pulumi:"pigJob"`
	// Optional. The optional list of prerequisite job step_ids. If not specified, the job will start at the beginning of workflow.
	PrerequisiteStepIds pulumi.StringArrayInput `pulumi:"prerequisiteStepIds"`
	// Optional. Job is a Presto job.
	PrestoJob PrestoJobPtrInput `pulumi:"prestoJob"`
	// Optional. Job is a PySpark job.
	PysparkJob PySparkJobPtrInput `pulumi:"pysparkJob"`
	// Optional. Job scheduling configuration.
	Scheduling JobSchedulingPtrInput `pulumi:"scheduling"`
	// Optional. Job is a Spark job.
	SparkJob SparkJobPtrInput `pulumi:"sparkJob"`
	// Optional. Job is a SparkR job.
	SparkRJob SparkRJobPtrInput `pulumi:"sparkRJob"`
	// Optional. Job is a SparkSql job.
	SparkSqlJob SparkSqlJobPtrInput `pulumi:"sparkSqlJob"`
	// Required. The step id. The id must be unique among all jobs within the template.The step id is used as prefix for job id, as job goog-dataproc-workflow-step-id label, and in prerequisiteStepIds field from other steps.The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_), and hyphens (-). Cannot begin or end with underscore or hyphen. Must consist of between 3 and 50 characters.
	StepId pulumi.StringPtrInput `pulumi:"stepId"`
}

func (OrderedJobArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*OrderedJob)(nil)).Elem()
}

func (i OrderedJobArgs) ToOrderedJobOutput() OrderedJobOutput {
	return i.ToOrderedJobOutputWithContext(context.Background())
}

func (i OrderedJobArgs) ToOrderedJobOutputWithContext(ctx context.Context) OrderedJobOutput {
	return pulumi.ToOutputWithContext(ctx, i).(OrderedJobOutput)
}

// OrderedJobArrayInput is an input type that accepts OrderedJobArray and OrderedJobArrayOutput values.
// You can construct a concrete instance of `OrderedJobArrayInput` via:
//
//          OrderedJobArray{ OrderedJobArgs{...} }
type OrderedJobArrayInput interface {
	pulumi.Input

	ToOrderedJobArrayOutput() OrderedJobArrayOutput
	ToOrderedJobArrayOutputWithContext(context.Context) OrderedJobArrayOutput
}

type OrderedJobArray []OrderedJobInput

func (OrderedJobArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]OrderedJob)(nil)).Elem()
}

func (i OrderedJobArray) ToOrderedJobArrayOutput() OrderedJobArrayOutput {
	return i.ToOrderedJobArrayOutputWithContext(context.Background())
}

func (i OrderedJobArray) ToOrderedJobArrayOutputWithContext(ctx context.Context) OrderedJobArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(OrderedJobArrayOutput)
}

// A job executed by the workflow.
type OrderedJobOutput struct{ *pulumi.OutputState }

func (OrderedJobOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*OrderedJob)(nil)).Elem()
}

func (o OrderedJobOutput) ToOrderedJobOutput() OrderedJobOutput {
	return o
}

func (o OrderedJobOutput) ToOrderedJobOutputWithContext(ctx context.Context) OrderedJobOutput {
	return o
}

// Optional. Job is a Hadoop job.
func (o OrderedJobOutput) HadoopJob() HadoopJobPtrOutput {
	return o.ApplyT(func(v OrderedJob) *HadoopJob { return v.HadoopJob }).(HadoopJobPtrOutput)
}

// Optional. Job is a Hive job.
func (o OrderedJobOutput) HiveJob() HiveJobPtrOutput {
	return o.ApplyT(func(v OrderedJob) *HiveJob { return v.HiveJob }).(HiveJobPtrOutput)
}

// Optional. The labels to associate with this job.Label keys must be between 1 and 63 characters long, and must conform to the following regular expression: \p{Ll}\p{Lo}{0,62}Label values must be between 1 and 63 characters long, and must conform to the following regular expression: \p{Ll}\p{Lo}\p{N}_-{0,63}No more than 32 labels can be associated with a given job.
func (o OrderedJobOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v OrderedJob) map[string]string { return v.Labels }).(pulumi.StringMapOutput)
}

// Optional. Job is a Pig job.
func (o OrderedJobOutput) PigJob() PigJobPtrOutput {
	return o.ApplyT(func(v OrderedJob) *PigJob { return v.PigJob }).(PigJobPtrOutput)
}

// Optional. The optional list of prerequisite job step_ids. If not specified, the job will start at the beginning of workflow.
func (o OrderedJobOutput) PrerequisiteStepIds() pulumi.StringArrayOutput {
	return o.ApplyT(func(v OrderedJob) []string { return v.PrerequisiteStepIds }).(pulumi.StringArrayOutput)
}

// Optional. Job is a Presto job.
func (o OrderedJobOutput) PrestoJob() PrestoJobPtrOutput {
	return o.ApplyT(func(v OrderedJob) *PrestoJob { return v.PrestoJob }).(PrestoJobPtrOutput)
}

// Optional. Job is a PySpark job.
func (o OrderedJobOutput) PysparkJob() PySparkJobPtrOutput {
	return o.ApplyT(func(v OrderedJob) *PySparkJob { return v.PysparkJob }).(PySparkJobPtrOutput)
}

// Optional. Job scheduling configuration.
func (o OrderedJobOutput) Scheduling() JobSchedulingPtrOutput {
	return o.ApplyT(func(v OrderedJob) *JobScheduling { return v.Scheduling }).(JobSchedulingPtrOutput)
}

// Optional. Job is a Spark job.
func (o OrderedJobOutput) SparkJob() SparkJobPtrOutput {
	return o.ApplyT(func(v OrderedJob) *SparkJob { return v.SparkJob }).(SparkJobPtrOutput)
}

// Optional. Job is a SparkR job.
func (o OrderedJobOutput) SparkRJob() SparkRJobPtrOutput {
	return o.ApplyT(func(v OrderedJob) *SparkRJob { return v.SparkRJob }).(SparkRJobPtrOutput)
}

// Optional. Job is a SparkSql job.
func (o OrderedJobOutput) SparkSqlJob() SparkSqlJobPtrOutput {
	return o.ApplyT(func(v OrderedJob) *SparkSqlJob { return v.SparkSqlJob }).(SparkSqlJobPtrOutput)
}

// Required. The step id. The id must be unique among all jobs within the template.The step id is used as prefix for job id, as job goog-dataproc-workflow-step-id label, and in prerequisiteStepIds field from other steps.The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_), and hyphens (-). Cannot begin or end with underscore or hyphen. Must consist of between 3 and 50 characters.
func (o OrderedJobOutput) StepId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v OrderedJob) *string { return v.StepId }).(pulumi.StringPtrOutput)
}

type OrderedJobArrayOutput struct{ *pulumi.OutputState }

func (OrderedJobArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]OrderedJob)(nil)).Elem()
}

func (o OrderedJobArrayOutput) ToOrderedJobArrayOutput() OrderedJobArrayOutput {
	return o
}

func (o OrderedJobArrayOutput) ToOrderedJobArrayOutputWithContext(ctx context.Context) OrderedJobArrayOutput {
	return o
}

func (o OrderedJobArrayOutput) Index(i pulumi.IntInput) OrderedJobOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) OrderedJob {
		return vs[0].([]OrderedJob)[vs[1].(int)]
	}).(OrderedJobOutput)
}

// Configuration for parameter validation.
type ParameterValidation struct {
	// Validation based on regular expressions.
	Regex *RegexValidation `pulumi:"regex"`
	// Validation based on a list of allowed values.
	Values *ValueValidation `pulumi:"values"`
}

// ParameterValidationInput is an input type that accepts ParameterValidationArgs and ParameterValidationOutput values.
// You can construct a concrete instance of `ParameterValidationInput` via:
//
//          ParameterValidationArgs{...}
type ParameterValidationInput interface {
	pulumi.Input

	ToParameterValidationOutput() ParameterValidationOutput
	ToParameterValidationOutputWithContext(context.Context) ParameterValidationOutput
}

// Configuration for parameter validation.
type ParameterValidationArgs struct {
	// Validation based on regular expressions.
	Regex RegexValidationPtrInput `pulumi:"regex"`
	// Validation based on a list of allowed values.
	Values ValueValidationPtrInput `pulumi:"values"`
}

func (ParameterValidationArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ParameterValidation)(nil)).Elem()
}

func (i ParameterValidationArgs) ToParameterValidationOutput() ParameterValidationOutput {
	return i.ToParameterValidationOutputWithContext(context.Background())
}

func (i ParameterValidationArgs) ToParameterValidationOutputWithContext(ctx context.Context) ParameterValidationOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ParameterValidationOutput)
}

func (i ParameterValidationArgs) ToParameterValidationPtrOutput() ParameterValidationPtrOutput {
	return i.ToParameterValidationPtrOutputWithContext(context.Background())
}

func (i ParameterValidationArgs) ToParameterValidationPtrOutputWithContext(ctx context.Context) ParameterValidationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ParameterValidationOutput).ToParameterValidationPtrOutputWithContext(ctx)
}

// ParameterValidationPtrInput is an input type that accepts ParameterValidationArgs, ParameterValidationPtr and ParameterValidationPtrOutput values.
// You can construct a concrete instance of `ParameterValidationPtrInput` via:
//
//          ParameterValidationArgs{...}
//
//  or:
//
//          nil
type ParameterValidationPtrInput interface {
	pulumi.Input

	ToParameterValidationPtrOutput() ParameterValidationPtrOutput
	ToParameterValidationPtrOutputWithContext(context.Context) ParameterValidationPtrOutput
}

type parameterValidationPtrType ParameterValidationArgs

func ParameterValidationPtr(v *ParameterValidationArgs) ParameterValidationPtrInput {
	return (*parameterValidationPtrType)(v)
}

func (*parameterValidationPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ParameterValidation)(nil)).Elem()
}

func (i *parameterValidationPtrType) ToParameterValidationPtrOutput() ParameterValidationPtrOutput {
	return i.ToParameterValidationPtrOutputWithContext(context.Background())
}

func (i *parameterValidationPtrType) ToParameterValidationPtrOutputWithContext(ctx context.Context) ParameterValidationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ParameterValidationPtrOutput)
}

// Configuration for parameter validation.
type ParameterValidationOutput struct{ *pulumi.OutputState }

func (ParameterValidationOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ParameterValidation)(nil)).Elem()
}

func (o ParameterValidationOutput) ToParameterValidationOutput() ParameterValidationOutput {
	return o
}

func (o ParameterValidationOutput) ToParameterValidationOutputWithContext(ctx context.Context) ParameterValidationOutput {
	return o
}

func (o ParameterValidationOutput) ToParameterValidationPtrOutput() ParameterValidationPtrOutput {
	return o.ToParameterValidationPtrOutputWithContext(context.Background())
}

func (o ParameterValidationOutput) ToParameterValidationPtrOutputWithContext(ctx context.Context) ParameterValidationPtrOutput {
	return o.ApplyT(func(v ParameterValidation) *ParameterValidation {
		return &v
	}).(ParameterValidationPtrOutput)
}

// Validation based on regular expressions.
func (o ParameterValidationOutput) Regex() RegexValidationPtrOutput {
	return o.ApplyT(func(v ParameterValidation) *RegexValidation { return v.Regex }).(RegexValidationPtrOutput)
}

// Validation based on a list of allowed values.
func (o ParameterValidationOutput) Values() ValueValidationPtrOutput {
	return o.ApplyT(func(v ParameterValidation) *ValueValidation { return v.Values }).(ValueValidationPtrOutput)
}

type ParameterValidationPtrOutput struct{ *pulumi.OutputState }

func (ParameterValidationPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ParameterValidation)(nil)).Elem()
}

func (o ParameterValidationPtrOutput) ToParameterValidationPtrOutput() ParameterValidationPtrOutput {
	return o
}

func (o ParameterValidationPtrOutput) ToParameterValidationPtrOutputWithContext(ctx context.Context) ParameterValidationPtrOutput {
	return o
}

func (o ParameterValidationPtrOutput) Elem() ParameterValidationOutput {
	return o.ApplyT(func(v *ParameterValidation) ParameterValidation { return *v }).(ParameterValidationOutput)
}

// Validation based on regular expressions.
func (o ParameterValidationPtrOutput) Regex() RegexValidationPtrOutput {
	return o.ApplyT(func(v *ParameterValidation) *RegexValidation {
		if v == nil {
			return nil
		}
		return v.Regex
	}).(RegexValidationPtrOutput)
}

// Validation based on a list of allowed values.
func (o ParameterValidationPtrOutput) Values() ValueValidationPtrOutput {
	return o.ApplyT(func(v *ParameterValidation) *ValueValidation {
		if v == nil {
			return nil
		}
		return v.Values
	}).(ValueValidationPtrOutput)
}

// A Dataproc job for running Apache Pig (https://pig.apache.org/) queries on YARN.
type PigJob struct {
	// Optional. Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries.
	ContinueOnFailure *bool `pulumi:"continueOnFailure"`
	// Optional. HCFS URIs of jar files to add to the CLASSPATH of the Pig Client and Hadoop MapReduce (MR) tasks. Can contain Pig UDFs.
	JarFileUris []string `pulumi:"jarFileUris"`
	// Optional. The runtime log config for job execution.
	LoggingConfig *LoggingConfig `pulumi:"loggingConfig"`
	// Optional. A mapping of property names to values, used to configure Pig. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site.xml, /etc/pig/conf/pig.properties, and classes in user code.
	Properties map[string]string `pulumi:"properties"`
	// The HCFS URI of the script that contains the Pig queries.
	QueryFileUri *string `pulumi:"queryFileUri"`
	// A list of queries.
	QueryList *QueryList `pulumi:"queryList"`
	// Optional. Mapping of query variable names to values (equivalent to the Pig command: name=[value]).
	ScriptVariables map[string]string `pulumi:"scriptVariables"`
}

// PigJobInput is an input type that accepts PigJobArgs and PigJobOutput values.
// You can construct a concrete instance of `PigJobInput` via:
//
//          PigJobArgs{...}
type PigJobInput interface {
	pulumi.Input

	ToPigJobOutput() PigJobOutput
	ToPigJobOutputWithContext(context.Context) PigJobOutput
}

// A Dataproc job for running Apache Pig (https://pig.apache.org/) queries on YARN.
type PigJobArgs struct {
	// Optional. Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries.
	ContinueOnFailure pulumi.BoolPtrInput `pulumi:"continueOnFailure"`
	// Optional. HCFS URIs of jar files to add to the CLASSPATH of the Pig Client and Hadoop MapReduce (MR) tasks. Can contain Pig UDFs.
	JarFileUris pulumi.StringArrayInput `pulumi:"jarFileUris"`
	// Optional. The runtime log config for job execution.
	LoggingConfig LoggingConfigPtrInput `pulumi:"loggingConfig"`
	// Optional. A mapping of property names to values, used to configure Pig. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site.xml, /etc/pig/conf/pig.properties, and classes in user code.
	Properties pulumi.StringMapInput `pulumi:"properties"`
	// The HCFS URI of the script that contains the Pig queries.
	QueryFileUri pulumi.StringPtrInput `pulumi:"queryFileUri"`
	// A list of queries.
	QueryList QueryListPtrInput `pulumi:"queryList"`
	// Optional. Mapping of query variable names to values (equivalent to the Pig command: name=[value]).
	ScriptVariables pulumi.StringMapInput `pulumi:"scriptVariables"`
}

func (PigJobArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*PigJob)(nil)).Elem()
}

func (i PigJobArgs) ToPigJobOutput() PigJobOutput {
	return i.ToPigJobOutputWithContext(context.Background())
}

func (i PigJobArgs) ToPigJobOutputWithContext(ctx context.Context) PigJobOutput {
	return pulumi.ToOutputWithContext(ctx, i).(PigJobOutput)
}

func (i PigJobArgs) ToPigJobPtrOutput() PigJobPtrOutput {
	return i.ToPigJobPtrOutputWithContext(context.Background())
}

func (i PigJobArgs) ToPigJobPtrOutputWithContext(ctx context.Context) PigJobPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(PigJobOutput).ToPigJobPtrOutputWithContext(ctx)
}

// PigJobPtrInput is an input type that accepts PigJobArgs, PigJobPtr and PigJobPtrOutput values.
// You can construct a concrete instance of `PigJobPtrInput` via:
//
//          PigJobArgs{...}
//
//  or:
//
//          nil
type PigJobPtrInput interface {
	pulumi.Input

	ToPigJobPtrOutput() PigJobPtrOutput
	ToPigJobPtrOutputWithContext(context.Context) PigJobPtrOutput
}

type pigJobPtrType PigJobArgs

func PigJobPtr(v *PigJobArgs) PigJobPtrInput {
	return (*pigJobPtrType)(v)
}

func (*pigJobPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**PigJob)(nil)).Elem()
}

func (i *pigJobPtrType) ToPigJobPtrOutput() PigJobPtrOutput {
	return i.ToPigJobPtrOutputWithContext(context.Background())
}

func (i *pigJobPtrType) ToPigJobPtrOutputWithContext(ctx context.Context) PigJobPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(PigJobPtrOutput)
}

// A Dataproc job for running Apache Pig (https://pig.apache.org/) queries on YARN.
type PigJobOutput struct{ *pulumi.OutputState }

func (PigJobOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*PigJob)(nil)).Elem()
}

func (o PigJobOutput) ToPigJobOutput() PigJobOutput {
	return o
}

func (o PigJobOutput) ToPigJobOutputWithContext(ctx context.Context) PigJobOutput {
	return o
}

func (o PigJobOutput) ToPigJobPtrOutput() PigJobPtrOutput {
	return o.ToPigJobPtrOutputWithContext(context.Background())
}

func (o PigJobOutput) ToPigJobPtrOutputWithContext(ctx context.Context) PigJobPtrOutput {
	return o.ApplyT(func(v PigJob) *PigJob {
		return &v
	}).(PigJobPtrOutput)
}

// Optional. Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries.
func (o PigJobOutput) ContinueOnFailure() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v PigJob) *bool { return v.ContinueOnFailure }).(pulumi.BoolPtrOutput)
}

// Optional. HCFS URIs of jar files to add to the CLASSPATH of the Pig Client and Hadoop MapReduce (MR) tasks. Can contain Pig UDFs.
func (o PigJobOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v PigJob) []string { return v.JarFileUris }).(pulumi.StringArrayOutput)
}

// Optional. The runtime log config for job execution.
func (o PigJobOutput) LoggingConfig() LoggingConfigPtrOutput {
	return o.ApplyT(func(v PigJob) *LoggingConfig { return v.LoggingConfig }).(LoggingConfigPtrOutput)
}

// Optional. A mapping of property names to values, used to configure Pig. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site.xml, /etc/pig/conf/pig.properties, and classes in user code.
func (o PigJobOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v PigJob) map[string]string { return v.Properties }).(pulumi.StringMapOutput)
}

// The HCFS URI of the script that contains the Pig queries.
func (o PigJobOutput) QueryFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v PigJob) *string { return v.QueryFileUri }).(pulumi.StringPtrOutput)
}

// A list of queries.
func (o PigJobOutput) QueryList() QueryListPtrOutput {
	return o.ApplyT(func(v PigJob) *QueryList { return v.QueryList }).(QueryListPtrOutput)
}

// Optional. Mapping of query variable names to values (equivalent to the Pig command: name=[value]).
func (o PigJobOutput) ScriptVariables() pulumi.StringMapOutput {
	return o.ApplyT(func(v PigJob) map[string]string { return v.ScriptVariables }).(pulumi.StringMapOutput)
}

type PigJobPtrOutput struct{ *pulumi.OutputState }

func (PigJobPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**PigJob)(nil)).Elem()
}

func (o PigJobPtrOutput) ToPigJobPtrOutput() PigJobPtrOutput {
	return o
}

func (o PigJobPtrOutput) ToPigJobPtrOutputWithContext(ctx context.Context) PigJobPtrOutput {
	return o
}

func (o PigJobPtrOutput) Elem() PigJobOutput {
	return o.ApplyT(func(v *PigJob) PigJob { return *v }).(PigJobOutput)
}

// Optional. Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries.
func (o PigJobPtrOutput) ContinueOnFailure() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *PigJob) *bool {
		if v == nil {
			return nil
		}
		return v.ContinueOnFailure
	}).(pulumi.BoolPtrOutput)
}

// Optional. HCFS URIs of jar files to add to the CLASSPATH of the Pig Client and Hadoop MapReduce (MR) tasks. Can contain Pig UDFs.
func (o PigJobPtrOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *PigJob) []string {
		if v == nil {
			return nil
		}
		return v.JarFileUris
	}).(pulumi.StringArrayOutput)
}

// Optional. The runtime log config for job execution.
func (o PigJobPtrOutput) LoggingConfig() LoggingConfigPtrOutput {
	return o.ApplyT(func(v *PigJob) *LoggingConfig {
		if v == nil {
			return nil
		}
		return v.LoggingConfig
	}).(LoggingConfigPtrOutput)
}

// Optional. A mapping of property names to values, used to configure Pig. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site.xml, /etc/pig/conf/pig.properties, and classes in user code.
func (o PigJobPtrOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v *PigJob) map[string]string {
		if v == nil {
			return nil
		}
		return v.Properties
	}).(pulumi.StringMapOutput)
}

// The HCFS URI of the script that contains the Pig queries.
func (o PigJobPtrOutput) QueryFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *PigJob) *string {
		if v == nil {
			return nil
		}
		return v.QueryFileUri
	}).(pulumi.StringPtrOutput)
}

// A list of queries.
func (o PigJobPtrOutput) QueryList() QueryListPtrOutput {
	return o.ApplyT(func(v *PigJob) *QueryList {
		if v == nil {
			return nil
		}
		return v.QueryList
	}).(QueryListPtrOutput)
}

// Optional. Mapping of query variable names to values (equivalent to the Pig command: name=[value]).
func (o PigJobPtrOutput) ScriptVariables() pulumi.StringMapOutput {
	return o.ApplyT(func(v *PigJob) map[string]string {
		if v == nil {
			return nil
		}
		return v.ScriptVariables
	}).(pulumi.StringMapOutput)
}

// An Identity and Access Management (IAM) policy, which specifies access controls for Google Cloud resources.A Policy is a collection of bindings. A binding binds one or more members to a single role. Members can be user accounts, service accounts, Google groups, and domains (such as G Suite). A role is a named list of permissions; each role can be an IAM predefined role or a user-created custom role.For some types of Google Cloud resources, a binding can also specify a condition, which is a logical expression that allows access to a resource only if the expression evaluates to true. A condition can add constraints based on attributes of the request, the resource, or both. To learn which resources support conditions in their IAM policies, see the IAM documentation (https://cloud.google.com/iam/help/conditions/resource-policies).JSON example: { "bindings": [ { "role": "roles/resourcemanager.organizationAdmin", "members": [ "user:mike@example.com", "group:admins@example.com", "domain:google.com", "serviceAccount:my-project-id@appspot.gserviceaccount.com" ] }, { "role": "roles/resourcemanager.organizationViewer", "members": [ "user:eve@example.com" ], "condition": { "title": "expirable access", "description": "Does not grant access after Sep 2020", "expression": "request.time < timestamp('2020-10-01T00:00:00.000Z')", } } ], "etag": "BwWWja0YfJA=", "version": 3 } YAML example: bindings: - members: - user:mike@example.com - group:admins@example.com - domain:google.com - serviceAccount:my-project-id@appspot.gserviceaccount.com role: roles/resourcemanager.organizationAdmin - members: - user:eve@example.com role: roles/resourcemanager.organizationViewer condition: title: expirable access description: Does not grant access after Sep 2020 expression: request.time < timestamp('2020-10-01T00:00:00.000Z') - etag: BwWWja0YfJA= - version: 3 For a description of IAM and its features, see the IAM documentation (https://cloud.google.com/iam/docs/).
type PolicyType struct {
	// Associates a list of members to a role. Optionally, may specify a condition that determines how and when the bindings are applied. Each of the bindings must contain at least one member.
	Bindings []Binding `pulumi:"bindings"`
	// etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a policy from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform policy updates in order to avoid race conditions: An etag is returned in the response to getIamPolicy, and systems are expected to put that etag in the request to setIamPolicy to ensure that their change will be applied to the same version of the policy.Important: If you use IAM Conditions, you must include the etag field whenever you call setIamPolicy. If you omit this field, then IAM allows you to overwrite a version 3 policy with a version 1 policy, and all of the conditions in the version 3 policy are lost.
	Etag *string `pulumi:"etag"`
	// Specifies the format of the policy.Valid values are 0, 1, and 3. Requests that specify an invalid value are rejected.Any operation that affects conditional role bindings must specify version 3. This requirement applies to the following operations: Getting a policy that includes a conditional role binding Adding a conditional role binding to a policy Changing a conditional role binding in a policy Removing any role binding, with or without a condition, from a policy that includes conditionsImportant: If you use IAM Conditions, you must include the etag field whenever you call setIamPolicy. If you omit this field, then IAM allows you to overwrite a version 3 policy with a version 1 policy, and all of the conditions in the version 3 policy are lost.If a policy does not include any conditions, operations on that policy may specify any valid version or leave the field unset.To learn which resources support conditions in their IAM policies, see the IAM documentation (https://cloud.google.com/iam/help/conditions/resource-policies).
	Version *int `pulumi:"version"`
}

// PolicyTypeInput is an input type that accepts PolicyTypeArgs and PolicyTypeOutput values.
// You can construct a concrete instance of `PolicyTypeInput` via:
//
//          PolicyTypeArgs{...}
type PolicyTypeInput interface {
	pulumi.Input

	ToPolicyTypeOutput() PolicyTypeOutput
	ToPolicyTypeOutputWithContext(context.Context) PolicyTypeOutput
}

// An Identity and Access Management (IAM) policy, which specifies access controls for Google Cloud resources.A Policy is a collection of bindings. A binding binds one or more members to a single role. Members can be user accounts, service accounts, Google groups, and domains (such as G Suite). A role is a named list of permissions; each role can be an IAM predefined role or a user-created custom role.For some types of Google Cloud resources, a binding can also specify a condition, which is a logical expression that allows access to a resource only if the expression evaluates to true. A condition can add constraints based on attributes of the request, the resource, or both. To learn which resources support conditions in their IAM policies, see the IAM documentation (https://cloud.google.com/iam/help/conditions/resource-policies).JSON example: { "bindings": [ { "role": "roles/resourcemanager.organizationAdmin", "members": [ "user:mike@example.com", "group:admins@example.com", "domain:google.com", "serviceAccount:my-project-id@appspot.gserviceaccount.com" ] }, { "role": "roles/resourcemanager.organizationViewer", "members": [ "user:eve@example.com" ], "condition": { "title": "expirable access", "description": "Does not grant access after Sep 2020", "expression": "request.time < timestamp('2020-10-01T00:00:00.000Z')", } } ], "etag": "BwWWja0YfJA=", "version": 3 } YAML example: bindings: - members: - user:mike@example.com - group:admins@example.com - domain:google.com - serviceAccount:my-project-id@appspot.gserviceaccount.com role: roles/resourcemanager.organizationAdmin - members: - user:eve@example.com role: roles/resourcemanager.organizationViewer condition: title: expirable access description: Does not grant access after Sep 2020 expression: request.time < timestamp('2020-10-01T00:00:00.000Z') - etag: BwWWja0YfJA= - version: 3 For a description of IAM and its features, see the IAM documentation (https://cloud.google.com/iam/docs/).
type PolicyTypeArgs struct {
	// Associates a list of members to a role. Optionally, may specify a condition that determines how and when the bindings are applied. Each of the bindings must contain at least one member.
	Bindings BindingArrayInput `pulumi:"bindings"`
	// etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a policy from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform policy updates in order to avoid race conditions: An etag is returned in the response to getIamPolicy, and systems are expected to put that etag in the request to setIamPolicy to ensure that their change will be applied to the same version of the policy.Important: If you use IAM Conditions, you must include the etag field whenever you call setIamPolicy. If you omit this field, then IAM allows you to overwrite a version 3 policy with a version 1 policy, and all of the conditions in the version 3 policy are lost.
	Etag pulumi.StringPtrInput `pulumi:"etag"`
	// Specifies the format of the policy.Valid values are 0, 1, and 3. Requests that specify an invalid value are rejected.Any operation that affects conditional role bindings must specify version 3. This requirement applies to the following operations: Getting a policy that includes a conditional role binding Adding a conditional role binding to a policy Changing a conditional role binding in a policy Removing any role binding, with or without a condition, from a policy that includes conditionsImportant: If you use IAM Conditions, you must include the etag field whenever you call setIamPolicy. If you omit this field, then IAM allows you to overwrite a version 3 policy with a version 1 policy, and all of the conditions in the version 3 policy are lost.If a policy does not include any conditions, operations on that policy may specify any valid version or leave the field unset.To learn which resources support conditions in their IAM policies, see the IAM documentation (https://cloud.google.com/iam/help/conditions/resource-policies).
	Version pulumi.IntPtrInput `pulumi:"version"`
}

func (PolicyTypeArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*PolicyType)(nil)).Elem()
}

func (i PolicyTypeArgs) ToPolicyTypeOutput() PolicyTypeOutput {
	return i.ToPolicyTypeOutputWithContext(context.Background())
}

func (i PolicyTypeArgs) ToPolicyTypeOutputWithContext(ctx context.Context) PolicyTypeOutput {
	return pulumi.ToOutputWithContext(ctx, i).(PolicyTypeOutput)
}

func (i PolicyTypeArgs) ToPolicyTypePtrOutput() PolicyTypePtrOutput {
	return i.ToPolicyTypePtrOutputWithContext(context.Background())
}

func (i PolicyTypeArgs) ToPolicyTypePtrOutputWithContext(ctx context.Context) PolicyTypePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(PolicyTypeOutput).ToPolicyTypePtrOutputWithContext(ctx)
}

// PolicyTypePtrInput is an input type that accepts PolicyTypeArgs, PolicyTypePtr and PolicyTypePtrOutput values.
// You can construct a concrete instance of `PolicyTypePtrInput` via:
//
//          PolicyTypeArgs{...}
//
//  or:
//
//          nil
type PolicyTypePtrInput interface {
	pulumi.Input

	ToPolicyTypePtrOutput() PolicyTypePtrOutput
	ToPolicyTypePtrOutputWithContext(context.Context) PolicyTypePtrOutput
}

type policyTypePtrType PolicyTypeArgs

func PolicyTypePtr(v *PolicyTypeArgs) PolicyTypePtrInput {
	return (*policyTypePtrType)(v)
}

func (*policyTypePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**PolicyType)(nil)).Elem()
}

func (i *policyTypePtrType) ToPolicyTypePtrOutput() PolicyTypePtrOutput {
	return i.ToPolicyTypePtrOutputWithContext(context.Background())
}

func (i *policyTypePtrType) ToPolicyTypePtrOutputWithContext(ctx context.Context) PolicyTypePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(PolicyTypePtrOutput)
}

// An Identity and Access Management (IAM) policy, which specifies access controls for Google Cloud resources.A Policy is a collection of bindings. A binding binds one or more members to a single role. Members can be user accounts, service accounts, Google groups, and domains (such as G Suite). A role is a named list of permissions; each role can be an IAM predefined role or a user-created custom role.For some types of Google Cloud resources, a binding can also specify a condition, which is a logical expression that allows access to a resource only if the expression evaluates to true. A condition can add constraints based on attributes of the request, the resource, or both. To learn which resources support conditions in their IAM policies, see the IAM documentation (https://cloud.google.com/iam/help/conditions/resource-policies).JSON example: { "bindings": [ { "role": "roles/resourcemanager.organizationAdmin", "members": [ "user:mike@example.com", "group:admins@example.com", "domain:google.com", "serviceAccount:my-project-id@appspot.gserviceaccount.com" ] }, { "role": "roles/resourcemanager.organizationViewer", "members": [ "user:eve@example.com" ], "condition": { "title": "expirable access", "description": "Does not grant access after Sep 2020", "expression": "request.time < timestamp('2020-10-01T00:00:00.000Z')", } } ], "etag": "BwWWja0YfJA=", "version": 3 } YAML example: bindings: - members: - user:mike@example.com - group:admins@example.com - domain:google.com - serviceAccount:my-project-id@appspot.gserviceaccount.com role: roles/resourcemanager.organizationAdmin - members: - user:eve@example.com role: roles/resourcemanager.organizationViewer condition: title: expirable access description: Does not grant access after Sep 2020 expression: request.time < timestamp('2020-10-01T00:00:00.000Z') - etag: BwWWja0YfJA= - version: 3 For a description of IAM and its features, see the IAM documentation (https://cloud.google.com/iam/docs/).
type PolicyTypeOutput struct{ *pulumi.OutputState }

func (PolicyTypeOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*PolicyType)(nil)).Elem()
}

func (o PolicyTypeOutput) ToPolicyTypeOutput() PolicyTypeOutput {
	return o
}

func (o PolicyTypeOutput) ToPolicyTypeOutputWithContext(ctx context.Context) PolicyTypeOutput {
	return o
}

func (o PolicyTypeOutput) ToPolicyTypePtrOutput() PolicyTypePtrOutput {
	return o.ToPolicyTypePtrOutputWithContext(context.Background())
}

func (o PolicyTypeOutput) ToPolicyTypePtrOutputWithContext(ctx context.Context) PolicyTypePtrOutput {
	return o.ApplyT(func(v PolicyType) *PolicyType {
		return &v
	}).(PolicyTypePtrOutput)
}

// Associates a list of members to a role. Optionally, may specify a condition that determines how and when the bindings are applied. Each of the bindings must contain at least one member.
func (o PolicyTypeOutput) Bindings() BindingArrayOutput {
	return o.ApplyT(func(v PolicyType) []Binding { return v.Bindings }).(BindingArrayOutput)
}

// etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a policy from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform policy updates in order to avoid race conditions: An etag is returned in the response to getIamPolicy, and systems are expected to put that etag in the request to setIamPolicy to ensure that their change will be applied to the same version of the policy.Important: If you use IAM Conditions, you must include the etag field whenever you call setIamPolicy. If you omit this field, then IAM allows you to overwrite a version 3 policy with a version 1 policy, and all of the conditions in the version 3 policy are lost.
func (o PolicyTypeOutput) Etag() pulumi.StringPtrOutput {
	return o.ApplyT(func(v PolicyType) *string { return v.Etag }).(pulumi.StringPtrOutput)
}

// Specifies the format of the policy.Valid values are 0, 1, and 3. Requests that specify an invalid value are rejected.Any operation that affects conditional role bindings must specify version 3. This requirement applies to the following operations: Getting a policy that includes a conditional role binding Adding a conditional role binding to a policy Changing a conditional role binding in a policy Removing any role binding, with or without a condition, from a policy that includes conditionsImportant: If you use IAM Conditions, you must include the etag field whenever you call setIamPolicy. If you omit this field, then IAM allows you to overwrite a version 3 policy with a version 1 policy, and all of the conditions in the version 3 policy are lost.If a policy does not include any conditions, operations on that policy may specify any valid version or leave the field unset.To learn which resources support conditions in their IAM policies, see the IAM documentation (https://cloud.google.com/iam/help/conditions/resource-policies).
func (o PolicyTypeOutput) Version() pulumi.IntPtrOutput {
	return o.ApplyT(func(v PolicyType) *int { return v.Version }).(pulumi.IntPtrOutput)
}

type PolicyTypePtrOutput struct{ *pulumi.OutputState }

func (PolicyTypePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**PolicyType)(nil)).Elem()
}

func (o PolicyTypePtrOutput) ToPolicyTypePtrOutput() PolicyTypePtrOutput {
	return o
}

func (o PolicyTypePtrOutput) ToPolicyTypePtrOutputWithContext(ctx context.Context) PolicyTypePtrOutput {
	return o
}

func (o PolicyTypePtrOutput) Elem() PolicyTypeOutput {
	return o.ApplyT(func(v *PolicyType) PolicyType { return *v }).(PolicyTypeOutput)
}

// Associates a list of members to a role. Optionally, may specify a condition that determines how and when the bindings are applied. Each of the bindings must contain at least one member.
func (o PolicyTypePtrOutput) Bindings() BindingArrayOutput {
	return o.ApplyT(func(v *PolicyType) []Binding {
		if v == nil {
			return nil
		}
		return v.Bindings
	}).(BindingArrayOutput)
}

// etag is used for optimistic concurrency control as a way to help prevent simultaneous updates of a policy from overwriting each other. It is strongly suggested that systems make use of the etag in the read-modify-write cycle to perform policy updates in order to avoid race conditions: An etag is returned in the response to getIamPolicy, and systems are expected to put that etag in the request to setIamPolicy to ensure that their change will be applied to the same version of the policy.Important: If you use IAM Conditions, you must include the etag field whenever you call setIamPolicy. If you omit this field, then IAM allows you to overwrite a version 3 policy with a version 1 policy, and all of the conditions in the version 3 policy are lost.
func (o PolicyTypePtrOutput) Etag() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *PolicyType) *string {
		if v == nil {
			return nil
		}
		return v.Etag
	}).(pulumi.StringPtrOutput)
}

// Specifies the format of the policy.Valid values are 0, 1, and 3. Requests that specify an invalid value are rejected.Any operation that affects conditional role bindings must specify version 3. This requirement applies to the following operations: Getting a policy that includes a conditional role binding Adding a conditional role binding to a policy Changing a conditional role binding in a policy Removing any role binding, with or without a condition, from a policy that includes conditionsImportant: If you use IAM Conditions, you must include the etag field whenever you call setIamPolicy. If you omit this field, then IAM allows you to overwrite a version 3 policy with a version 1 policy, and all of the conditions in the version 3 policy are lost.If a policy does not include any conditions, operations on that policy may specify any valid version or leave the field unset.To learn which resources support conditions in their IAM policies, see the IAM documentation (https://cloud.google.com/iam/help/conditions/resource-policies).
func (o PolicyTypePtrOutput) Version() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *PolicyType) *int {
		if v == nil {
			return nil
		}
		return v.Version
	}).(pulumi.IntPtrOutput)
}

// A Dataproc job for running Presto (https://prestosql.io/) queries. IMPORTANT: The Dataproc Presto Optional Component (https://cloud.google.com/dataproc/docs/concepts/components/presto) must be enabled when the cluster is created to submit a Presto job to the cluster.
type PrestoJob struct {
	// Optional. Presto client tags to attach to this query
	ClientTags []string `pulumi:"clientTags"`
	// Optional. Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries.
	ContinueOnFailure *bool `pulumi:"continueOnFailure"`
	// Optional. The runtime log config for job execution.
	LoggingConfig *LoggingConfig `pulumi:"loggingConfig"`
	// Optional. The format in which query output will be displayed. See the Presto documentation for supported output formats
	OutputFormat *string `pulumi:"outputFormat"`
	// Optional. A mapping of property names to values. Used to set Presto session properties (https://prestodb.io/docs/current/sql/set-session.html) Equivalent to using the --session flag in the Presto CLI
	Properties map[string]string `pulumi:"properties"`
	// The HCFS URI of the script that contains SQL queries.
	QueryFileUri *string `pulumi:"queryFileUri"`
	// A list of queries.
	QueryList *QueryList `pulumi:"queryList"`
}

// PrestoJobInput is an input type that accepts PrestoJobArgs and PrestoJobOutput values.
// You can construct a concrete instance of `PrestoJobInput` via:
//
//          PrestoJobArgs{...}
type PrestoJobInput interface {
	pulumi.Input

	ToPrestoJobOutput() PrestoJobOutput
	ToPrestoJobOutputWithContext(context.Context) PrestoJobOutput
}

// A Dataproc job for running Presto (https://prestosql.io/) queries. IMPORTANT: The Dataproc Presto Optional Component (https://cloud.google.com/dataproc/docs/concepts/components/presto) must be enabled when the cluster is created to submit a Presto job to the cluster.
type PrestoJobArgs struct {
	// Optional. Presto client tags to attach to this query
	ClientTags pulumi.StringArrayInput `pulumi:"clientTags"`
	// Optional. Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries.
	ContinueOnFailure pulumi.BoolPtrInput `pulumi:"continueOnFailure"`
	// Optional. The runtime log config for job execution.
	LoggingConfig LoggingConfigPtrInput `pulumi:"loggingConfig"`
	// Optional. The format in which query output will be displayed. See the Presto documentation for supported output formats
	OutputFormat pulumi.StringPtrInput `pulumi:"outputFormat"`
	// Optional. A mapping of property names to values. Used to set Presto session properties (https://prestodb.io/docs/current/sql/set-session.html) Equivalent to using the --session flag in the Presto CLI
	Properties pulumi.StringMapInput `pulumi:"properties"`
	// The HCFS URI of the script that contains SQL queries.
	QueryFileUri pulumi.StringPtrInput `pulumi:"queryFileUri"`
	// A list of queries.
	QueryList QueryListPtrInput `pulumi:"queryList"`
}

func (PrestoJobArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*PrestoJob)(nil)).Elem()
}

func (i PrestoJobArgs) ToPrestoJobOutput() PrestoJobOutput {
	return i.ToPrestoJobOutputWithContext(context.Background())
}

func (i PrestoJobArgs) ToPrestoJobOutputWithContext(ctx context.Context) PrestoJobOutput {
	return pulumi.ToOutputWithContext(ctx, i).(PrestoJobOutput)
}

func (i PrestoJobArgs) ToPrestoJobPtrOutput() PrestoJobPtrOutput {
	return i.ToPrestoJobPtrOutputWithContext(context.Background())
}

func (i PrestoJobArgs) ToPrestoJobPtrOutputWithContext(ctx context.Context) PrestoJobPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(PrestoJobOutput).ToPrestoJobPtrOutputWithContext(ctx)
}

// PrestoJobPtrInput is an input type that accepts PrestoJobArgs, PrestoJobPtr and PrestoJobPtrOutput values.
// You can construct a concrete instance of `PrestoJobPtrInput` via:
//
//          PrestoJobArgs{...}
//
//  or:
//
//          nil
type PrestoJobPtrInput interface {
	pulumi.Input

	ToPrestoJobPtrOutput() PrestoJobPtrOutput
	ToPrestoJobPtrOutputWithContext(context.Context) PrestoJobPtrOutput
}

type prestoJobPtrType PrestoJobArgs

func PrestoJobPtr(v *PrestoJobArgs) PrestoJobPtrInput {
	return (*prestoJobPtrType)(v)
}

func (*prestoJobPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**PrestoJob)(nil)).Elem()
}

func (i *prestoJobPtrType) ToPrestoJobPtrOutput() PrestoJobPtrOutput {
	return i.ToPrestoJobPtrOutputWithContext(context.Background())
}

func (i *prestoJobPtrType) ToPrestoJobPtrOutputWithContext(ctx context.Context) PrestoJobPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(PrestoJobPtrOutput)
}

// A Dataproc job for running Presto (https://prestosql.io/) queries. IMPORTANT: The Dataproc Presto Optional Component (https://cloud.google.com/dataproc/docs/concepts/components/presto) must be enabled when the cluster is created to submit a Presto job to the cluster.
type PrestoJobOutput struct{ *pulumi.OutputState }

func (PrestoJobOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*PrestoJob)(nil)).Elem()
}

func (o PrestoJobOutput) ToPrestoJobOutput() PrestoJobOutput {
	return o
}

func (o PrestoJobOutput) ToPrestoJobOutputWithContext(ctx context.Context) PrestoJobOutput {
	return o
}

func (o PrestoJobOutput) ToPrestoJobPtrOutput() PrestoJobPtrOutput {
	return o.ToPrestoJobPtrOutputWithContext(context.Background())
}

func (o PrestoJobOutput) ToPrestoJobPtrOutputWithContext(ctx context.Context) PrestoJobPtrOutput {
	return o.ApplyT(func(v PrestoJob) *PrestoJob {
		return &v
	}).(PrestoJobPtrOutput)
}

// Optional. Presto client tags to attach to this query
func (o PrestoJobOutput) ClientTags() pulumi.StringArrayOutput {
	return o.ApplyT(func(v PrestoJob) []string { return v.ClientTags }).(pulumi.StringArrayOutput)
}

// Optional. Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries.
func (o PrestoJobOutput) ContinueOnFailure() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v PrestoJob) *bool { return v.ContinueOnFailure }).(pulumi.BoolPtrOutput)
}

// Optional. The runtime log config for job execution.
func (o PrestoJobOutput) LoggingConfig() LoggingConfigPtrOutput {
	return o.ApplyT(func(v PrestoJob) *LoggingConfig { return v.LoggingConfig }).(LoggingConfigPtrOutput)
}

// Optional. The format in which query output will be displayed. See the Presto documentation for supported output formats
func (o PrestoJobOutput) OutputFormat() pulumi.StringPtrOutput {
	return o.ApplyT(func(v PrestoJob) *string { return v.OutputFormat }).(pulumi.StringPtrOutput)
}

// Optional. A mapping of property names to values. Used to set Presto session properties (https://prestodb.io/docs/current/sql/set-session.html) Equivalent to using the --session flag in the Presto CLI
func (o PrestoJobOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v PrestoJob) map[string]string { return v.Properties }).(pulumi.StringMapOutput)
}

// The HCFS URI of the script that contains SQL queries.
func (o PrestoJobOutput) QueryFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v PrestoJob) *string { return v.QueryFileUri }).(pulumi.StringPtrOutput)
}

// A list of queries.
func (o PrestoJobOutput) QueryList() QueryListPtrOutput {
	return o.ApplyT(func(v PrestoJob) *QueryList { return v.QueryList }).(QueryListPtrOutput)
}

type PrestoJobPtrOutput struct{ *pulumi.OutputState }

func (PrestoJobPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**PrestoJob)(nil)).Elem()
}

func (o PrestoJobPtrOutput) ToPrestoJobPtrOutput() PrestoJobPtrOutput {
	return o
}

func (o PrestoJobPtrOutput) ToPrestoJobPtrOutputWithContext(ctx context.Context) PrestoJobPtrOutput {
	return o
}

func (o PrestoJobPtrOutput) Elem() PrestoJobOutput {
	return o.ApplyT(func(v *PrestoJob) PrestoJob { return *v }).(PrestoJobOutput)
}

// Optional. Presto client tags to attach to this query
func (o PrestoJobPtrOutput) ClientTags() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *PrestoJob) []string {
		if v == nil {
			return nil
		}
		return v.ClientTags
	}).(pulumi.StringArrayOutput)
}

// Optional. Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries.
func (o PrestoJobPtrOutput) ContinueOnFailure() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *PrestoJob) *bool {
		if v == nil {
			return nil
		}
		return v.ContinueOnFailure
	}).(pulumi.BoolPtrOutput)
}

// Optional. The runtime log config for job execution.
func (o PrestoJobPtrOutput) LoggingConfig() LoggingConfigPtrOutput {
	return o.ApplyT(func(v *PrestoJob) *LoggingConfig {
		if v == nil {
			return nil
		}
		return v.LoggingConfig
	}).(LoggingConfigPtrOutput)
}

// Optional. The format in which query output will be displayed. See the Presto documentation for supported output formats
func (o PrestoJobPtrOutput) OutputFormat() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *PrestoJob) *string {
		if v == nil {
			return nil
		}
		return v.OutputFormat
	}).(pulumi.StringPtrOutput)
}

// Optional. A mapping of property names to values. Used to set Presto session properties (https://prestodb.io/docs/current/sql/set-session.html) Equivalent to using the --session flag in the Presto CLI
func (o PrestoJobPtrOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v *PrestoJob) map[string]string {
		if v == nil {
			return nil
		}
		return v.Properties
	}).(pulumi.StringMapOutput)
}

// The HCFS URI of the script that contains SQL queries.
func (o PrestoJobPtrOutput) QueryFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *PrestoJob) *string {
		if v == nil {
			return nil
		}
		return v.QueryFileUri
	}).(pulumi.StringPtrOutput)
}

// A list of queries.
func (o PrestoJobPtrOutput) QueryList() QueryListPtrOutput {
	return o.ApplyT(func(v *PrestoJob) *QueryList {
		if v == nil {
			return nil
		}
		return v.QueryList
	}).(QueryListPtrOutput)
}

// A Dataproc job for running Apache PySpark (https://spark.apache.org/docs/0.9.0/python-programming-guide.html) applications on YARN.
type PySparkJob struct {
	// Optional. HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
	ArchiveUris []string `pulumi:"archiveUris"`
	// Optional. The arguments to pass to the driver. Do not include arguments, such as --conf, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
	Args []string `pulumi:"args"`
	// Optional. HCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
	FileUris []string `pulumi:"fileUris"`
	// Optional. HCFS URIs of jar files to add to the CLASSPATHs of the Python driver and tasks.
	JarFileUris []string `pulumi:"jarFileUris"`
	// Optional. The runtime log config for job execution.
	LoggingConfig *LoggingConfig `pulumi:"loggingConfig"`
	// Required. The HCFS URI of the main Python file to use as the driver. Must be a .py file.
	MainPythonFileUri *string `pulumi:"mainPythonFileUri"`
	// Optional. A mapping of property names to values, used to configure PySpark. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.
	Properties map[string]string `pulumi:"properties"`
	// Optional. HCFS file URIs of Python files to pass to the PySpark framework. Supported file types: .py, .egg, and .zip.
	PythonFileUris []string `pulumi:"pythonFileUris"`
}

// PySparkJobInput is an input type that accepts PySparkJobArgs and PySparkJobOutput values.
// You can construct a concrete instance of `PySparkJobInput` via:
//
//          PySparkJobArgs{...}
type PySparkJobInput interface {
	pulumi.Input

	ToPySparkJobOutput() PySparkJobOutput
	ToPySparkJobOutputWithContext(context.Context) PySparkJobOutput
}

// A Dataproc job for running Apache PySpark (https://spark.apache.org/docs/0.9.0/python-programming-guide.html) applications on YARN.
type PySparkJobArgs struct {
	// Optional. HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
	ArchiveUris pulumi.StringArrayInput `pulumi:"archiveUris"`
	// Optional. The arguments to pass to the driver. Do not include arguments, such as --conf, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
	Args pulumi.StringArrayInput `pulumi:"args"`
	// Optional. HCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
	FileUris pulumi.StringArrayInput `pulumi:"fileUris"`
	// Optional. HCFS URIs of jar files to add to the CLASSPATHs of the Python driver and tasks.
	JarFileUris pulumi.StringArrayInput `pulumi:"jarFileUris"`
	// Optional. The runtime log config for job execution.
	LoggingConfig LoggingConfigPtrInput `pulumi:"loggingConfig"`
	// Required. The HCFS URI of the main Python file to use as the driver. Must be a .py file.
	MainPythonFileUri pulumi.StringPtrInput `pulumi:"mainPythonFileUri"`
	// Optional. A mapping of property names to values, used to configure PySpark. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.
	Properties pulumi.StringMapInput `pulumi:"properties"`
	// Optional. HCFS file URIs of Python files to pass to the PySpark framework. Supported file types: .py, .egg, and .zip.
	PythonFileUris pulumi.StringArrayInput `pulumi:"pythonFileUris"`
}

func (PySparkJobArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*PySparkJob)(nil)).Elem()
}

func (i PySparkJobArgs) ToPySparkJobOutput() PySparkJobOutput {
	return i.ToPySparkJobOutputWithContext(context.Background())
}

func (i PySparkJobArgs) ToPySparkJobOutputWithContext(ctx context.Context) PySparkJobOutput {
	return pulumi.ToOutputWithContext(ctx, i).(PySparkJobOutput)
}

func (i PySparkJobArgs) ToPySparkJobPtrOutput() PySparkJobPtrOutput {
	return i.ToPySparkJobPtrOutputWithContext(context.Background())
}

func (i PySparkJobArgs) ToPySparkJobPtrOutputWithContext(ctx context.Context) PySparkJobPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(PySparkJobOutput).ToPySparkJobPtrOutputWithContext(ctx)
}

// PySparkJobPtrInput is an input type that accepts PySparkJobArgs, PySparkJobPtr and PySparkJobPtrOutput values.
// You can construct a concrete instance of `PySparkJobPtrInput` via:
//
//          PySparkJobArgs{...}
//
//  or:
//
//          nil
type PySparkJobPtrInput interface {
	pulumi.Input

	ToPySparkJobPtrOutput() PySparkJobPtrOutput
	ToPySparkJobPtrOutputWithContext(context.Context) PySparkJobPtrOutput
}

type pySparkJobPtrType PySparkJobArgs

func PySparkJobPtr(v *PySparkJobArgs) PySparkJobPtrInput {
	return (*pySparkJobPtrType)(v)
}

func (*pySparkJobPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**PySparkJob)(nil)).Elem()
}

func (i *pySparkJobPtrType) ToPySparkJobPtrOutput() PySparkJobPtrOutput {
	return i.ToPySparkJobPtrOutputWithContext(context.Background())
}

func (i *pySparkJobPtrType) ToPySparkJobPtrOutputWithContext(ctx context.Context) PySparkJobPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(PySparkJobPtrOutput)
}

// A Dataproc job for running Apache PySpark (https://spark.apache.org/docs/0.9.0/python-programming-guide.html) applications on YARN.
type PySparkJobOutput struct{ *pulumi.OutputState }

func (PySparkJobOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*PySparkJob)(nil)).Elem()
}

func (o PySparkJobOutput) ToPySparkJobOutput() PySparkJobOutput {
	return o
}

func (o PySparkJobOutput) ToPySparkJobOutputWithContext(ctx context.Context) PySparkJobOutput {
	return o
}

func (o PySparkJobOutput) ToPySparkJobPtrOutput() PySparkJobPtrOutput {
	return o.ToPySparkJobPtrOutputWithContext(context.Background())
}

func (o PySparkJobOutput) ToPySparkJobPtrOutputWithContext(ctx context.Context) PySparkJobPtrOutput {
	return o.ApplyT(func(v PySparkJob) *PySparkJob {
		return &v
	}).(PySparkJobPtrOutput)
}

// Optional. HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
func (o PySparkJobOutput) ArchiveUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v PySparkJob) []string { return v.ArchiveUris }).(pulumi.StringArrayOutput)
}

// Optional. The arguments to pass to the driver. Do not include arguments, such as --conf, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
func (o PySparkJobOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v PySparkJob) []string { return v.Args }).(pulumi.StringArrayOutput)
}

// Optional. HCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
func (o PySparkJobOutput) FileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v PySparkJob) []string { return v.FileUris }).(pulumi.StringArrayOutput)
}

// Optional. HCFS URIs of jar files to add to the CLASSPATHs of the Python driver and tasks.
func (o PySparkJobOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v PySparkJob) []string { return v.JarFileUris }).(pulumi.StringArrayOutput)
}

// Optional. The runtime log config for job execution.
func (o PySparkJobOutput) LoggingConfig() LoggingConfigPtrOutput {
	return o.ApplyT(func(v PySparkJob) *LoggingConfig { return v.LoggingConfig }).(LoggingConfigPtrOutput)
}

// Required. The HCFS URI of the main Python file to use as the driver. Must be a .py file.
func (o PySparkJobOutput) MainPythonFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v PySparkJob) *string { return v.MainPythonFileUri }).(pulumi.StringPtrOutput)
}

// Optional. A mapping of property names to values, used to configure PySpark. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.
func (o PySparkJobOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v PySparkJob) map[string]string { return v.Properties }).(pulumi.StringMapOutput)
}

// Optional. HCFS file URIs of Python files to pass to the PySpark framework. Supported file types: .py, .egg, and .zip.
func (o PySparkJobOutput) PythonFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v PySparkJob) []string { return v.PythonFileUris }).(pulumi.StringArrayOutput)
}

type PySparkJobPtrOutput struct{ *pulumi.OutputState }

func (PySparkJobPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**PySparkJob)(nil)).Elem()
}

func (o PySparkJobPtrOutput) ToPySparkJobPtrOutput() PySparkJobPtrOutput {
	return o
}

func (o PySparkJobPtrOutput) ToPySparkJobPtrOutputWithContext(ctx context.Context) PySparkJobPtrOutput {
	return o
}

func (o PySparkJobPtrOutput) Elem() PySparkJobOutput {
	return o.ApplyT(func(v *PySparkJob) PySparkJob { return *v }).(PySparkJobOutput)
}

// Optional. HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
func (o PySparkJobPtrOutput) ArchiveUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *PySparkJob) []string {
		if v == nil {
			return nil
		}
		return v.ArchiveUris
	}).(pulumi.StringArrayOutput)
}

// Optional. The arguments to pass to the driver. Do not include arguments, such as --conf, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
func (o PySparkJobPtrOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *PySparkJob) []string {
		if v == nil {
			return nil
		}
		return v.Args
	}).(pulumi.StringArrayOutput)
}

// Optional. HCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
func (o PySparkJobPtrOutput) FileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *PySparkJob) []string {
		if v == nil {
			return nil
		}
		return v.FileUris
	}).(pulumi.StringArrayOutput)
}

// Optional. HCFS URIs of jar files to add to the CLASSPATHs of the Python driver and tasks.
func (o PySparkJobPtrOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *PySparkJob) []string {
		if v == nil {
			return nil
		}
		return v.JarFileUris
	}).(pulumi.StringArrayOutput)
}

// Optional. The runtime log config for job execution.
func (o PySparkJobPtrOutput) LoggingConfig() LoggingConfigPtrOutput {
	return o.ApplyT(func(v *PySparkJob) *LoggingConfig {
		if v == nil {
			return nil
		}
		return v.LoggingConfig
	}).(LoggingConfigPtrOutput)
}

// Required. The HCFS URI of the main Python file to use as the driver. Must be a .py file.
func (o PySparkJobPtrOutput) MainPythonFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *PySparkJob) *string {
		if v == nil {
			return nil
		}
		return v.MainPythonFileUri
	}).(pulumi.StringPtrOutput)
}

// Optional. A mapping of property names to values, used to configure PySpark. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.
func (o PySparkJobPtrOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v *PySparkJob) map[string]string {
		if v == nil {
			return nil
		}
		return v.Properties
	}).(pulumi.StringMapOutput)
}

// Optional. HCFS file URIs of Python files to pass to the PySpark framework. Supported file types: .py, .egg, and .zip.
func (o PySparkJobPtrOutput) PythonFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *PySparkJob) []string {
		if v == nil {
			return nil
		}
		return v.PythonFileUris
	}).(pulumi.StringArrayOutput)
}

// A list of queries to run on a cluster.
type QueryList struct {
	// Required. The queries to execute. You do not need to end a query expression with a semicolon. Multiple queries can be specified in one string by separating each with a semicolon. Here is an example of a Dataproc API snippet that uses a QueryList to specify a HiveJob: "hiveJob": { "queryList": { "queries": [ "query1", "query2", "query3;query4", ] } }
	Queries []string `pulumi:"queries"`
}

// QueryListInput is an input type that accepts QueryListArgs and QueryListOutput values.
// You can construct a concrete instance of `QueryListInput` via:
//
//          QueryListArgs{...}
type QueryListInput interface {
	pulumi.Input

	ToQueryListOutput() QueryListOutput
	ToQueryListOutputWithContext(context.Context) QueryListOutput
}

// A list of queries to run on a cluster.
type QueryListArgs struct {
	// Required. The queries to execute. You do not need to end a query expression with a semicolon. Multiple queries can be specified in one string by separating each with a semicolon. Here is an example of a Dataproc API snippet that uses a QueryList to specify a HiveJob: "hiveJob": { "queryList": { "queries": [ "query1", "query2", "query3;query4", ] } }
	Queries pulumi.StringArrayInput `pulumi:"queries"`
}

func (QueryListArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*QueryList)(nil)).Elem()
}

func (i QueryListArgs) ToQueryListOutput() QueryListOutput {
	return i.ToQueryListOutputWithContext(context.Background())
}

func (i QueryListArgs) ToQueryListOutputWithContext(ctx context.Context) QueryListOutput {
	return pulumi.ToOutputWithContext(ctx, i).(QueryListOutput)
}

func (i QueryListArgs) ToQueryListPtrOutput() QueryListPtrOutput {
	return i.ToQueryListPtrOutputWithContext(context.Background())
}

func (i QueryListArgs) ToQueryListPtrOutputWithContext(ctx context.Context) QueryListPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(QueryListOutput).ToQueryListPtrOutputWithContext(ctx)
}

// QueryListPtrInput is an input type that accepts QueryListArgs, QueryListPtr and QueryListPtrOutput values.
// You can construct a concrete instance of `QueryListPtrInput` via:
//
//          QueryListArgs{...}
//
//  or:
//
//          nil
type QueryListPtrInput interface {
	pulumi.Input

	ToQueryListPtrOutput() QueryListPtrOutput
	ToQueryListPtrOutputWithContext(context.Context) QueryListPtrOutput
}

type queryListPtrType QueryListArgs

func QueryListPtr(v *QueryListArgs) QueryListPtrInput {
	return (*queryListPtrType)(v)
}

func (*queryListPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**QueryList)(nil)).Elem()
}

func (i *queryListPtrType) ToQueryListPtrOutput() QueryListPtrOutput {
	return i.ToQueryListPtrOutputWithContext(context.Background())
}

func (i *queryListPtrType) ToQueryListPtrOutputWithContext(ctx context.Context) QueryListPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(QueryListPtrOutput)
}

// A list of queries to run on a cluster.
type QueryListOutput struct{ *pulumi.OutputState }

func (QueryListOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*QueryList)(nil)).Elem()
}

func (o QueryListOutput) ToQueryListOutput() QueryListOutput {
	return o
}

func (o QueryListOutput) ToQueryListOutputWithContext(ctx context.Context) QueryListOutput {
	return o
}

func (o QueryListOutput) ToQueryListPtrOutput() QueryListPtrOutput {
	return o.ToQueryListPtrOutputWithContext(context.Background())
}

func (o QueryListOutput) ToQueryListPtrOutputWithContext(ctx context.Context) QueryListPtrOutput {
	return o.ApplyT(func(v QueryList) *QueryList {
		return &v
	}).(QueryListPtrOutput)
}

// Required. The queries to execute. You do not need to end a query expression with a semicolon. Multiple queries can be specified in one string by separating each with a semicolon. Here is an example of a Dataproc API snippet that uses a QueryList to specify a HiveJob: "hiveJob": { "queryList": { "queries": [ "query1", "query2", "query3;query4", ] } }
func (o QueryListOutput) Queries() pulumi.StringArrayOutput {
	return o.ApplyT(func(v QueryList) []string { return v.Queries }).(pulumi.StringArrayOutput)
}

type QueryListPtrOutput struct{ *pulumi.OutputState }

func (QueryListPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**QueryList)(nil)).Elem()
}

func (o QueryListPtrOutput) ToQueryListPtrOutput() QueryListPtrOutput {
	return o
}

func (o QueryListPtrOutput) ToQueryListPtrOutputWithContext(ctx context.Context) QueryListPtrOutput {
	return o
}

func (o QueryListPtrOutput) Elem() QueryListOutput {
	return o.ApplyT(func(v *QueryList) QueryList { return *v }).(QueryListOutput)
}

// Required. The queries to execute. You do not need to end a query expression with a semicolon. Multiple queries can be specified in one string by separating each with a semicolon. Here is an example of a Dataproc API snippet that uses a QueryList to specify a HiveJob: "hiveJob": { "queryList": { "queries": [ "query1", "query2", "query3;query4", ] } }
func (o QueryListPtrOutput) Queries() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *QueryList) []string {
		if v == nil {
			return nil
		}
		return v.Queries
	}).(pulumi.StringArrayOutput)
}

// Validation based on regular expressions.
type RegexValidation struct {
	// Required. RE2 regular expressions used to validate the parameter's value. The value must match the regex in its entirety (substring matches are not sufficient).
	Regexes []string `pulumi:"regexes"`
}

// RegexValidationInput is an input type that accepts RegexValidationArgs and RegexValidationOutput values.
// You can construct a concrete instance of `RegexValidationInput` via:
//
//          RegexValidationArgs{...}
type RegexValidationInput interface {
	pulumi.Input

	ToRegexValidationOutput() RegexValidationOutput
	ToRegexValidationOutputWithContext(context.Context) RegexValidationOutput
}

// Validation based on regular expressions.
type RegexValidationArgs struct {
	// Required. RE2 regular expressions used to validate the parameter's value. The value must match the regex in its entirety (substring matches are not sufficient).
	Regexes pulumi.StringArrayInput `pulumi:"regexes"`
}

func (RegexValidationArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*RegexValidation)(nil)).Elem()
}

func (i RegexValidationArgs) ToRegexValidationOutput() RegexValidationOutput {
	return i.ToRegexValidationOutputWithContext(context.Background())
}

func (i RegexValidationArgs) ToRegexValidationOutputWithContext(ctx context.Context) RegexValidationOutput {
	return pulumi.ToOutputWithContext(ctx, i).(RegexValidationOutput)
}

func (i RegexValidationArgs) ToRegexValidationPtrOutput() RegexValidationPtrOutput {
	return i.ToRegexValidationPtrOutputWithContext(context.Background())
}

func (i RegexValidationArgs) ToRegexValidationPtrOutputWithContext(ctx context.Context) RegexValidationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(RegexValidationOutput).ToRegexValidationPtrOutputWithContext(ctx)
}

// RegexValidationPtrInput is an input type that accepts RegexValidationArgs, RegexValidationPtr and RegexValidationPtrOutput values.
// You can construct a concrete instance of `RegexValidationPtrInput` via:
//
//          RegexValidationArgs{...}
//
//  or:
//
//          nil
type RegexValidationPtrInput interface {
	pulumi.Input

	ToRegexValidationPtrOutput() RegexValidationPtrOutput
	ToRegexValidationPtrOutputWithContext(context.Context) RegexValidationPtrOutput
}

type regexValidationPtrType RegexValidationArgs

func RegexValidationPtr(v *RegexValidationArgs) RegexValidationPtrInput {
	return (*regexValidationPtrType)(v)
}

func (*regexValidationPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**RegexValidation)(nil)).Elem()
}

func (i *regexValidationPtrType) ToRegexValidationPtrOutput() RegexValidationPtrOutput {
	return i.ToRegexValidationPtrOutputWithContext(context.Background())
}

func (i *regexValidationPtrType) ToRegexValidationPtrOutputWithContext(ctx context.Context) RegexValidationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(RegexValidationPtrOutput)
}

// Validation based on regular expressions.
type RegexValidationOutput struct{ *pulumi.OutputState }

func (RegexValidationOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*RegexValidation)(nil)).Elem()
}

func (o RegexValidationOutput) ToRegexValidationOutput() RegexValidationOutput {
	return o
}

func (o RegexValidationOutput) ToRegexValidationOutputWithContext(ctx context.Context) RegexValidationOutput {
	return o
}

func (o RegexValidationOutput) ToRegexValidationPtrOutput() RegexValidationPtrOutput {
	return o.ToRegexValidationPtrOutputWithContext(context.Background())
}

func (o RegexValidationOutput) ToRegexValidationPtrOutputWithContext(ctx context.Context) RegexValidationPtrOutput {
	return o.ApplyT(func(v RegexValidation) *RegexValidation {
		return &v
	}).(RegexValidationPtrOutput)
}

// Required. RE2 regular expressions used to validate the parameter's value. The value must match the regex in its entirety (substring matches are not sufficient).
func (o RegexValidationOutput) Regexes() pulumi.StringArrayOutput {
	return o.ApplyT(func(v RegexValidation) []string { return v.Regexes }).(pulumi.StringArrayOutput)
}

type RegexValidationPtrOutput struct{ *pulumi.OutputState }

func (RegexValidationPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**RegexValidation)(nil)).Elem()
}

func (o RegexValidationPtrOutput) ToRegexValidationPtrOutput() RegexValidationPtrOutput {
	return o
}

func (o RegexValidationPtrOutput) ToRegexValidationPtrOutputWithContext(ctx context.Context) RegexValidationPtrOutput {
	return o
}

func (o RegexValidationPtrOutput) Elem() RegexValidationOutput {
	return o.ApplyT(func(v *RegexValidation) RegexValidation { return *v }).(RegexValidationOutput)
}

// Required. RE2 regular expressions used to validate the parameter's value. The value must match the regex in its entirety (substring matches are not sufficient).
func (o RegexValidationPtrOutput) Regexes() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *RegexValidation) []string {
		if v == nil {
			return nil
		}
		return v.Regexes
	}).(pulumi.StringArrayOutput)
}

// Reservation Affinity for consuming Zonal reservation.
type ReservationAffinity struct {
	// Optional. Type of reservation to consume
	ConsumeReservationType *string `pulumi:"consumeReservationType"`
	// Optional. Corresponds to the label key of reservation resource.
	Key *string `pulumi:"key"`
	// Optional. Corresponds to the label values of reservation resource.
	Values []string `pulumi:"values"`
}

// ReservationAffinityInput is an input type that accepts ReservationAffinityArgs and ReservationAffinityOutput values.
// You can construct a concrete instance of `ReservationAffinityInput` via:
//
//          ReservationAffinityArgs{...}
type ReservationAffinityInput interface {
	pulumi.Input

	ToReservationAffinityOutput() ReservationAffinityOutput
	ToReservationAffinityOutputWithContext(context.Context) ReservationAffinityOutput
}

// Reservation Affinity for consuming Zonal reservation.
type ReservationAffinityArgs struct {
	// Optional. Type of reservation to consume
	ConsumeReservationType pulumi.StringPtrInput `pulumi:"consumeReservationType"`
	// Optional. Corresponds to the label key of reservation resource.
	Key pulumi.StringPtrInput `pulumi:"key"`
	// Optional. Corresponds to the label values of reservation resource.
	Values pulumi.StringArrayInput `pulumi:"values"`
}

func (ReservationAffinityArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ReservationAffinity)(nil)).Elem()
}

func (i ReservationAffinityArgs) ToReservationAffinityOutput() ReservationAffinityOutput {
	return i.ToReservationAffinityOutputWithContext(context.Background())
}

func (i ReservationAffinityArgs) ToReservationAffinityOutputWithContext(ctx context.Context) ReservationAffinityOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ReservationAffinityOutput)
}

func (i ReservationAffinityArgs) ToReservationAffinityPtrOutput() ReservationAffinityPtrOutput {
	return i.ToReservationAffinityPtrOutputWithContext(context.Background())
}

func (i ReservationAffinityArgs) ToReservationAffinityPtrOutputWithContext(ctx context.Context) ReservationAffinityPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ReservationAffinityOutput).ToReservationAffinityPtrOutputWithContext(ctx)
}

// ReservationAffinityPtrInput is an input type that accepts ReservationAffinityArgs, ReservationAffinityPtr and ReservationAffinityPtrOutput values.
// You can construct a concrete instance of `ReservationAffinityPtrInput` via:
//
//          ReservationAffinityArgs{...}
//
//  or:
//
//          nil
type ReservationAffinityPtrInput interface {
	pulumi.Input

	ToReservationAffinityPtrOutput() ReservationAffinityPtrOutput
	ToReservationAffinityPtrOutputWithContext(context.Context) ReservationAffinityPtrOutput
}

type reservationAffinityPtrType ReservationAffinityArgs

func ReservationAffinityPtr(v *ReservationAffinityArgs) ReservationAffinityPtrInput {
	return (*reservationAffinityPtrType)(v)
}

func (*reservationAffinityPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ReservationAffinity)(nil)).Elem()
}

func (i *reservationAffinityPtrType) ToReservationAffinityPtrOutput() ReservationAffinityPtrOutput {
	return i.ToReservationAffinityPtrOutputWithContext(context.Background())
}

func (i *reservationAffinityPtrType) ToReservationAffinityPtrOutputWithContext(ctx context.Context) ReservationAffinityPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ReservationAffinityPtrOutput)
}

// Reservation Affinity for consuming Zonal reservation.
type ReservationAffinityOutput struct{ *pulumi.OutputState }

func (ReservationAffinityOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ReservationAffinity)(nil)).Elem()
}

func (o ReservationAffinityOutput) ToReservationAffinityOutput() ReservationAffinityOutput {
	return o
}

func (o ReservationAffinityOutput) ToReservationAffinityOutputWithContext(ctx context.Context) ReservationAffinityOutput {
	return o
}

func (o ReservationAffinityOutput) ToReservationAffinityPtrOutput() ReservationAffinityPtrOutput {
	return o.ToReservationAffinityPtrOutputWithContext(context.Background())
}

func (o ReservationAffinityOutput) ToReservationAffinityPtrOutputWithContext(ctx context.Context) ReservationAffinityPtrOutput {
	return o.ApplyT(func(v ReservationAffinity) *ReservationAffinity {
		return &v
	}).(ReservationAffinityPtrOutput)
}

// Optional. Type of reservation to consume
func (o ReservationAffinityOutput) ConsumeReservationType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ReservationAffinity) *string { return v.ConsumeReservationType }).(pulumi.StringPtrOutput)
}

// Optional. Corresponds to the label key of reservation resource.
func (o ReservationAffinityOutput) Key() pulumi.StringPtrOutput {
	return o.ApplyT(func(v ReservationAffinity) *string { return v.Key }).(pulumi.StringPtrOutput)
}

// Optional. Corresponds to the label values of reservation resource.
func (o ReservationAffinityOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v ReservationAffinity) []string { return v.Values }).(pulumi.StringArrayOutput)
}

type ReservationAffinityPtrOutput struct{ *pulumi.OutputState }

func (ReservationAffinityPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ReservationAffinity)(nil)).Elem()
}

func (o ReservationAffinityPtrOutput) ToReservationAffinityPtrOutput() ReservationAffinityPtrOutput {
	return o
}

func (o ReservationAffinityPtrOutput) ToReservationAffinityPtrOutputWithContext(ctx context.Context) ReservationAffinityPtrOutput {
	return o
}

func (o ReservationAffinityPtrOutput) Elem() ReservationAffinityOutput {
	return o.ApplyT(func(v *ReservationAffinity) ReservationAffinity { return *v }).(ReservationAffinityOutput)
}

// Optional. Type of reservation to consume
func (o ReservationAffinityPtrOutput) ConsumeReservationType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ReservationAffinity) *string {
		if v == nil {
			return nil
		}
		return v.ConsumeReservationType
	}).(pulumi.StringPtrOutput)
}

// Optional. Corresponds to the label key of reservation resource.
func (o ReservationAffinityPtrOutput) Key() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *ReservationAffinity) *string {
		if v == nil {
			return nil
		}
		return v.Key
	}).(pulumi.StringPtrOutput)
}

// Optional. Corresponds to the label values of reservation resource.
func (o ReservationAffinityPtrOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *ReservationAffinity) []string {
		if v == nil {
			return nil
		}
		return v.Values
	}).(pulumi.StringArrayOutput)
}

// Security related configuration, including encryption, Kerberos, etc.
type SecurityConfig struct {
	// Optional. Kerberos related configuration.
	KerberosConfig *KerberosConfig `pulumi:"kerberosConfig"`
}

// SecurityConfigInput is an input type that accepts SecurityConfigArgs and SecurityConfigOutput values.
// You can construct a concrete instance of `SecurityConfigInput` via:
//
//          SecurityConfigArgs{...}
type SecurityConfigInput interface {
	pulumi.Input

	ToSecurityConfigOutput() SecurityConfigOutput
	ToSecurityConfigOutputWithContext(context.Context) SecurityConfigOutput
}

// Security related configuration, including encryption, Kerberos, etc.
type SecurityConfigArgs struct {
	// Optional. Kerberos related configuration.
	KerberosConfig KerberosConfigPtrInput `pulumi:"kerberosConfig"`
}

func (SecurityConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*SecurityConfig)(nil)).Elem()
}

func (i SecurityConfigArgs) ToSecurityConfigOutput() SecurityConfigOutput {
	return i.ToSecurityConfigOutputWithContext(context.Background())
}

func (i SecurityConfigArgs) ToSecurityConfigOutputWithContext(ctx context.Context) SecurityConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(SecurityConfigOutput)
}

func (i SecurityConfigArgs) ToSecurityConfigPtrOutput() SecurityConfigPtrOutput {
	return i.ToSecurityConfigPtrOutputWithContext(context.Background())
}

func (i SecurityConfigArgs) ToSecurityConfigPtrOutputWithContext(ctx context.Context) SecurityConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(SecurityConfigOutput).ToSecurityConfigPtrOutputWithContext(ctx)
}

// SecurityConfigPtrInput is an input type that accepts SecurityConfigArgs, SecurityConfigPtr and SecurityConfigPtrOutput values.
// You can construct a concrete instance of `SecurityConfigPtrInput` via:
//
//          SecurityConfigArgs{...}
//
//  or:
//
//          nil
type SecurityConfigPtrInput interface {
	pulumi.Input

	ToSecurityConfigPtrOutput() SecurityConfigPtrOutput
	ToSecurityConfigPtrOutputWithContext(context.Context) SecurityConfigPtrOutput
}

type securityConfigPtrType SecurityConfigArgs

func SecurityConfigPtr(v *SecurityConfigArgs) SecurityConfigPtrInput {
	return (*securityConfigPtrType)(v)
}

func (*securityConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**SecurityConfig)(nil)).Elem()
}

func (i *securityConfigPtrType) ToSecurityConfigPtrOutput() SecurityConfigPtrOutput {
	return i.ToSecurityConfigPtrOutputWithContext(context.Background())
}

func (i *securityConfigPtrType) ToSecurityConfigPtrOutputWithContext(ctx context.Context) SecurityConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(SecurityConfigPtrOutput)
}

// Security related configuration, including encryption, Kerberos, etc.
type SecurityConfigOutput struct{ *pulumi.OutputState }

func (SecurityConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*SecurityConfig)(nil)).Elem()
}

func (o SecurityConfigOutput) ToSecurityConfigOutput() SecurityConfigOutput {
	return o
}

func (o SecurityConfigOutput) ToSecurityConfigOutputWithContext(ctx context.Context) SecurityConfigOutput {
	return o
}

func (o SecurityConfigOutput) ToSecurityConfigPtrOutput() SecurityConfigPtrOutput {
	return o.ToSecurityConfigPtrOutputWithContext(context.Background())
}

func (o SecurityConfigOutput) ToSecurityConfigPtrOutputWithContext(ctx context.Context) SecurityConfigPtrOutput {
	return o.ApplyT(func(v SecurityConfig) *SecurityConfig {
		return &v
	}).(SecurityConfigPtrOutput)
}

// Optional. Kerberos related configuration.
func (o SecurityConfigOutput) KerberosConfig() KerberosConfigPtrOutput {
	return o.ApplyT(func(v SecurityConfig) *KerberosConfig { return v.KerberosConfig }).(KerberosConfigPtrOutput)
}

type SecurityConfigPtrOutput struct{ *pulumi.OutputState }

func (SecurityConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**SecurityConfig)(nil)).Elem()
}

func (o SecurityConfigPtrOutput) ToSecurityConfigPtrOutput() SecurityConfigPtrOutput {
	return o
}

func (o SecurityConfigPtrOutput) ToSecurityConfigPtrOutputWithContext(ctx context.Context) SecurityConfigPtrOutput {
	return o
}

func (o SecurityConfigPtrOutput) Elem() SecurityConfigOutput {
	return o.ApplyT(func(v *SecurityConfig) SecurityConfig { return *v }).(SecurityConfigOutput)
}

// Optional. Kerberos related configuration.
func (o SecurityConfigPtrOutput) KerberosConfig() KerberosConfigPtrOutput {
	return o.ApplyT(func(v *SecurityConfig) *KerberosConfig {
		if v == nil {
			return nil
		}
		return v.KerberosConfig
	}).(KerberosConfigPtrOutput)
}

// Shielded Instance Config for clusters using Compute Engine Shielded VMs (https://cloud.google.com/security/shielded-cloud/shielded-vm).
type ShieldedInstanceConfig struct {
	// Optional. Defines whether instances have integrity monitoring enabled.
	EnableIntegrityMonitoring *bool `pulumi:"enableIntegrityMonitoring"`
	// Optional. Defines whether instances have Secure Boot enabled.
	EnableSecureBoot *bool `pulumi:"enableSecureBoot"`
	// Optional. Defines whether instances have the vTPM enabled.
	EnableVtpm *bool `pulumi:"enableVtpm"`
}

// ShieldedInstanceConfigInput is an input type that accepts ShieldedInstanceConfigArgs and ShieldedInstanceConfigOutput values.
// You can construct a concrete instance of `ShieldedInstanceConfigInput` via:
//
//          ShieldedInstanceConfigArgs{...}
type ShieldedInstanceConfigInput interface {
	pulumi.Input

	ToShieldedInstanceConfigOutput() ShieldedInstanceConfigOutput
	ToShieldedInstanceConfigOutputWithContext(context.Context) ShieldedInstanceConfigOutput
}

// Shielded Instance Config for clusters using Compute Engine Shielded VMs (https://cloud.google.com/security/shielded-cloud/shielded-vm).
type ShieldedInstanceConfigArgs struct {
	// Optional. Defines whether instances have integrity monitoring enabled.
	EnableIntegrityMonitoring pulumi.BoolPtrInput `pulumi:"enableIntegrityMonitoring"`
	// Optional. Defines whether instances have Secure Boot enabled.
	EnableSecureBoot pulumi.BoolPtrInput `pulumi:"enableSecureBoot"`
	// Optional. Defines whether instances have the vTPM enabled.
	EnableVtpm pulumi.BoolPtrInput `pulumi:"enableVtpm"`
}

func (ShieldedInstanceConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ShieldedInstanceConfig)(nil)).Elem()
}

func (i ShieldedInstanceConfigArgs) ToShieldedInstanceConfigOutput() ShieldedInstanceConfigOutput {
	return i.ToShieldedInstanceConfigOutputWithContext(context.Background())
}

func (i ShieldedInstanceConfigArgs) ToShieldedInstanceConfigOutputWithContext(ctx context.Context) ShieldedInstanceConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ShieldedInstanceConfigOutput)
}

func (i ShieldedInstanceConfigArgs) ToShieldedInstanceConfigPtrOutput() ShieldedInstanceConfigPtrOutput {
	return i.ToShieldedInstanceConfigPtrOutputWithContext(context.Background())
}

func (i ShieldedInstanceConfigArgs) ToShieldedInstanceConfigPtrOutputWithContext(ctx context.Context) ShieldedInstanceConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ShieldedInstanceConfigOutput).ToShieldedInstanceConfigPtrOutputWithContext(ctx)
}

// ShieldedInstanceConfigPtrInput is an input type that accepts ShieldedInstanceConfigArgs, ShieldedInstanceConfigPtr and ShieldedInstanceConfigPtrOutput values.
// You can construct a concrete instance of `ShieldedInstanceConfigPtrInput` via:
//
//          ShieldedInstanceConfigArgs{...}
//
//  or:
//
//          nil
type ShieldedInstanceConfigPtrInput interface {
	pulumi.Input

	ToShieldedInstanceConfigPtrOutput() ShieldedInstanceConfigPtrOutput
	ToShieldedInstanceConfigPtrOutputWithContext(context.Context) ShieldedInstanceConfigPtrOutput
}

type shieldedInstanceConfigPtrType ShieldedInstanceConfigArgs

func ShieldedInstanceConfigPtr(v *ShieldedInstanceConfigArgs) ShieldedInstanceConfigPtrInput {
	return (*shieldedInstanceConfigPtrType)(v)
}

func (*shieldedInstanceConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ShieldedInstanceConfig)(nil)).Elem()
}

func (i *shieldedInstanceConfigPtrType) ToShieldedInstanceConfigPtrOutput() ShieldedInstanceConfigPtrOutput {
	return i.ToShieldedInstanceConfigPtrOutputWithContext(context.Background())
}

func (i *shieldedInstanceConfigPtrType) ToShieldedInstanceConfigPtrOutputWithContext(ctx context.Context) ShieldedInstanceConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ShieldedInstanceConfigPtrOutput)
}

// Shielded Instance Config for clusters using Compute Engine Shielded VMs (https://cloud.google.com/security/shielded-cloud/shielded-vm).
type ShieldedInstanceConfigOutput struct{ *pulumi.OutputState }

func (ShieldedInstanceConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ShieldedInstanceConfig)(nil)).Elem()
}

func (o ShieldedInstanceConfigOutput) ToShieldedInstanceConfigOutput() ShieldedInstanceConfigOutput {
	return o
}

func (o ShieldedInstanceConfigOutput) ToShieldedInstanceConfigOutputWithContext(ctx context.Context) ShieldedInstanceConfigOutput {
	return o
}

func (o ShieldedInstanceConfigOutput) ToShieldedInstanceConfigPtrOutput() ShieldedInstanceConfigPtrOutput {
	return o.ToShieldedInstanceConfigPtrOutputWithContext(context.Background())
}

func (o ShieldedInstanceConfigOutput) ToShieldedInstanceConfigPtrOutputWithContext(ctx context.Context) ShieldedInstanceConfigPtrOutput {
	return o.ApplyT(func(v ShieldedInstanceConfig) *ShieldedInstanceConfig {
		return &v
	}).(ShieldedInstanceConfigPtrOutput)
}

// Optional. Defines whether instances have integrity monitoring enabled.
func (o ShieldedInstanceConfigOutput) EnableIntegrityMonitoring() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v ShieldedInstanceConfig) *bool { return v.EnableIntegrityMonitoring }).(pulumi.BoolPtrOutput)
}

// Optional. Defines whether instances have Secure Boot enabled.
func (o ShieldedInstanceConfigOutput) EnableSecureBoot() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v ShieldedInstanceConfig) *bool { return v.EnableSecureBoot }).(pulumi.BoolPtrOutput)
}

// Optional. Defines whether instances have the vTPM enabled.
func (o ShieldedInstanceConfigOutput) EnableVtpm() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v ShieldedInstanceConfig) *bool { return v.EnableVtpm }).(pulumi.BoolPtrOutput)
}

type ShieldedInstanceConfigPtrOutput struct{ *pulumi.OutputState }

func (ShieldedInstanceConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ShieldedInstanceConfig)(nil)).Elem()
}

func (o ShieldedInstanceConfigPtrOutput) ToShieldedInstanceConfigPtrOutput() ShieldedInstanceConfigPtrOutput {
	return o
}

func (o ShieldedInstanceConfigPtrOutput) ToShieldedInstanceConfigPtrOutputWithContext(ctx context.Context) ShieldedInstanceConfigPtrOutput {
	return o
}

func (o ShieldedInstanceConfigPtrOutput) Elem() ShieldedInstanceConfigOutput {
	return o.ApplyT(func(v *ShieldedInstanceConfig) ShieldedInstanceConfig { return *v }).(ShieldedInstanceConfigOutput)
}

// Optional. Defines whether instances have integrity monitoring enabled.
func (o ShieldedInstanceConfigPtrOutput) EnableIntegrityMonitoring() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *ShieldedInstanceConfig) *bool {
		if v == nil {
			return nil
		}
		return v.EnableIntegrityMonitoring
	}).(pulumi.BoolPtrOutput)
}

// Optional. Defines whether instances have Secure Boot enabled.
func (o ShieldedInstanceConfigPtrOutput) EnableSecureBoot() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *ShieldedInstanceConfig) *bool {
		if v == nil {
			return nil
		}
		return v.EnableSecureBoot
	}).(pulumi.BoolPtrOutput)
}

// Optional. Defines whether instances have the vTPM enabled.
func (o ShieldedInstanceConfigPtrOutput) EnableVtpm() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *ShieldedInstanceConfig) *bool {
		if v == nil {
			return nil
		}
		return v.EnableVtpm
	}).(pulumi.BoolPtrOutput)
}

// Specifies the selection and config of software inside the cluster.
type SoftwareConfig struct {
	// Optional. The version of software inside the cluster. It must be one of the supported Dataproc Versions (https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions#supported_dataproc_versions), such as "1.2" (including a subminor version, such as "1.2.29"), or the "preview" version (https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions#other_versions). If unspecified, it defaults to the latest Debian version.
	ImageVersion *string `pulumi:"imageVersion"`
	// The set of optional components to activate on the cluster.
	OptionalComponents []string `pulumi:"optionalComponents"`
	// Optional. The properties to set on daemon config files.Property keys are specified in prefix:property format, for example core:hadoop.tmp.dir. The following are supported prefixes and their mappings: capacity-scheduler: capacity-scheduler.xml core: core-site.xml distcp: distcp-default.xml hdfs: hdfs-site.xml hive: hive-site.xml mapred: mapred-site.xml pig: pig.properties spark: spark-defaults.conf yarn: yarn-site.xmlFor more information, see Cluster properties (https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
	Properties map[string]string `pulumi:"properties"`
}

// SoftwareConfigInput is an input type that accepts SoftwareConfigArgs and SoftwareConfigOutput values.
// You can construct a concrete instance of `SoftwareConfigInput` via:
//
//          SoftwareConfigArgs{...}
type SoftwareConfigInput interface {
	pulumi.Input

	ToSoftwareConfigOutput() SoftwareConfigOutput
	ToSoftwareConfigOutputWithContext(context.Context) SoftwareConfigOutput
}

// Specifies the selection and config of software inside the cluster.
type SoftwareConfigArgs struct {
	// Optional. The version of software inside the cluster. It must be one of the supported Dataproc Versions (https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions#supported_dataproc_versions), such as "1.2" (including a subminor version, such as "1.2.29"), or the "preview" version (https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions#other_versions). If unspecified, it defaults to the latest Debian version.
	ImageVersion pulumi.StringPtrInput `pulumi:"imageVersion"`
	// The set of optional components to activate on the cluster.
	OptionalComponents pulumi.StringArrayInput `pulumi:"optionalComponents"`
	// Optional. The properties to set on daemon config files.Property keys are specified in prefix:property format, for example core:hadoop.tmp.dir. The following are supported prefixes and their mappings: capacity-scheduler: capacity-scheduler.xml core: core-site.xml distcp: distcp-default.xml hdfs: hdfs-site.xml hive: hive-site.xml mapred: mapred-site.xml pig: pig.properties spark: spark-defaults.conf yarn: yarn-site.xmlFor more information, see Cluster properties (https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
	Properties pulumi.StringMapInput `pulumi:"properties"`
}

func (SoftwareConfigArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*SoftwareConfig)(nil)).Elem()
}

func (i SoftwareConfigArgs) ToSoftwareConfigOutput() SoftwareConfigOutput {
	return i.ToSoftwareConfigOutputWithContext(context.Background())
}

func (i SoftwareConfigArgs) ToSoftwareConfigOutputWithContext(ctx context.Context) SoftwareConfigOutput {
	return pulumi.ToOutputWithContext(ctx, i).(SoftwareConfigOutput)
}

func (i SoftwareConfigArgs) ToSoftwareConfigPtrOutput() SoftwareConfigPtrOutput {
	return i.ToSoftwareConfigPtrOutputWithContext(context.Background())
}

func (i SoftwareConfigArgs) ToSoftwareConfigPtrOutputWithContext(ctx context.Context) SoftwareConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(SoftwareConfigOutput).ToSoftwareConfigPtrOutputWithContext(ctx)
}

// SoftwareConfigPtrInput is an input type that accepts SoftwareConfigArgs, SoftwareConfigPtr and SoftwareConfigPtrOutput values.
// You can construct a concrete instance of `SoftwareConfigPtrInput` via:
//
//          SoftwareConfigArgs{...}
//
//  or:
//
//          nil
type SoftwareConfigPtrInput interface {
	pulumi.Input

	ToSoftwareConfigPtrOutput() SoftwareConfigPtrOutput
	ToSoftwareConfigPtrOutputWithContext(context.Context) SoftwareConfigPtrOutput
}

type softwareConfigPtrType SoftwareConfigArgs

func SoftwareConfigPtr(v *SoftwareConfigArgs) SoftwareConfigPtrInput {
	return (*softwareConfigPtrType)(v)
}

func (*softwareConfigPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**SoftwareConfig)(nil)).Elem()
}

func (i *softwareConfigPtrType) ToSoftwareConfigPtrOutput() SoftwareConfigPtrOutput {
	return i.ToSoftwareConfigPtrOutputWithContext(context.Background())
}

func (i *softwareConfigPtrType) ToSoftwareConfigPtrOutputWithContext(ctx context.Context) SoftwareConfigPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(SoftwareConfigPtrOutput)
}

// Specifies the selection and config of software inside the cluster.
type SoftwareConfigOutput struct{ *pulumi.OutputState }

func (SoftwareConfigOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*SoftwareConfig)(nil)).Elem()
}

func (o SoftwareConfigOutput) ToSoftwareConfigOutput() SoftwareConfigOutput {
	return o
}

func (o SoftwareConfigOutput) ToSoftwareConfigOutputWithContext(ctx context.Context) SoftwareConfigOutput {
	return o
}

func (o SoftwareConfigOutput) ToSoftwareConfigPtrOutput() SoftwareConfigPtrOutput {
	return o.ToSoftwareConfigPtrOutputWithContext(context.Background())
}

func (o SoftwareConfigOutput) ToSoftwareConfigPtrOutputWithContext(ctx context.Context) SoftwareConfigPtrOutput {
	return o.ApplyT(func(v SoftwareConfig) *SoftwareConfig {
		return &v
	}).(SoftwareConfigPtrOutput)
}

// Optional. The version of software inside the cluster. It must be one of the supported Dataproc Versions (https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions#supported_dataproc_versions), such as "1.2" (including a subminor version, such as "1.2.29"), or the "preview" version (https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions#other_versions). If unspecified, it defaults to the latest Debian version.
func (o SoftwareConfigOutput) ImageVersion() pulumi.StringPtrOutput {
	return o.ApplyT(func(v SoftwareConfig) *string { return v.ImageVersion }).(pulumi.StringPtrOutput)
}

// The set of optional components to activate on the cluster.
func (o SoftwareConfigOutput) OptionalComponents() pulumi.StringArrayOutput {
	return o.ApplyT(func(v SoftwareConfig) []string { return v.OptionalComponents }).(pulumi.StringArrayOutput)
}

// Optional. The properties to set on daemon config files.Property keys are specified in prefix:property format, for example core:hadoop.tmp.dir. The following are supported prefixes and their mappings: capacity-scheduler: capacity-scheduler.xml core: core-site.xml distcp: distcp-default.xml hdfs: hdfs-site.xml hive: hive-site.xml mapred: mapred-site.xml pig: pig.properties spark: spark-defaults.conf yarn: yarn-site.xmlFor more information, see Cluster properties (https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
func (o SoftwareConfigOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v SoftwareConfig) map[string]string { return v.Properties }).(pulumi.StringMapOutput)
}

type SoftwareConfigPtrOutput struct{ *pulumi.OutputState }

func (SoftwareConfigPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**SoftwareConfig)(nil)).Elem()
}

func (o SoftwareConfigPtrOutput) ToSoftwareConfigPtrOutput() SoftwareConfigPtrOutput {
	return o
}

func (o SoftwareConfigPtrOutput) ToSoftwareConfigPtrOutputWithContext(ctx context.Context) SoftwareConfigPtrOutput {
	return o
}

func (o SoftwareConfigPtrOutput) Elem() SoftwareConfigOutput {
	return o.ApplyT(func(v *SoftwareConfig) SoftwareConfig { return *v }).(SoftwareConfigOutput)
}

// Optional. The version of software inside the cluster. It must be one of the supported Dataproc Versions (https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions#supported_dataproc_versions), such as "1.2" (including a subminor version, such as "1.2.29"), or the "preview" version (https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions#other_versions). If unspecified, it defaults to the latest Debian version.
func (o SoftwareConfigPtrOutput) ImageVersion() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *SoftwareConfig) *string {
		if v == nil {
			return nil
		}
		return v.ImageVersion
	}).(pulumi.StringPtrOutput)
}

// The set of optional components to activate on the cluster.
func (o SoftwareConfigPtrOutput) OptionalComponents() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *SoftwareConfig) []string {
		if v == nil {
			return nil
		}
		return v.OptionalComponents
	}).(pulumi.StringArrayOutput)
}

// Optional. The properties to set on daemon config files.Property keys are specified in prefix:property format, for example core:hadoop.tmp.dir. The following are supported prefixes and their mappings: capacity-scheduler: capacity-scheduler.xml core: core-site.xml distcp: distcp-default.xml hdfs: hdfs-site.xml hive: hive-site.xml mapred: mapred-site.xml pig: pig.properties spark: spark-defaults.conf yarn: yarn-site.xmlFor more information, see Cluster properties (https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
func (o SoftwareConfigPtrOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v *SoftwareConfig) map[string]string {
		if v == nil {
			return nil
		}
		return v.Properties
	}).(pulumi.StringMapOutput)
}

// A Dataproc job for running Apache Spark (http://spark.apache.org/) applications on YARN. The specification of the main method to call to drive the job. Specify either the jar file that contains the main class or the main class name. To pass both a main jar and a main class in that jar, add the jar to CommonJob.jar_file_uris, and then specify the main class name in main_class.
type SparkJob struct {
	// Optional. HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
	ArchiveUris []string `pulumi:"archiveUris"`
	// Optional. The arguments to pass to the driver. Do not include arguments, such as --conf, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
	Args []string `pulumi:"args"`
	// Optional. HCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
	FileUris []string `pulumi:"fileUris"`
	// Optional. HCFS URIs of jar files to add to the CLASSPATHs of the Spark driver and tasks.
	JarFileUris []string `pulumi:"jarFileUris"`
	// Optional. The runtime log config for job execution.
	LoggingConfig *LoggingConfig `pulumi:"loggingConfig"`
	// The name of the driver's main class. The jar file that contains the class must be in the default CLASSPATH or specified in jar_file_uris.
	MainClass *string `pulumi:"mainClass"`
	// The HCFS URI of the jar file that contains the main class.
	MainJarFileUri *string `pulumi:"mainJarFileUri"`
	// Optional. A mapping of property names to values, used to configure Spark. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.
	Properties map[string]string `pulumi:"properties"`
}

// SparkJobInput is an input type that accepts SparkJobArgs and SparkJobOutput values.
// You can construct a concrete instance of `SparkJobInput` via:
//
//          SparkJobArgs{...}
type SparkJobInput interface {
	pulumi.Input

	ToSparkJobOutput() SparkJobOutput
	ToSparkJobOutputWithContext(context.Context) SparkJobOutput
}

// A Dataproc job for running Apache Spark (http://spark.apache.org/) applications on YARN. The specification of the main method to call to drive the job. Specify either the jar file that contains the main class or the main class name. To pass both a main jar and a main class in that jar, add the jar to CommonJob.jar_file_uris, and then specify the main class name in main_class.
type SparkJobArgs struct {
	// Optional. HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
	ArchiveUris pulumi.StringArrayInput `pulumi:"archiveUris"`
	// Optional. The arguments to pass to the driver. Do not include arguments, such as --conf, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
	Args pulumi.StringArrayInput `pulumi:"args"`
	// Optional. HCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
	FileUris pulumi.StringArrayInput `pulumi:"fileUris"`
	// Optional. HCFS URIs of jar files to add to the CLASSPATHs of the Spark driver and tasks.
	JarFileUris pulumi.StringArrayInput `pulumi:"jarFileUris"`
	// Optional. The runtime log config for job execution.
	LoggingConfig LoggingConfigPtrInput `pulumi:"loggingConfig"`
	// The name of the driver's main class. The jar file that contains the class must be in the default CLASSPATH or specified in jar_file_uris.
	MainClass pulumi.StringPtrInput `pulumi:"mainClass"`
	// The HCFS URI of the jar file that contains the main class.
	MainJarFileUri pulumi.StringPtrInput `pulumi:"mainJarFileUri"`
	// Optional. A mapping of property names to values, used to configure Spark. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.
	Properties pulumi.StringMapInput `pulumi:"properties"`
}

func (SparkJobArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*SparkJob)(nil)).Elem()
}

func (i SparkJobArgs) ToSparkJobOutput() SparkJobOutput {
	return i.ToSparkJobOutputWithContext(context.Background())
}

func (i SparkJobArgs) ToSparkJobOutputWithContext(ctx context.Context) SparkJobOutput {
	return pulumi.ToOutputWithContext(ctx, i).(SparkJobOutput)
}

func (i SparkJobArgs) ToSparkJobPtrOutput() SparkJobPtrOutput {
	return i.ToSparkJobPtrOutputWithContext(context.Background())
}

func (i SparkJobArgs) ToSparkJobPtrOutputWithContext(ctx context.Context) SparkJobPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(SparkJobOutput).ToSparkJobPtrOutputWithContext(ctx)
}

// SparkJobPtrInput is an input type that accepts SparkJobArgs, SparkJobPtr and SparkJobPtrOutput values.
// You can construct a concrete instance of `SparkJobPtrInput` via:
//
//          SparkJobArgs{...}
//
//  or:
//
//          nil
type SparkJobPtrInput interface {
	pulumi.Input

	ToSparkJobPtrOutput() SparkJobPtrOutput
	ToSparkJobPtrOutputWithContext(context.Context) SparkJobPtrOutput
}

type sparkJobPtrType SparkJobArgs

func SparkJobPtr(v *SparkJobArgs) SparkJobPtrInput {
	return (*sparkJobPtrType)(v)
}

func (*sparkJobPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**SparkJob)(nil)).Elem()
}

func (i *sparkJobPtrType) ToSparkJobPtrOutput() SparkJobPtrOutput {
	return i.ToSparkJobPtrOutputWithContext(context.Background())
}

func (i *sparkJobPtrType) ToSparkJobPtrOutputWithContext(ctx context.Context) SparkJobPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(SparkJobPtrOutput)
}

// A Dataproc job for running Apache Spark (http://spark.apache.org/) applications on YARN. The specification of the main method to call to drive the job. Specify either the jar file that contains the main class or the main class name. To pass both a main jar and a main class in that jar, add the jar to CommonJob.jar_file_uris, and then specify the main class name in main_class.
type SparkJobOutput struct{ *pulumi.OutputState }

func (SparkJobOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*SparkJob)(nil)).Elem()
}

func (o SparkJobOutput) ToSparkJobOutput() SparkJobOutput {
	return o
}

func (o SparkJobOutput) ToSparkJobOutputWithContext(ctx context.Context) SparkJobOutput {
	return o
}

func (o SparkJobOutput) ToSparkJobPtrOutput() SparkJobPtrOutput {
	return o.ToSparkJobPtrOutputWithContext(context.Background())
}

func (o SparkJobOutput) ToSparkJobPtrOutputWithContext(ctx context.Context) SparkJobPtrOutput {
	return o.ApplyT(func(v SparkJob) *SparkJob {
		return &v
	}).(SparkJobPtrOutput)
}

// Optional. HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
func (o SparkJobOutput) ArchiveUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v SparkJob) []string { return v.ArchiveUris }).(pulumi.StringArrayOutput)
}

// Optional. The arguments to pass to the driver. Do not include arguments, such as --conf, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
func (o SparkJobOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v SparkJob) []string { return v.Args }).(pulumi.StringArrayOutput)
}

// Optional. HCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
func (o SparkJobOutput) FileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v SparkJob) []string { return v.FileUris }).(pulumi.StringArrayOutput)
}

// Optional. HCFS URIs of jar files to add to the CLASSPATHs of the Spark driver and tasks.
func (o SparkJobOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v SparkJob) []string { return v.JarFileUris }).(pulumi.StringArrayOutput)
}

// Optional. The runtime log config for job execution.
func (o SparkJobOutput) LoggingConfig() LoggingConfigPtrOutput {
	return o.ApplyT(func(v SparkJob) *LoggingConfig { return v.LoggingConfig }).(LoggingConfigPtrOutput)
}

// The name of the driver's main class. The jar file that contains the class must be in the default CLASSPATH or specified in jar_file_uris.
func (o SparkJobOutput) MainClass() pulumi.StringPtrOutput {
	return o.ApplyT(func(v SparkJob) *string { return v.MainClass }).(pulumi.StringPtrOutput)
}

// The HCFS URI of the jar file that contains the main class.
func (o SparkJobOutput) MainJarFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v SparkJob) *string { return v.MainJarFileUri }).(pulumi.StringPtrOutput)
}

// Optional. A mapping of property names to values, used to configure Spark. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.
func (o SparkJobOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v SparkJob) map[string]string { return v.Properties }).(pulumi.StringMapOutput)
}

type SparkJobPtrOutput struct{ *pulumi.OutputState }

func (SparkJobPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**SparkJob)(nil)).Elem()
}

func (o SparkJobPtrOutput) ToSparkJobPtrOutput() SparkJobPtrOutput {
	return o
}

func (o SparkJobPtrOutput) ToSparkJobPtrOutputWithContext(ctx context.Context) SparkJobPtrOutput {
	return o
}

func (o SparkJobPtrOutput) Elem() SparkJobOutput {
	return o.ApplyT(func(v *SparkJob) SparkJob { return *v }).(SparkJobOutput)
}

// Optional. HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
func (o SparkJobPtrOutput) ArchiveUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *SparkJob) []string {
		if v == nil {
			return nil
		}
		return v.ArchiveUris
	}).(pulumi.StringArrayOutput)
}

// Optional. The arguments to pass to the driver. Do not include arguments, such as --conf, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
func (o SparkJobPtrOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *SparkJob) []string {
		if v == nil {
			return nil
		}
		return v.Args
	}).(pulumi.StringArrayOutput)
}

// Optional. HCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
func (o SparkJobPtrOutput) FileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *SparkJob) []string {
		if v == nil {
			return nil
		}
		return v.FileUris
	}).(pulumi.StringArrayOutput)
}

// Optional. HCFS URIs of jar files to add to the CLASSPATHs of the Spark driver and tasks.
func (o SparkJobPtrOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *SparkJob) []string {
		if v == nil {
			return nil
		}
		return v.JarFileUris
	}).(pulumi.StringArrayOutput)
}

// Optional. The runtime log config for job execution.
func (o SparkJobPtrOutput) LoggingConfig() LoggingConfigPtrOutput {
	return o.ApplyT(func(v *SparkJob) *LoggingConfig {
		if v == nil {
			return nil
		}
		return v.LoggingConfig
	}).(LoggingConfigPtrOutput)
}

// The name of the driver's main class. The jar file that contains the class must be in the default CLASSPATH or specified in jar_file_uris.
func (o SparkJobPtrOutput) MainClass() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *SparkJob) *string {
		if v == nil {
			return nil
		}
		return v.MainClass
	}).(pulumi.StringPtrOutput)
}

// The HCFS URI of the jar file that contains the main class.
func (o SparkJobPtrOutput) MainJarFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *SparkJob) *string {
		if v == nil {
			return nil
		}
		return v.MainJarFileUri
	}).(pulumi.StringPtrOutput)
}

// Optional. A mapping of property names to values, used to configure Spark. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.
func (o SparkJobPtrOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v *SparkJob) map[string]string {
		if v == nil {
			return nil
		}
		return v.Properties
	}).(pulumi.StringMapOutput)
}

// A Dataproc job for running Apache SparkR (https://spark.apache.org/docs/latest/sparkr.html) applications on YARN.
type SparkRJob struct {
	// Optional. HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
	ArchiveUris []string `pulumi:"archiveUris"`
	// Optional. The arguments to pass to the driver. Do not include arguments, such as --conf, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
	Args []string `pulumi:"args"`
	// Optional. HCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
	FileUris []string `pulumi:"fileUris"`
	// Optional. The runtime log config for job execution.
	LoggingConfig *LoggingConfig `pulumi:"loggingConfig"`
	// Required. The HCFS URI of the main R file to use as the driver. Must be a .R file.
	MainRFileUri *string `pulumi:"mainRFileUri"`
	// Optional. A mapping of property names to values, used to configure SparkR. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.
	Properties map[string]string `pulumi:"properties"`
}

// SparkRJobInput is an input type that accepts SparkRJobArgs and SparkRJobOutput values.
// You can construct a concrete instance of `SparkRJobInput` via:
//
//          SparkRJobArgs{...}
type SparkRJobInput interface {
	pulumi.Input

	ToSparkRJobOutput() SparkRJobOutput
	ToSparkRJobOutputWithContext(context.Context) SparkRJobOutput
}

// A Dataproc job for running Apache SparkR (https://spark.apache.org/docs/latest/sparkr.html) applications on YARN.
type SparkRJobArgs struct {
	// Optional. HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
	ArchiveUris pulumi.StringArrayInput `pulumi:"archiveUris"`
	// Optional. The arguments to pass to the driver. Do not include arguments, such as --conf, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
	Args pulumi.StringArrayInput `pulumi:"args"`
	// Optional. HCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
	FileUris pulumi.StringArrayInput `pulumi:"fileUris"`
	// Optional. The runtime log config for job execution.
	LoggingConfig LoggingConfigPtrInput `pulumi:"loggingConfig"`
	// Required. The HCFS URI of the main R file to use as the driver. Must be a .R file.
	MainRFileUri pulumi.StringPtrInput `pulumi:"mainRFileUri"`
	// Optional. A mapping of property names to values, used to configure SparkR. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.
	Properties pulumi.StringMapInput `pulumi:"properties"`
}

func (SparkRJobArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*SparkRJob)(nil)).Elem()
}

func (i SparkRJobArgs) ToSparkRJobOutput() SparkRJobOutput {
	return i.ToSparkRJobOutputWithContext(context.Background())
}

func (i SparkRJobArgs) ToSparkRJobOutputWithContext(ctx context.Context) SparkRJobOutput {
	return pulumi.ToOutputWithContext(ctx, i).(SparkRJobOutput)
}

func (i SparkRJobArgs) ToSparkRJobPtrOutput() SparkRJobPtrOutput {
	return i.ToSparkRJobPtrOutputWithContext(context.Background())
}

func (i SparkRJobArgs) ToSparkRJobPtrOutputWithContext(ctx context.Context) SparkRJobPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(SparkRJobOutput).ToSparkRJobPtrOutputWithContext(ctx)
}

// SparkRJobPtrInput is an input type that accepts SparkRJobArgs, SparkRJobPtr and SparkRJobPtrOutput values.
// You can construct a concrete instance of `SparkRJobPtrInput` via:
//
//          SparkRJobArgs{...}
//
//  or:
//
//          nil
type SparkRJobPtrInput interface {
	pulumi.Input

	ToSparkRJobPtrOutput() SparkRJobPtrOutput
	ToSparkRJobPtrOutputWithContext(context.Context) SparkRJobPtrOutput
}

type sparkRJobPtrType SparkRJobArgs

func SparkRJobPtr(v *SparkRJobArgs) SparkRJobPtrInput {
	return (*sparkRJobPtrType)(v)
}

func (*sparkRJobPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**SparkRJob)(nil)).Elem()
}

func (i *sparkRJobPtrType) ToSparkRJobPtrOutput() SparkRJobPtrOutput {
	return i.ToSparkRJobPtrOutputWithContext(context.Background())
}

func (i *sparkRJobPtrType) ToSparkRJobPtrOutputWithContext(ctx context.Context) SparkRJobPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(SparkRJobPtrOutput)
}

// A Dataproc job for running Apache SparkR (https://spark.apache.org/docs/latest/sparkr.html) applications on YARN.
type SparkRJobOutput struct{ *pulumi.OutputState }

func (SparkRJobOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*SparkRJob)(nil)).Elem()
}

func (o SparkRJobOutput) ToSparkRJobOutput() SparkRJobOutput {
	return o
}

func (o SparkRJobOutput) ToSparkRJobOutputWithContext(ctx context.Context) SparkRJobOutput {
	return o
}

func (o SparkRJobOutput) ToSparkRJobPtrOutput() SparkRJobPtrOutput {
	return o.ToSparkRJobPtrOutputWithContext(context.Background())
}

func (o SparkRJobOutput) ToSparkRJobPtrOutputWithContext(ctx context.Context) SparkRJobPtrOutput {
	return o.ApplyT(func(v SparkRJob) *SparkRJob {
		return &v
	}).(SparkRJobPtrOutput)
}

// Optional. HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
func (o SparkRJobOutput) ArchiveUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v SparkRJob) []string { return v.ArchiveUris }).(pulumi.StringArrayOutput)
}

// Optional. The arguments to pass to the driver. Do not include arguments, such as --conf, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
func (o SparkRJobOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v SparkRJob) []string { return v.Args }).(pulumi.StringArrayOutput)
}

// Optional. HCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
func (o SparkRJobOutput) FileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v SparkRJob) []string { return v.FileUris }).(pulumi.StringArrayOutput)
}

// Optional. The runtime log config for job execution.
func (o SparkRJobOutput) LoggingConfig() LoggingConfigPtrOutput {
	return o.ApplyT(func(v SparkRJob) *LoggingConfig { return v.LoggingConfig }).(LoggingConfigPtrOutput)
}

// Required. The HCFS URI of the main R file to use as the driver. Must be a .R file.
func (o SparkRJobOutput) MainRFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v SparkRJob) *string { return v.MainRFileUri }).(pulumi.StringPtrOutput)
}

// Optional. A mapping of property names to values, used to configure SparkR. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.
func (o SparkRJobOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v SparkRJob) map[string]string { return v.Properties }).(pulumi.StringMapOutput)
}

type SparkRJobPtrOutput struct{ *pulumi.OutputState }

func (SparkRJobPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**SparkRJob)(nil)).Elem()
}

func (o SparkRJobPtrOutput) ToSparkRJobPtrOutput() SparkRJobPtrOutput {
	return o
}

func (o SparkRJobPtrOutput) ToSparkRJobPtrOutputWithContext(ctx context.Context) SparkRJobPtrOutput {
	return o
}

func (o SparkRJobPtrOutput) Elem() SparkRJobOutput {
	return o.ApplyT(func(v *SparkRJob) SparkRJob { return *v }).(SparkRJobOutput)
}

// Optional. HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
func (o SparkRJobPtrOutput) ArchiveUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *SparkRJob) []string {
		if v == nil {
			return nil
		}
		return v.ArchiveUris
	}).(pulumi.StringArrayOutput)
}

// Optional. The arguments to pass to the driver. Do not include arguments, such as --conf, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
func (o SparkRJobPtrOutput) Args() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *SparkRJob) []string {
		if v == nil {
			return nil
		}
		return v.Args
	}).(pulumi.StringArrayOutput)
}

// Optional. HCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
func (o SparkRJobPtrOutput) FileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *SparkRJob) []string {
		if v == nil {
			return nil
		}
		return v.FileUris
	}).(pulumi.StringArrayOutput)
}

// Optional. The runtime log config for job execution.
func (o SparkRJobPtrOutput) LoggingConfig() LoggingConfigPtrOutput {
	return o.ApplyT(func(v *SparkRJob) *LoggingConfig {
		if v == nil {
			return nil
		}
		return v.LoggingConfig
	}).(LoggingConfigPtrOutput)
}

// Required. The HCFS URI of the main R file to use as the driver. Must be a .R file.
func (o SparkRJobPtrOutput) MainRFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *SparkRJob) *string {
		if v == nil {
			return nil
		}
		return v.MainRFileUri
	}).(pulumi.StringPtrOutput)
}

// Optional. A mapping of property names to values, used to configure SparkR. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.
func (o SparkRJobPtrOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v *SparkRJob) map[string]string {
		if v == nil {
			return nil
		}
		return v.Properties
	}).(pulumi.StringMapOutput)
}

// A Dataproc job for running Apache Spark SQL (http://spark.apache.org/sql/) queries.
type SparkSqlJob struct {
	// Optional. HCFS URIs of jar files to be added to the Spark CLASSPATH.
	JarFileUris []string `pulumi:"jarFileUris"`
	// Optional. The runtime log config for job execution.
	LoggingConfig *LoggingConfig `pulumi:"loggingConfig"`
	// Optional. A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Dataproc API may be overwritten.
	Properties map[string]string `pulumi:"properties"`
	// The HCFS URI of the script that contains SQL queries.
	QueryFileUri *string `pulumi:"queryFileUri"`
	// A list of queries.
	QueryList *QueryList `pulumi:"queryList"`
	// Optional. Mapping of query variable names to values (equivalent to the Spark SQL command: SET name="value";).
	ScriptVariables map[string]string `pulumi:"scriptVariables"`
}

// SparkSqlJobInput is an input type that accepts SparkSqlJobArgs and SparkSqlJobOutput values.
// You can construct a concrete instance of `SparkSqlJobInput` via:
//
//          SparkSqlJobArgs{...}
type SparkSqlJobInput interface {
	pulumi.Input

	ToSparkSqlJobOutput() SparkSqlJobOutput
	ToSparkSqlJobOutputWithContext(context.Context) SparkSqlJobOutput
}

// A Dataproc job for running Apache Spark SQL (http://spark.apache.org/sql/) queries.
type SparkSqlJobArgs struct {
	// Optional. HCFS URIs of jar files to be added to the Spark CLASSPATH.
	JarFileUris pulumi.StringArrayInput `pulumi:"jarFileUris"`
	// Optional. The runtime log config for job execution.
	LoggingConfig LoggingConfigPtrInput `pulumi:"loggingConfig"`
	// Optional. A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Dataproc API may be overwritten.
	Properties pulumi.StringMapInput `pulumi:"properties"`
	// The HCFS URI of the script that contains SQL queries.
	QueryFileUri pulumi.StringPtrInput `pulumi:"queryFileUri"`
	// A list of queries.
	QueryList QueryListPtrInput `pulumi:"queryList"`
	// Optional. Mapping of query variable names to values (equivalent to the Spark SQL command: SET name="value";).
	ScriptVariables pulumi.StringMapInput `pulumi:"scriptVariables"`
}

func (SparkSqlJobArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*SparkSqlJob)(nil)).Elem()
}

func (i SparkSqlJobArgs) ToSparkSqlJobOutput() SparkSqlJobOutput {
	return i.ToSparkSqlJobOutputWithContext(context.Background())
}

func (i SparkSqlJobArgs) ToSparkSqlJobOutputWithContext(ctx context.Context) SparkSqlJobOutput {
	return pulumi.ToOutputWithContext(ctx, i).(SparkSqlJobOutput)
}

func (i SparkSqlJobArgs) ToSparkSqlJobPtrOutput() SparkSqlJobPtrOutput {
	return i.ToSparkSqlJobPtrOutputWithContext(context.Background())
}

func (i SparkSqlJobArgs) ToSparkSqlJobPtrOutputWithContext(ctx context.Context) SparkSqlJobPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(SparkSqlJobOutput).ToSparkSqlJobPtrOutputWithContext(ctx)
}

// SparkSqlJobPtrInput is an input type that accepts SparkSqlJobArgs, SparkSqlJobPtr and SparkSqlJobPtrOutput values.
// You can construct a concrete instance of `SparkSqlJobPtrInput` via:
//
//          SparkSqlJobArgs{...}
//
//  or:
//
//          nil
type SparkSqlJobPtrInput interface {
	pulumi.Input

	ToSparkSqlJobPtrOutput() SparkSqlJobPtrOutput
	ToSparkSqlJobPtrOutputWithContext(context.Context) SparkSqlJobPtrOutput
}

type sparkSqlJobPtrType SparkSqlJobArgs

func SparkSqlJobPtr(v *SparkSqlJobArgs) SparkSqlJobPtrInput {
	return (*sparkSqlJobPtrType)(v)
}

func (*sparkSqlJobPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**SparkSqlJob)(nil)).Elem()
}

func (i *sparkSqlJobPtrType) ToSparkSqlJobPtrOutput() SparkSqlJobPtrOutput {
	return i.ToSparkSqlJobPtrOutputWithContext(context.Background())
}

func (i *sparkSqlJobPtrType) ToSparkSqlJobPtrOutputWithContext(ctx context.Context) SparkSqlJobPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(SparkSqlJobPtrOutput)
}

// A Dataproc job for running Apache Spark SQL (http://spark.apache.org/sql/) queries.
type SparkSqlJobOutput struct{ *pulumi.OutputState }

func (SparkSqlJobOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*SparkSqlJob)(nil)).Elem()
}

func (o SparkSqlJobOutput) ToSparkSqlJobOutput() SparkSqlJobOutput {
	return o
}

func (o SparkSqlJobOutput) ToSparkSqlJobOutputWithContext(ctx context.Context) SparkSqlJobOutput {
	return o
}

func (o SparkSqlJobOutput) ToSparkSqlJobPtrOutput() SparkSqlJobPtrOutput {
	return o.ToSparkSqlJobPtrOutputWithContext(context.Background())
}

func (o SparkSqlJobOutput) ToSparkSqlJobPtrOutputWithContext(ctx context.Context) SparkSqlJobPtrOutput {
	return o.ApplyT(func(v SparkSqlJob) *SparkSqlJob {
		return &v
	}).(SparkSqlJobPtrOutput)
}

// Optional. HCFS URIs of jar files to be added to the Spark CLASSPATH.
func (o SparkSqlJobOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v SparkSqlJob) []string { return v.JarFileUris }).(pulumi.StringArrayOutput)
}

// Optional. The runtime log config for job execution.
func (o SparkSqlJobOutput) LoggingConfig() LoggingConfigPtrOutput {
	return o.ApplyT(func(v SparkSqlJob) *LoggingConfig { return v.LoggingConfig }).(LoggingConfigPtrOutput)
}

// Optional. A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Dataproc API may be overwritten.
func (o SparkSqlJobOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v SparkSqlJob) map[string]string { return v.Properties }).(pulumi.StringMapOutput)
}

// The HCFS URI of the script that contains SQL queries.
func (o SparkSqlJobOutput) QueryFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v SparkSqlJob) *string { return v.QueryFileUri }).(pulumi.StringPtrOutput)
}

// A list of queries.
func (o SparkSqlJobOutput) QueryList() QueryListPtrOutput {
	return o.ApplyT(func(v SparkSqlJob) *QueryList { return v.QueryList }).(QueryListPtrOutput)
}

// Optional. Mapping of query variable names to values (equivalent to the Spark SQL command: SET name="value";).
func (o SparkSqlJobOutput) ScriptVariables() pulumi.StringMapOutput {
	return o.ApplyT(func(v SparkSqlJob) map[string]string { return v.ScriptVariables }).(pulumi.StringMapOutput)
}

type SparkSqlJobPtrOutput struct{ *pulumi.OutputState }

func (SparkSqlJobPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**SparkSqlJob)(nil)).Elem()
}

func (o SparkSqlJobPtrOutput) ToSparkSqlJobPtrOutput() SparkSqlJobPtrOutput {
	return o
}

func (o SparkSqlJobPtrOutput) ToSparkSqlJobPtrOutputWithContext(ctx context.Context) SparkSqlJobPtrOutput {
	return o
}

func (o SparkSqlJobPtrOutput) Elem() SparkSqlJobOutput {
	return o.ApplyT(func(v *SparkSqlJob) SparkSqlJob { return *v }).(SparkSqlJobOutput)
}

// Optional. HCFS URIs of jar files to be added to the Spark CLASSPATH.
func (o SparkSqlJobPtrOutput) JarFileUris() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *SparkSqlJob) []string {
		if v == nil {
			return nil
		}
		return v.JarFileUris
	}).(pulumi.StringArrayOutput)
}

// Optional. The runtime log config for job execution.
func (o SparkSqlJobPtrOutput) LoggingConfig() LoggingConfigPtrOutput {
	return o.ApplyT(func(v *SparkSqlJob) *LoggingConfig {
		if v == nil {
			return nil
		}
		return v.LoggingConfig
	}).(LoggingConfigPtrOutput)
}

// Optional. A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Dataproc API may be overwritten.
func (o SparkSqlJobPtrOutput) Properties() pulumi.StringMapOutput {
	return o.ApplyT(func(v *SparkSqlJob) map[string]string {
		if v == nil {
			return nil
		}
		return v.Properties
	}).(pulumi.StringMapOutput)
}

// The HCFS URI of the script that contains SQL queries.
func (o SparkSqlJobPtrOutput) QueryFileUri() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *SparkSqlJob) *string {
		if v == nil {
			return nil
		}
		return v.QueryFileUri
	}).(pulumi.StringPtrOutput)
}

// A list of queries.
func (o SparkSqlJobPtrOutput) QueryList() QueryListPtrOutput {
	return o.ApplyT(func(v *SparkSqlJob) *QueryList {
		if v == nil {
			return nil
		}
		return v.QueryList
	}).(QueryListPtrOutput)
}

// Optional. Mapping of query variable names to values (equivalent to the Spark SQL command: SET name="value";).
func (o SparkSqlJobPtrOutput) ScriptVariables() pulumi.StringMapOutput {
	return o.ApplyT(func(v *SparkSqlJob) map[string]string {
		if v == nil {
			return nil
		}
		return v.ScriptVariables
	}).(pulumi.StringMapOutput)
}

// A configurable parameter that replaces one or more fields in the template. Parameterizable fields: - Labels - File uris - Job properties - Job arguments - Script variables - Main class (in HadoopJob and SparkJob) - Zone (in ClusterSelector)
type TemplateParameter struct {
	// Optional. Brief description of the parameter. Must not exceed 1024 characters.
	Description *string `pulumi:"description"`
	// Required. Paths to all fields that the parameter replaces. A field is allowed to appear in at most one parameter's list of field paths.A field path is similar in syntax to a google.protobuf.FieldMask. For example, a field path that references the zone field of a workflow template's cluster selector would be specified as placement.clusterSelector.zone.Also, field paths can reference fields using the following syntax: Values in maps can be referenced by key: labels'key' placement.clusterSelector.clusterLabels'key' placement.managedCluster.labels'key' placement.clusterSelector.clusterLabels'key' jobs'step-id'.labels'key' Jobs in the jobs list can be referenced by step-id: jobs'step-id'.hadoopJob.mainJarFileUri jobs'step-id'.hiveJob.queryFileUri jobs'step-id'.pySparkJob.mainPythonFileUri jobs'step-id'.hadoopJob.jarFileUris0 jobs'step-id'.hadoopJob.archiveUris0 jobs'step-id'.hadoopJob.fileUris0 jobs'step-id'.pySparkJob.pythonFileUris0 Items in repeated fields can be referenced by a zero-based index: jobs'step-id'.sparkJob.args0 Other examples: jobs'step-id'.hadoopJob.properties'key' jobs'step-id'.hadoopJob.args0 jobs'step-id'.hiveJob.scriptVariables'key' jobs'step-id'.hadoopJob.mainJarFileUri placement.clusterSelector.zoneIt may not be possible to parameterize maps and repeated fields in their entirety since only individual map values and individual items in repeated fields can be referenced. For example, the following field paths are invalid: placement.clusterSelector.clusterLabels jobs'step-id'.sparkJob.args
	Fields []string `pulumi:"fields"`
	// Required. Parameter name. The parameter name is used as the key, and paired with the parameter value, which are passed to the template when the template is instantiated. The name must contain only capital letters (A-Z), numbers (0-9), and underscores (_), and must not start with a number. The maximum length is 40 characters.
	Name *string `pulumi:"name"`
	// Optional. Validation rules to be applied to this parameter's value.
	Validation *ParameterValidation `pulumi:"validation"`
}

// TemplateParameterInput is an input type that accepts TemplateParameterArgs and TemplateParameterOutput values.
// You can construct a concrete instance of `TemplateParameterInput` via:
//
//          TemplateParameterArgs{...}
type TemplateParameterInput interface {
	pulumi.Input

	ToTemplateParameterOutput() TemplateParameterOutput
	ToTemplateParameterOutputWithContext(context.Context) TemplateParameterOutput
}

// A configurable parameter that replaces one or more fields in the template. Parameterizable fields: - Labels - File uris - Job properties - Job arguments - Script variables - Main class (in HadoopJob and SparkJob) - Zone (in ClusterSelector)
type TemplateParameterArgs struct {
	// Optional. Brief description of the parameter. Must not exceed 1024 characters.
	Description pulumi.StringPtrInput `pulumi:"description"`
	// Required. Paths to all fields that the parameter replaces. A field is allowed to appear in at most one parameter's list of field paths.A field path is similar in syntax to a google.protobuf.FieldMask. For example, a field path that references the zone field of a workflow template's cluster selector would be specified as placement.clusterSelector.zone.Also, field paths can reference fields using the following syntax: Values in maps can be referenced by key: labels'key' placement.clusterSelector.clusterLabels'key' placement.managedCluster.labels'key' placement.clusterSelector.clusterLabels'key' jobs'step-id'.labels'key' Jobs in the jobs list can be referenced by step-id: jobs'step-id'.hadoopJob.mainJarFileUri jobs'step-id'.hiveJob.queryFileUri jobs'step-id'.pySparkJob.mainPythonFileUri jobs'step-id'.hadoopJob.jarFileUris0 jobs'step-id'.hadoopJob.archiveUris0 jobs'step-id'.hadoopJob.fileUris0 jobs'step-id'.pySparkJob.pythonFileUris0 Items in repeated fields can be referenced by a zero-based index: jobs'step-id'.sparkJob.args0 Other examples: jobs'step-id'.hadoopJob.properties'key' jobs'step-id'.hadoopJob.args0 jobs'step-id'.hiveJob.scriptVariables'key' jobs'step-id'.hadoopJob.mainJarFileUri placement.clusterSelector.zoneIt may not be possible to parameterize maps and repeated fields in their entirety since only individual map values and individual items in repeated fields can be referenced. For example, the following field paths are invalid: placement.clusterSelector.clusterLabels jobs'step-id'.sparkJob.args
	Fields pulumi.StringArrayInput `pulumi:"fields"`
	// Required. Parameter name. The parameter name is used as the key, and paired with the parameter value, which are passed to the template when the template is instantiated. The name must contain only capital letters (A-Z), numbers (0-9), and underscores (_), and must not start with a number. The maximum length is 40 characters.
	Name pulumi.StringPtrInput `pulumi:"name"`
	// Optional. Validation rules to be applied to this parameter's value.
	Validation ParameterValidationPtrInput `pulumi:"validation"`
}

func (TemplateParameterArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*TemplateParameter)(nil)).Elem()
}

func (i TemplateParameterArgs) ToTemplateParameterOutput() TemplateParameterOutput {
	return i.ToTemplateParameterOutputWithContext(context.Background())
}

func (i TemplateParameterArgs) ToTemplateParameterOutputWithContext(ctx context.Context) TemplateParameterOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TemplateParameterOutput)
}

// TemplateParameterArrayInput is an input type that accepts TemplateParameterArray and TemplateParameterArrayOutput values.
// You can construct a concrete instance of `TemplateParameterArrayInput` via:
//
//          TemplateParameterArray{ TemplateParameterArgs{...} }
type TemplateParameterArrayInput interface {
	pulumi.Input

	ToTemplateParameterArrayOutput() TemplateParameterArrayOutput
	ToTemplateParameterArrayOutputWithContext(context.Context) TemplateParameterArrayOutput
}

type TemplateParameterArray []TemplateParameterInput

func (TemplateParameterArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]TemplateParameter)(nil)).Elem()
}

func (i TemplateParameterArray) ToTemplateParameterArrayOutput() TemplateParameterArrayOutput {
	return i.ToTemplateParameterArrayOutputWithContext(context.Background())
}

func (i TemplateParameterArray) ToTemplateParameterArrayOutputWithContext(ctx context.Context) TemplateParameterArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(TemplateParameterArrayOutput)
}

// A configurable parameter that replaces one or more fields in the template. Parameterizable fields: - Labels - File uris - Job properties - Job arguments - Script variables - Main class (in HadoopJob and SparkJob) - Zone (in ClusterSelector)
type TemplateParameterOutput struct{ *pulumi.OutputState }

func (TemplateParameterOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*TemplateParameter)(nil)).Elem()
}

func (o TemplateParameterOutput) ToTemplateParameterOutput() TemplateParameterOutput {
	return o
}

func (o TemplateParameterOutput) ToTemplateParameterOutputWithContext(ctx context.Context) TemplateParameterOutput {
	return o
}

// Optional. Brief description of the parameter. Must not exceed 1024 characters.
func (o TemplateParameterOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v TemplateParameter) *string { return v.Description }).(pulumi.StringPtrOutput)
}

// Required. Paths to all fields that the parameter replaces. A field is allowed to appear in at most one parameter's list of field paths.A field path is similar in syntax to a google.protobuf.FieldMask. For example, a field path that references the zone field of a workflow template's cluster selector would be specified as placement.clusterSelector.zone.Also, field paths can reference fields using the following syntax: Values in maps can be referenced by key: labels'key' placement.clusterSelector.clusterLabels'key' placement.managedCluster.labels'key' placement.clusterSelector.clusterLabels'key' jobs'step-id'.labels'key' Jobs in the jobs list can be referenced by step-id: jobs'step-id'.hadoopJob.mainJarFileUri jobs'step-id'.hiveJob.queryFileUri jobs'step-id'.pySparkJob.mainPythonFileUri jobs'step-id'.hadoopJob.jarFileUris0 jobs'step-id'.hadoopJob.archiveUris0 jobs'step-id'.hadoopJob.fileUris0 jobs'step-id'.pySparkJob.pythonFileUris0 Items in repeated fields can be referenced by a zero-based index: jobs'step-id'.sparkJob.args0 Other examples: jobs'step-id'.hadoopJob.properties'key' jobs'step-id'.hadoopJob.args0 jobs'step-id'.hiveJob.scriptVariables'key' jobs'step-id'.hadoopJob.mainJarFileUri placement.clusterSelector.zoneIt may not be possible to parameterize maps and repeated fields in their entirety since only individual map values and individual items in repeated fields can be referenced. For example, the following field paths are invalid: placement.clusterSelector.clusterLabels jobs'step-id'.sparkJob.args
func (o TemplateParameterOutput) Fields() pulumi.StringArrayOutput {
	return o.ApplyT(func(v TemplateParameter) []string { return v.Fields }).(pulumi.StringArrayOutput)
}

// Required. Parameter name. The parameter name is used as the key, and paired with the parameter value, which are passed to the template when the template is instantiated. The name must contain only capital letters (A-Z), numbers (0-9), and underscores (_), and must not start with a number. The maximum length is 40 characters.
func (o TemplateParameterOutput) Name() pulumi.StringPtrOutput {
	return o.ApplyT(func(v TemplateParameter) *string { return v.Name }).(pulumi.StringPtrOutput)
}

// Optional. Validation rules to be applied to this parameter's value.
func (o TemplateParameterOutput) Validation() ParameterValidationPtrOutput {
	return o.ApplyT(func(v TemplateParameter) *ParameterValidation { return v.Validation }).(ParameterValidationPtrOutput)
}

type TemplateParameterArrayOutput struct{ *pulumi.OutputState }

func (TemplateParameterArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]TemplateParameter)(nil)).Elem()
}

func (o TemplateParameterArrayOutput) ToTemplateParameterArrayOutput() TemplateParameterArrayOutput {
	return o
}

func (o TemplateParameterArrayOutput) ToTemplateParameterArrayOutputWithContext(ctx context.Context) TemplateParameterArrayOutput {
	return o
}

func (o TemplateParameterArrayOutput) Index(i pulumi.IntInput) TemplateParameterOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) TemplateParameter {
		return vs[0].([]TemplateParameter)[vs[1].(int)]
	}).(TemplateParameterOutput)
}

// Validation based on a list of allowed values.
type ValueValidation struct {
	// Required. List of allowed values for the parameter.
	Values []string `pulumi:"values"`
}

// ValueValidationInput is an input type that accepts ValueValidationArgs and ValueValidationOutput values.
// You can construct a concrete instance of `ValueValidationInput` via:
//
//          ValueValidationArgs{...}
type ValueValidationInput interface {
	pulumi.Input

	ToValueValidationOutput() ValueValidationOutput
	ToValueValidationOutputWithContext(context.Context) ValueValidationOutput
}

// Validation based on a list of allowed values.
type ValueValidationArgs struct {
	// Required. List of allowed values for the parameter.
	Values pulumi.StringArrayInput `pulumi:"values"`
}

func (ValueValidationArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*ValueValidation)(nil)).Elem()
}

func (i ValueValidationArgs) ToValueValidationOutput() ValueValidationOutput {
	return i.ToValueValidationOutputWithContext(context.Background())
}

func (i ValueValidationArgs) ToValueValidationOutputWithContext(ctx context.Context) ValueValidationOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ValueValidationOutput)
}

func (i ValueValidationArgs) ToValueValidationPtrOutput() ValueValidationPtrOutput {
	return i.ToValueValidationPtrOutputWithContext(context.Background())
}

func (i ValueValidationArgs) ToValueValidationPtrOutputWithContext(ctx context.Context) ValueValidationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ValueValidationOutput).ToValueValidationPtrOutputWithContext(ctx)
}

// ValueValidationPtrInput is an input type that accepts ValueValidationArgs, ValueValidationPtr and ValueValidationPtrOutput values.
// You can construct a concrete instance of `ValueValidationPtrInput` via:
//
//          ValueValidationArgs{...}
//
//  or:
//
//          nil
type ValueValidationPtrInput interface {
	pulumi.Input

	ToValueValidationPtrOutput() ValueValidationPtrOutput
	ToValueValidationPtrOutputWithContext(context.Context) ValueValidationPtrOutput
}

type valueValidationPtrType ValueValidationArgs

func ValueValidationPtr(v *ValueValidationArgs) ValueValidationPtrInput {
	return (*valueValidationPtrType)(v)
}

func (*valueValidationPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**ValueValidation)(nil)).Elem()
}

func (i *valueValidationPtrType) ToValueValidationPtrOutput() ValueValidationPtrOutput {
	return i.ToValueValidationPtrOutputWithContext(context.Background())
}

func (i *valueValidationPtrType) ToValueValidationPtrOutputWithContext(ctx context.Context) ValueValidationPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(ValueValidationPtrOutput)
}

// Validation based on a list of allowed values.
type ValueValidationOutput struct{ *pulumi.OutputState }

func (ValueValidationOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*ValueValidation)(nil)).Elem()
}

func (o ValueValidationOutput) ToValueValidationOutput() ValueValidationOutput {
	return o
}

func (o ValueValidationOutput) ToValueValidationOutputWithContext(ctx context.Context) ValueValidationOutput {
	return o
}

func (o ValueValidationOutput) ToValueValidationPtrOutput() ValueValidationPtrOutput {
	return o.ToValueValidationPtrOutputWithContext(context.Background())
}

func (o ValueValidationOutput) ToValueValidationPtrOutputWithContext(ctx context.Context) ValueValidationPtrOutput {
	return o.ApplyT(func(v ValueValidation) *ValueValidation {
		return &v
	}).(ValueValidationPtrOutput)
}

// Required. List of allowed values for the parameter.
func (o ValueValidationOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v ValueValidation) []string { return v.Values }).(pulumi.StringArrayOutput)
}

type ValueValidationPtrOutput struct{ *pulumi.OutputState }

func (ValueValidationPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**ValueValidation)(nil)).Elem()
}

func (o ValueValidationPtrOutput) ToValueValidationPtrOutput() ValueValidationPtrOutput {
	return o
}

func (o ValueValidationPtrOutput) ToValueValidationPtrOutputWithContext(ctx context.Context) ValueValidationPtrOutput {
	return o
}

func (o ValueValidationPtrOutput) Elem() ValueValidationOutput {
	return o.ApplyT(func(v *ValueValidation) ValueValidation { return *v }).(ValueValidationOutput)
}

// Required. List of allowed values for the parameter.
func (o ValueValidationPtrOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *ValueValidation) []string {
		if v == nil {
			return nil
		}
		return v.Values
	}).(pulumi.StringArrayOutput)
}

// Specifies workflow execution target.Either managed_cluster or cluster_selector is required.
type WorkflowTemplatePlacement struct {
	// Optional. A selector that chooses target cluster for jobs based on metadata.The selector is evaluated at the time each job is submitted.
	ClusterSelector *ClusterSelector `pulumi:"clusterSelector"`
	// Optional. A cluster that is managed by the workflow.
	ManagedCluster *ManagedCluster `pulumi:"managedCluster"`
}

// WorkflowTemplatePlacementInput is an input type that accepts WorkflowTemplatePlacementArgs and WorkflowTemplatePlacementOutput values.
// You can construct a concrete instance of `WorkflowTemplatePlacementInput` via:
//
//          WorkflowTemplatePlacementArgs{...}
type WorkflowTemplatePlacementInput interface {
	pulumi.Input

	ToWorkflowTemplatePlacementOutput() WorkflowTemplatePlacementOutput
	ToWorkflowTemplatePlacementOutputWithContext(context.Context) WorkflowTemplatePlacementOutput
}

// Specifies workflow execution target.Either managed_cluster or cluster_selector is required.
type WorkflowTemplatePlacementArgs struct {
	// Optional. A selector that chooses target cluster for jobs based on metadata.The selector is evaluated at the time each job is submitted.
	ClusterSelector ClusterSelectorPtrInput `pulumi:"clusterSelector"`
	// Optional. A cluster that is managed by the workflow.
	ManagedCluster ManagedClusterPtrInput `pulumi:"managedCluster"`
}

func (WorkflowTemplatePlacementArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkflowTemplatePlacement)(nil)).Elem()
}

func (i WorkflowTemplatePlacementArgs) ToWorkflowTemplatePlacementOutput() WorkflowTemplatePlacementOutput {
	return i.ToWorkflowTemplatePlacementOutputWithContext(context.Background())
}

func (i WorkflowTemplatePlacementArgs) ToWorkflowTemplatePlacementOutputWithContext(ctx context.Context) WorkflowTemplatePlacementOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkflowTemplatePlacementOutput)
}

func (i WorkflowTemplatePlacementArgs) ToWorkflowTemplatePlacementPtrOutput() WorkflowTemplatePlacementPtrOutput {
	return i.ToWorkflowTemplatePlacementPtrOutputWithContext(context.Background())
}

func (i WorkflowTemplatePlacementArgs) ToWorkflowTemplatePlacementPtrOutputWithContext(ctx context.Context) WorkflowTemplatePlacementPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkflowTemplatePlacementOutput).ToWorkflowTemplatePlacementPtrOutputWithContext(ctx)
}

// WorkflowTemplatePlacementPtrInput is an input type that accepts WorkflowTemplatePlacementArgs, WorkflowTemplatePlacementPtr and WorkflowTemplatePlacementPtrOutput values.
// You can construct a concrete instance of `WorkflowTemplatePlacementPtrInput` via:
//
//          WorkflowTemplatePlacementArgs{...}
//
//  or:
//
//          nil
type WorkflowTemplatePlacementPtrInput interface {
	pulumi.Input

	ToWorkflowTemplatePlacementPtrOutput() WorkflowTemplatePlacementPtrOutput
	ToWorkflowTemplatePlacementPtrOutputWithContext(context.Context) WorkflowTemplatePlacementPtrOutput
}

type workflowTemplatePlacementPtrType WorkflowTemplatePlacementArgs

func WorkflowTemplatePlacementPtr(v *WorkflowTemplatePlacementArgs) WorkflowTemplatePlacementPtrInput {
	return (*workflowTemplatePlacementPtrType)(v)
}

func (*workflowTemplatePlacementPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkflowTemplatePlacement)(nil)).Elem()
}

func (i *workflowTemplatePlacementPtrType) ToWorkflowTemplatePlacementPtrOutput() WorkflowTemplatePlacementPtrOutput {
	return i.ToWorkflowTemplatePlacementPtrOutputWithContext(context.Background())
}

func (i *workflowTemplatePlacementPtrType) ToWorkflowTemplatePlacementPtrOutputWithContext(ctx context.Context) WorkflowTemplatePlacementPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkflowTemplatePlacementPtrOutput)
}

// Specifies workflow execution target.Either managed_cluster or cluster_selector is required.
type WorkflowTemplatePlacementOutput struct{ *pulumi.OutputState }

func (WorkflowTemplatePlacementOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkflowTemplatePlacement)(nil)).Elem()
}

func (o WorkflowTemplatePlacementOutput) ToWorkflowTemplatePlacementOutput() WorkflowTemplatePlacementOutput {
	return o
}

func (o WorkflowTemplatePlacementOutput) ToWorkflowTemplatePlacementOutputWithContext(ctx context.Context) WorkflowTemplatePlacementOutput {
	return o
}

func (o WorkflowTemplatePlacementOutput) ToWorkflowTemplatePlacementPtrOutput() WorkflowTemplatePlacementPtrOutput {
	return o.ToWorkflowTemplatePlacementPtrOutputWithContext(context.Background())
}

func (o WorkflowTemplatePlacementOutput) ToWorkflowTemplatePlacementPtrOutputWithContext(ctx context.Context) WorkflowTemplatePlacementPtrOutput {
	return o.ApplyT(func(v WorkflowTemplatePlacement) *WorkflowTemplatePlacement {
		return &v
	}).(WorkflowTemplatePlacementPtrOutput)
}

// Optional. A selector that chooses target cluster for jobs based on metadata.The selector is evaluated at the time each job is submitted.
func (o WorkflowTemplatePlacementOutput) ClusterSelector() ClusterSelectorPtrOutput {
	return o.ApplyT(func(v WorkflowTemplatePlacement) *ClusterSelector { return v.ClusterSelector }).(ClusterSelectorPtrOutput)
}

// Optional. A cluster that is managed by the workflow.
func (o WorkflowTemplatePlacementOutput) ManagedCluster() ManagedClusterPtrOutput {
	return o.ApplyT(func(v WorkflowTemplatePlacement) *ManagedCluster { return v.ManagedCluster }).(ManagedClusterPtrOutput)
}

type WorkflowTemplatePlacementPtrOutput struct{ *pulumi.OutputState }

func (WorkflowTemplatePlacementPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkflowTemplatePlacement)(nil)).Elem()
}

func (o WorkflowTemplatePlacementPtrOutput) ToWorkflowTemplatePlacementPtrOutput() WorkflowTemplatePlacementPtrOutput {
	return o
}

func (o WorkflowTemplatePlacementPtrOutput) ToWorkflowTemplatePlacementPtrOutputWithContext(ctx context.Context) WorkflowTemplatePlacementPtrOutput {
	return o
}

func (o WorkflowTemplatePlacementPtrOutput) Elem() WorkflowTemplatePlacementOutput {
	return o.ApplyT(func(v *WorkflowTemplatePlacement) WorkflowTemplatePlacement { return *v }).(WorkflowTemplatePlacementOutput)
}

// Optional. A selector that chooses target cluster for jobs based on metadata.The selector is evaluated at the time each job is submitted.
func (o WorkflowTemplatePlacementPtrOutput) ClusterSelector() ClusterSelectorPtrOutput {
	return o.ApplyT(func(v *WorkflowTemplatePlacement) *ClusterSelector {
		if v == nil {
			return nil
		}
		return v.ClusterSelector
	}).(ClusterSelectorPtrOutput)
}

// Optional. A cluster that is managed by the workflow.
func (o WorkflowTemplatePlacementPtrOutput) ManagedCluster() ManagedClusterPtrOutput {
	return o.ApplyT(func(v *WorkflowTemplatePlacement) *ManagedCluster {
		if v == nil {
			return nil
		}
		return v.ManagedCluster
	}).(ManagedClusterPtrOutput)
}

func init() {
	pulumi.RegisterOutputType(AcceleratorConfigOutput{})
	pulumi.RegisterOutputType(AcceleratorConfigArrayOutput{})
	pulumi.RegisterOutputType(AutoscalingConfigOutput{})
	pulumi.RegisterOutputType(AutoscalingConfigPtrOutput{})
	pulumi.RegisterOutputType(BasicAutoscalingAlgorithmOutput{})
	pulumi.RegisterOutputType(BasicAutoscalingAlgorithmPtrOutput{})
	pulumi.RegisterOutputType(BasicYarnAutoscalingConfigOutput{})
	pulumi.RegisterOutputType(BasicYarnAutoscalingConfigPtrOutput{})
	pulumi.RegisterOutputType(BindingOutput{})
	pulumi.RegisterOutputType(BindingArrayOutput{})
	pulumi.RegisterOutputType(ClusterConfigOutput{})
	pulumi.RegisterOutputType(ClusterConfigPtrOutput{})
	pulumi.RegisterOutputType(ClusterMetricsOutput{})
	pulumi.RegisterOutputType(ClusterMetricsPtrOutput{})
	pulumi.RegisterOutputType(ClusterSelectorOutput{})
	pulumi.RegisterOutputType(ClusterSelectorPtrOutput{})
	pulumi.RegisterOutputType(ClusterStatusOutput{})
	pulumi.RegisterOutputType(ClusterStatusPtrOutput{})
	pulumi.RegisterOutputType(ClusterStatusArrayOutput{})
	pulumi.RegisterOutputType(DiskConfigOutput{})
	pulumi.RegisterOutputType(DiskConfigPtrOutput{})
	pulumi.RegisterOutputType(EncryptionConfigOutput{})
	pulumi.RegisterOutputType(EncryptionConfigPtrOutput{})
	pulumi.RegisterOutputType(EndpointConfigOutput{})
	pulumi.RegisterOutputType(EndpointConfigPtrOutput{})
	pulumi.RegisterOutputType(ExprOutput{})
	pulumi.RegisterOutputType(ExprPtrOutput{})
	pulumi.RegisterOutputType(GceClusterConfigOutput{})
	pulumi.RegisterOutputType(GceClusterConfigPtrOutput{})
	pulumi.RegisterOutputType(GkeClusterConfigOutput{})
	pulumi.RegisterOutputType(GkeClusterConfigPtrOutput{})
	pulumi.RegisterOutputType(HadoopJobOutput{})
	pulumi.RegisterOutputType(HadoopJobPtrOutput{})
	pulumi.RegisterOutputType(HiveJobOutput{})
	pulumi.RegisterOutputType(HiveJobPtrOutput{})
	pulumi.RegisterOutputType(InstanceGroupAutoscalingPolicyConfigOutput{})
	pulumi.RegisterOutputType(InstanceGroupAutoscalingPolicyConfigPtrOutput{})
	pulumi.RegisterOutputType(InstanceGroupConfigOutput{})
	pulumi.RegisterOutputType(InstanceGroupConfigPtrOutput{})
	pulumi.RegisterOutputType(InstanceReferenceOutput{})
	pulumi.RegisterOutputType(InstanceReferenceArrayOutput{})
	pulumi.RegisterOutputType(JobSchedulingOutput{})
	pulumi.RegisterOutputType(JobSchedulingPtrOutput{})
	pulumi.RegisterOutputType(KerberosConfigOutput{})
	pulumi.RegisterOutputType(KerberosConfigPtrOutput{})
	pulumi.RegisterOutputType(LifecycleConfigOutput{})
	pulumi.RegisterOutputType(LifecycleConfigPtrOutput{})
	pulumi.RegisterOutputType(LoggingConfigOutput{})
	pulumi.RegisterOutputType(LoggingConfigPtrOutput{})
	pulumi.RegisterOutputType(ManagedClusterOutput{})
	pulumi.RegisterOutputType(ManagedClusterPtrOutput{})
	pulumi.RegisterOutputType(ManagedGroupConfigOutput{})
	pulumi.RegisterOutputType(ManagedGroupConfigPtrOutput{})
	pulumi.RegisterOutputType(MetastoreConfigOutput{})
	pulumi.RegisterOutputType(MetastoreConfigPtrOutput{})
	pulumi.RegisterOutputType(NamespacedGkeDeploymentTargetOutput{})
	pulumi.RegisterOutputType(NamespacedGkeDeploymentTargetPtrOutput{})
	pulumi.RegisterOutputType(NodeGroupAffinityOutput{})
	pulumi.RegisterOutputType(NodeGroupAffinityPtrOutput{})
	pulumi.RegisterOutputType(NodeInitializationActionOutput{})
	pulumi.RegisterOutputType(NodeInitializationActionArrayOutput{})
	pulumi.RegisterOutputType(OrderedJobOutput{})
	pulumi.RegisterOutputType(OrderedJobArrayOutput{})
	pulumi.RegisterOutputType(ParameterValidationOutput{})
	pulumi.RegisterOutputType(ParameterValidationPtrOutput{})
	pulumi.RegisterOutputType(PigJobOutput{})
	pulumi.RegisterOutputType(PigJobPtrOutput{})
	pulumi.RegisterOutputType(PolicyTypeOutput{})
	pulumi.RegisterOutputType(PolicyTypePtrOutput{})
	pulumi.RegisterOutputType(PrestoJobOutput{})
	pulumi.RegisterOutputType(PrestoJobPtrOutput{})
	pulumi.RegisterOutputType(PySparkJobOutput{})
	pulumi.RegisterOutputType(PySparkJobPtrOutput{})
	pulumi.RegisterOutputType(QueryListOutput{})
	pulumi.RegisterOutputType(QueryListPtrOutput{})
	pulumi.RegisterOutputType(RegexValidationOutput{})
	pulumi.RegisterOutputType(RegexValidationPtrOutput{})
	pulumi.RegisterOutputType(ReservationAffinityOutput{})
	pulumi.RegisterOutputType(ReservationAffinityPtrOutput{})
	pulumi.RegisterOutputType(SecurityConfigOutput{})
	pulumi.RegisterOutputType(SecurityConfigPtrOutput{})
	pulumi.RegisterOutputType(ShieldedInstanceConfigOutput{})
	pulumi.RegisterOutputType(ShieldedInstanceConfigPtrOutput{})
	pulumi.RegisterOutputType(SoftwareConfigOutput{})
	pulumi.RegisterOutputType(SoftwareConfigPtrOutput{})
	pulumi.RegisterOutputType(SparkJobOutput{})
	pulumi.RegisterOutputType(SparkJobPtrOutput{})
	pulumi.RegisterOutputType(SparkRJobOutput{})
	pulumi.RegisterOutputType(SparkRJobPtrOutput{})
	pulumi.RegisterOutputType(SparkSqlJobOutput{})
	pulumi.RegisterOutputType(SparkSqlJobPtrOutput{})
	pulumi.RegisterOutputType(TemplateParameterOutput{})
	pulumi.RegisterOutputType(TemplateParameterArrayOutput{})
	pulumi.RegisterOutputType(ValueValidationOutput{})
	pulumi.RegisterOutputType(ValueValidationPtrOutput{})
	pulumi.RegisterOutputType(WorkflowTemplatePlacementOutput{})
	pulumi.RegisterOutputType(WorkflowTemplatePlacementPtrOutput{})
}
