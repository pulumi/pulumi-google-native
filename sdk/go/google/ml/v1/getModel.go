// *** WARNING: this file was generated by the Pulumi SDK Generator. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package v1

import (
	"context"
	"reflect"

	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

// Gets information about a model, including its name, the description (if set), and the default version (if at least one version of the model has been deployed).
func LookupModel(ctx *pulumi.Context, args *LookupModelArgs, opts ...pulumi.InvokeOption) (*LookupModelResult, error) {
	var rv LookupModelResult
	err := ctx.Invoke("google-native:ml/v1:getModel", args, &rv, opts...)
	if err != nil {
		return nil, err
	}
	return &rv, nil
}

type LookupModelArgs struct {
	ModelId string  `pulumi:"modelId"`
	Project *string `pulumi:"project"`
}

type LookupModelResult struct {
	// The default version of the model. This version will be used to handle prediction requests that do not specify a version. You can change the default version by calling projects.models.versions.setDefault.
	DefaultVersion GoogleCloudMlV1__VersionResponse `pulumi:"defaultVersion"`
	// Optional. The description specified for the model when it was created.
	Description string `pulumi:"description"`
	// `etag` is used for optimistic concurrency control as a way to help prevent simultaneous updates of a model from overwriting each other. It is strongly suggested that systems make use of the `etag` in the read-modify-write cycle to perform model updates in order to avoid race conditions: An `etag` is returned in the response to `GetModel`, and systems are expected to put that etag in the request to `UpdateModel` to ensure that their change will be applied to the model as intended.
	Etag string `pulumi:"etag"`
	// Optional. One or more labels that you can add, to organize your models. Each label is a key-value pair, where both the key and the value are arbitrary strings that you supply. For more information, see the documentation on using labels.
	Labels map[string]string `pulumi:"labels"`
	// The name specified for the model when it was created. The model name must be unique within the project it is created in.
	Name string `pulumi:"name"`
	// Optional. If true, online prediction nodes send `stderr` and `stdout` streams to Cloud Logging. These can be more verbose than the standard access logs (see `onlinePredictionLogging`) and can incur higher cost. However, they are helpful for debugging. Note that [logs may incur a cost](/stackdriver/pricing), especially if your project receives prediction requests at a high QPS. Estimate your costs before enabling this option. Default is false.
	OnlinePredictionConsoleLogging bool `pulumi:"onlinePredictionConsoleLogging"`
	// Optional. If true, online prediction access logs are sent to Cloud Logging. These logs are like standard server access logs, containing information like timestamp and latency for each request. Note that [logs may incur a cost](/stackdriver/pricing), especially if your project receives prediction requests at a high queries per second rate (QPS). Estimate your costs before enabling this option. Default is false.
	OnlinePredictionLogging bool `pulumi:"onlinePredictionLogging"`
	// Optional. The list of regions where the model is going to be deployed. Only one region per model is supported. Defaults to 'us-central1' if nothing is set. See the available regions for AI Platform services. Note: * No matter where a model is deployed, it can always be accessed by users from anywhere, both for online and batch prediction. * The region for a batch prediction job is set by the region field when submitting the batch prediction job and does not take its value from this field.
	Regions []string `pulumi:"regions"`
}

func LookupModelOutput(ctx *pulumi.Context, args LookupModelOutputArgs, opts ...pulumi.InvokeOption) LookupModelResultOutput {
	return pulumi.ToOutputWithContext(context.Background(), args).
		ApplyT(func(v interface{}) (LookupModelResult, error) {
			args := v.(LookupModelArgs)
			r, err := LookupModel(ctx, &args, opts...)
			var s LookupModelResult
			if r != nil {
				s = *r
			}
			return s, err
		}).(LookupModelResultOutput)
}

type LookupModelOutputArgs struct {
	ModelId pulumi.StringInput    `pulumi:"modelId"`
	Project pulumi.StringPtrInput `pulumi:"project"`
}

func (LookupModelOutputArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*LookupModelArgs)(nil)).Elem()
}

type LookupModelResultOutput struct{ *pulumi.OutputState }

func (LookupModelResultOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*LookupModelResult)(nil)).Elem()
}

func (o LookupModelResultOutput) ToLookupModelResultOutput() LookupModelResultOutput {
	return o
}

func (o LookupModelResultOutput) ToLookupModelResultOutputWithContext(ctx context.Context) LookupModelResultOutput {
	return o
}

// The default version of the model. This version will be used to handle prediction requests that do not specify a version. You can change the default version by calling projects.models.versions.setDefault.
func (o LookupModelResultOutput) DefaultVersion() GoogleCloudMlV1__VersionResponseOutput {
	return o.ApplyT(func(v LookupModelResult) GoogleCloudMlV1__VersionResponse { return v.DefaultVersion }).(GoogleCloudMlV1__VersionResponseOutput)
}

// Optional. The description specified for the model when it was created.
func (o LookupModelResultOutput) Description() pulumi.StringOutput {
	return o.ApplyT(func(v LookupModelResult) string { return v.Description }).(pulumi.StringOutput)
}

// `etag` is used for optimistic concurrency control as a way to help prevent simultaneous updates of a model from overwriting each other. It is strongly suggested that systems make use of the `etag` in the read-modify-write cycle to perform model updates in order to avoid race conditions: An `etag` is returned in the response to `GetModel`, and systems are expected to put that etag in the request to `UpdateModel` to ensure that their change will be applied to the model as intended.
func (o LookupModelResultOutput) Etag() pulumi.StringOutput {
	return o.ApplyT(func(v LookupModelResult) string { return v.Etag }).(pulumi.StringOutput)
}

// Optional. One or more labels that you can add, to organize your models. Each label is a key-value pair, where both the key and the value are arbitrary strings that you supply. For more information, see the documentation on using labels.
func (o LookupModelResultOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v LookupModelResult) map[string]string { return v.Labels }).(pulumi.StringMapOutput)
}

// The name specified for the model when it was created. The model name must be unique within the project it is created in.
func (o LookupModelResultOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v LookupModelResult) string { return v.Name }).(pulumi.StringOutput)
}

// Optional. If true, online prediction nodes send `stderr` and `stdout` streams to Cloud Logging. These can be more verbose than the standard access logs (see `onlinePredictionLogging`) and can incur higher cost. However, they are helpful for debugging. Note that [logs may incur a cost](/stackdriver/pricing), especially if your project receives prediction requests at a high QPS. Estimate your costs before enabling this option. Default is false.
func (o LookupModelResultOutput) OnlinePredictionConsoleLogging() pulumi.BoolOutput {
	return o.ApplyT(func(v LookupModelResult) bool { return v.OnlinePredictionConsoleLogging }).(pulumi.BoolOutput)
}

// Optional. If true, online prediction access logs are sent to Cloud Logging. These logs are like standard server access logs, containing information like timestamp and latency for each request. Note that [logs may incur a cost](/stackdriver/pricing), especially if your project receives prediction requests at a high queries per second rate (QPS). Estimate your costs before enabling this option. Default is false.
func (o LookupModelResultOutput) OnlinePredictionLogging() pulumi.BoolOutput {
	return o.ApplyT(func(v LookupModelResult) bool { return v.OnlinePredictionLogging }).(pulumi.BoolOutput)
}

// Optional. The list of regions where the model is going to be deployed. Only one region per model is supported. Defaults to 'us-central1' if nothing is set. See the available regions for AI Platform services. Note: * No matter where a model is deployed, it can always be accessed by users from anywhere, both for online and batch prediction. * The region for a batch prediction job is set by the region field when submitting the batch prediction job and does not take its value from this field.
func (o LookupModelResultOutput) Regions() pulumi.StringArrayOutput {
	return o.ApplyT(func(v LookupModelResult) []string { return v.Regions }).(pulumi.StringArrayOutput)
}

func init() {
	pulumi.RegisterOutputType(LookupModelResultOutput{})
}
