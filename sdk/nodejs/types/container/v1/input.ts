// *** WARNING: this file was generated by the Pulumi SDK Generator. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "../../../types/input";
import * as outputs from "../../../types/output";
import * as enums from "../../../types/enums";
import * as utilities from "../../../utilities";

/**
 * AcceleratorConfig represents a Hardware Accelerator request.
 */
export interface AcceleratorConfigArgs {
    /**
     * The number of the accelerator cards exposed to an instance.
     */
    acceleratorCount?: pulumi.Input<string>;
    /**
     * The accelerator type resource name. List of supported accelerators [here](https://cloud.google.com/compute/docs/gpus)
     */
    acceleratorType?: pulumi.Input<string>;
    /**
     * Size of partitions to create on the GPU. Valid values are described in the NVIDIA [mig user guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning).
     */
    gpuPartitionSize?: pulumi.Input<string>;
    /**
     * The configuration for GPU sharing options.
     */
    gpuSharingConfig?: pulumi.Input<inputs.container.v1.GPUSharingConfigArgs>;
}

/**
 * Configuration for the addons that can be automatically spun up in the cluster, enabling additional functionality.
 */
export interface AddonsConfigArgs {
    /**
     * Configuration for the Cloud Run addon, which allows the user to use a managed Knative service.
     */
    cloudRunConfig?: pulumi.Input<inputs.container.v1.CloudRunConfigArgs>;
    /**
     * Configuration for the ConfigConnector add-on, a Kubernetes extension to manage hosted GCP services through the Kubernetes API
     */
    configConnectorConfig?: pulumi.Input<inputs.container.v1.ConfigConnectorConfigArgs>;
    /**
     * Configuration for NodeLocalDNS, a dns cache running on cluster nodes
     */
    dnsCacheConfig?: pulumi.Input<inputs.container.v1.DnsCacheConfigArgs>;
    /**
     * Configuration for the Compute Engine Persistent Disk CSI driver.
     */
    gcePersistentDiskCsiDriverConfig?: pulumi.Input<inputs.container.v1.GcePersistentDiskCsiDriverConfigArgs>;
    /**
     * Configuration for the GCP Filestore CSI driver.
     */
    gcpFilestoreCsiDriverConfig?: pulumi.Input<inputs.container.v1.GcpFilestoreCsiDriverConfigArgs>;
    /**
     * Configuration for the Backup for GKE agent addon.
     */
    gkeBackupAgentConfig?: pulumi.Input<inputs.container.v1.GkeBackupAgentConfigArgs>;
    /**
     * Configuration for the horizontal pod autoscaling feature, which increases or decreases the number of replica pods a replication controller has based on the resource usage of the existing pods.
     */
    horizontalPodAutoscaling?: pulumi.Input<inputs.container.v1.HorizontalPodAutoscalingArgs>;
    /**
     * Configuration for the HTTP (L7) load balancing controller addon, which makes it easy to set up HTTP load balancers for services in a cluster.
     */
    httpLoadBalancing?: pulumi.Input<inputs.container.v1.HttpLoadBalancingArgs>;
    /**
     * Configuration for the Kubernetes Dashboard. This addon is deprecated, and will be disabled in 1.15. It is recommended to use the Cloud Console to manage and monitor your Kubernetes clusters, workloads and applications. For more information, see: https://cloud.google.com/kubernetes-engine/docs/concepts/dashboards
     */
    kubernetesDashboard?: pulumi.Input<inputs.container.v1.KubernetesDashboardArgs>;
    /**
     * Configuration for NetworkPolicy. This only tracks whether the addon is enabled or not on the Master, it does not track whether network policy is enabled for the nodes.
     */
    networkPolicyConfig?: pulumi.Input<inputs.container.v1.NetworkPolicyConfigArgs>;
}

/**
 * Specifies options for controlling advanced machine features.
 */
export interface AdvancedMachineFeaturesArgs {
    /**
     * The number of threads per physical core. To disable simultaneous multithreading (SMT) set this to 1. If unset, the maximum number of threads supported per core by the underlying processor is assumed.
     */
    threadsPerCore?: pulumi.Input<string>;
}

/**
 * Configuration for returning group information from authenticators.
 */
export interface AuthenticatorGroupsConfigArgs {
    /**
     * Whether this cluster should return group membership lookups during authentication using a group of security groups.
     */
    enabled?: pulumi.Input<boolean>;
    /**
     * The name of the security group-of-groups to be used. Only relevant if enabled = true.
     */
    securityGroup?: pulumi.Input<string>;
}

/**
 * AutoUpgradeOptions defines the set of options for the user to control how the Auto Upgrades will proceed.
 */
export interface AutoUpgradeOptionsArgs {
}

/**
 * Autopilot is the configuration for Autopilot settings on the cluster.
 */
export interface AutopilotArgs {
    /**
     * Enable Autopilot
     */
    enabled?: pulumi.Input<boolean>;
}

/**
 * AutoprovisioningNodePoolDefaults contains defaults for a node pool created by NAP.
 */
export interface AutoprovisioningNodePoolDefaultsArgs {
    /**
     * The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: https://cloud.google.com/compute/docs/disks/customer-managed-encryption
     */
    bootDiskKmsKey?: pulumi.Input<string>;
    /**
     * Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB. If unspecified, the default disk size is 100GB.
     */
    diskSizeGb?: pulumi.Input<number>;
    /**
     * Type of the disk attached to each node (e.g. 'pd-standard', 'pd-ssd' or 'pd-balanced') If unspecified, the default disk type is 'pd-standard'
     */
    diskType?: pulumi.Input<string>;
    /**
     * The image type to use for NAP created node.
     */
    imageType?: pulumi.Input<string>;
    /**
     * Specifies the node management options for NAP created node-pools.
     */
    management?: pulumi.Input<inputs.container.v1.NodeManagementArgs>;
    /**
     * Deprecated. Minimum CPU platform to be used for NAP created node pools. The instance may be scheduled on the specified or newer CPU platform. Applicable values are the friendly names of CPU platforms, such as minCpuPlatform: Intel Haswell or minCpuPlatform: Intel Sandy Bridge. For more information, read [how to specify min CPU platform](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform). This field is deprecated, min_cpu_platform should be specified using https://cloud.google.com/requested-min-cpu-platform label selector on the pod. To unset the min cpu platform field pass "automatic" as field value.
     *
     * @deprecated Deprecated. Minimum CPU platform to be used for NAP created node pools. The instance may be scheduled on the specified or newer CPU platform. Applicable values are the friendly names of CPU platforms, such as minCpuPlatform: Intel Haswell or minCpuPlatform: Intel Sandy Bridge. For more information, read [how to specify min CPU platform](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform). This field is deprecated, min_cpu_platform should be specified using https://cloud.google.com/requested-min-cpu-platform label selector on the pod. To unset the min cpu platform field pass "automatic" as field value.
     */
    minCpuPlatform?: pulumi.Input<string>;
    /**
     * Scopes that are used by NAP when creating node pools.
     */
    oauthScopes?: pulumi.Input<pulumi.Input<string>[]>;
    /**
     * The Google Cloud Platform Service Account to be used by the node VMs.
     */
    serviceAccount?: pulumi.Input<string>;
    /**
     * Shielded Instance options.
     */
    shieldedInstanceConfig?: pulumi.Input<inputs.container.v1.ShieldedInstanceConfigArgs>;
    /**
     * Specifies the upgrade settings for NAP created node pools
     */
    upgradeSettings?: pulumi.Input<inputs.container.v1.UpgradeSettingsArgs>;
}

/**
 * Parameters for using BigQuery as the destination of resource usage export.
 */
export interface BigQueryDestinationArgs {
    /**
     * The ID of a BigQuery Dataset.
     */
    datasetId?: pulumi.Input<string>;
}

/**
 * Configuration for Binary Authorization.
 */
export interface BinaryAuthorizationArgs {
    /**
     * This field is deprecated. Leave this unset and instead configure BinaryAuthorization using evaluation_mode. If evaluation_mode is set to anything other than EVALUATION_MODE_UNSPECIFIED, this field is ignored.
     *
     * @deprecated This field is deprecated. Leave this unset and instead configure BinaryAuthorization using evaluation_mode. If evaluation_mode is set to anything other than EVALUATION_MODE_UNSPECIFIED, this field is ignored.
     */
    enabled?: pulumi.Input<boolean>;
    /**
     * Mode of operation for binauthz policy evaluation. Currently the only options are equivalent to enable/disable. If unspecified, defaults to DISABLED.
     */
    evaluationMode?: pulumi.Input<enums.container.v1.BinaryAuthorizationEvaluationMode>;
}

/**
 * Settings for blue-green upgrade.
 */
export interface BlueGreenSettingsArgs {
    /**
     * Time needed after draining entire blue pool. After this period, blue pool will be cleaned up.
     */
    nodePoolSoakDuration?: pulumi.Input<string>;
    /**
     * Standard policy for the blue-green upgrade.
     */
    standardRolloutPolicy?: pulumi.Input<inputs.container.v1.StandardRolloutPolicyArgs>;
}

/**
 * CidrBlock contains an optional name and one CIDR block.
 */
export interface CidrBlockArgs {
    /**
     * cidr_block must be specified in CIDR notation.
     */
    cidrBlock?: pulumi.Input<string>;
    /**
     * display_name is an optional field for users to identify CIDR blocks.
     */
    displayName?: pulumi.Input<string>;
}

/**
 * Configuration for client certificates on the cluster.
 */
export interface ClientCertificateConfigArgs {
    /**
     * Issue a client certificate.
     */
    issueClientCertificate?: pulumi.Input<boolean>;
}

/**
 * Configuration options for the Cloud Run feature.
 */
export interface CloudRunConfigArgs {
    /**
     * Whether Cloud Run addon is enabled for this cluster.
     */
    disabled?: pulumi.Input<boolean>;
    /**
     * Which load balancer type is installed for Cloud Run.
     */
    loadBalancerType?: pulumi.Input<enums.container.v1.CloudRunConfigLoadBalancerType>;
}

/**
 * ClusterAutoscaling contains global, per-cluster information required by Cluster Autoscaler to automatically adjust the size of the cluster and create/delete node pools based on the current needs.
 */
export interface ClusterAutoscalingArgs {
    /**
     * The list of Google Compute Engine [zones](https://cloud.google.com/compute/docs/zones#available) in which the NodePool's nodes can be created by NAP.
     */
    autoprovisioningLocations?: pulumi.Input<pulumi.Input<string>[]>;
    /**
     * AutoprovisioningNodePoolDefaults contains defaults for a node pool created by NAP.
     */
    autoprovisioningNodePoolDefaults?: pulumi.Input<inputs.container.v1.AutoprovisioningNodePoolDefaultsArgs>;
    /**
     * Defines autoscaling behaviour.
     */
    autoscalingProfile?: pulumi.Input<enums.container.v1.ClusterAutoscalingAutoscalingProfile>;
    /**
     * Enables automatic node pool creation and deletion.
     */
    enableNodeAutoprovisioning?: pulumi.Input<boolean>;
    /**
     * Contains global constraints regarding minimum and maximum amount of resources in the cluster.
     */
    resourceLimits?: pulumi.Input<pulumi.Input<inputs.container.v1.ResourceLimitArgs>[]>;
}

/**
 * ConfidentialNodes is configuration for the confidential nodes feature, which makes nodes run on confidential VMs.
 */
export interface ConfidentialNodesArgs {
    /**
     * Whether Confidential Nodes feature is enabled.
     */
    enabled?: pulumi.Input<boolean>;
}

/**
 * Configuration options for the Config Connector add-on.
 */
export interface ConfigConnectorConfigArgs {
    /**
     * Whether Cloud Connector is enabled for this cluster.
     */
    enabled?: pulumi.Input<boolean>;
}

/**
 * Parameters for controlling consumption metering.
 */
export interface ConsumptionMeteringConfigArgs {
    /**
     * Whether to enable consumption metering for this cluster. If enabled, a second BigQuery table will be created to hold resource consumption records.
     */
    enabled?: pulumi.Input<boolean>;
}

/**
 * Configuration for fine-grained cost management feature.
 */
export interface CostManagementConfigArgs {
    /**
     * Whether the feature is enabled or not.
     */
    enabled?: pulumi.Input<boolean>;
}

/**
 * DNSConfig contains the desired set of options for configuring clusterDNS.
 */
export interface DNSConfigArgs {
    /**
     * cluster_dns indicates which in-cluster DNS provider should be used.
     */
    clusterDns?: pulumi.Input<enums.container.v1.DNSConfigClusterDns>;
    /**
     * cluster_dns_domain is the suffix used for all cluster service records.
     */
    clusterDnsDomain?: pulumi.Input<string>;
    /**
     * cluster_dns_scope indicates the scope of access to cluster DNS records.
     */
    clusterDnsScope?: pulumi.Input<enums.container.v1.DNSConfigClusterDnsScope>;
}

/**
 * Time window specified for daily maintenance operations.
 */
export interface DailyMaintenanceWindowArgs {
    /**
     * Time within the maintenance window to start the maintenance operations. Time format should be in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) format "HH:MM", where HH : [00-23] and MM : [00-59] GMT.
     */
    startTime?: pulumi.Input<string>;
}

/**
 * Configuration of etcd encryption.
 */
export interface DatabaseEncryptionArgs {
    /**
     * Name of CloudKMS key to use for the encryption of secrets in etcd. Ex. projects/my-project/locations/global/keyRings/my-ring/cryptoKeys/my-key
     */
    keyName?: pulumi.Input<string>;
    /**
     * Denotes the state of etcd encryption.
     */
    state?: pulumi.Input<enums.container.v1.DatabaseEncryptionState>;
}

/**
 * DefaultSnatStatus contains the desired state of whether default sNAT should be disabled on the cluster.
 */
export interface DefaultSnatStatusArgs {
    /**
     * Disables cluster default sNAT rules.
     */
    disabled?: pulumi.Input<boolean>;
}

/**
 * Configuration for NodeLocal DNSCache
 */
export interface DnsCacheConfigArgs {
    /**
     * Whether NodeLocal DNSCache is enabled for this cluster.
     */
    enabled?: pulumi.Input<boolean>;
}

/**
 * Allows filtering to one or more specific event types. If event types are present, those and only those event types will be transmitted to the cluster. Other types will be skipped. If no filter is specified, or no event types are present, all event types will be sent
 */
export interface FilterArgs {
    /**
     * Event types to allowlist.
     */
    eventType?: pulumi.Input<pulumi.Input<enums.container.v1.FilterEventTypeItem>[]>;
}

/**
 * GPUSharingConfig represents the GPU sharing configuration for Hardware Accelerators.
 */
export interface GPUSharingConfigArgs {
    /**
     * The type of GPU sharing strategy to enable on the GPU node.
     */
    gpuSharingStrategy?: pulumi.Input<enums.container.v1.GPUSharingConfigGpuSharingStrategy>;
    /**
     * The max number of containers that can share a physical GPU.
     */
    maxSharedClientsPerGpu?: pulumi.Input<string>;
}

/**
 * GatewayAPIConfig contains the desired config of Gateway API on this cluster.
 */
export interface GatewayAPIConfigArgs {
    /**
     * The Gateway API release channel to use for Gateway API.
     */
    channel?: pulumi.Input<enums.container.v1.GatewayAPIConfigChannel>;
}

/**
 * Configuration for the Compute Engine PD CSI driver.
 */
export interface GcePersistentDiskCsiDriverConfigArgs {
    /**
     * Whether the Compute Engine PD CSI driver is enabled for this cluster.
     */
    enabled?: pulumi.Input<boolean>;
}

/**
 * GcfsConfig contains configurations of Google Container File System (image streaming).
 */
export interface GcfsConfigArgs {
    /**
     * Whether to use GCFS.
     */
    enabled?: pulumi.Input<boolean>;
}

/**
 * Configuration for the GCP Filestore CSI driver.
 */
export interface GcpFilestoreCsiDriverConfigArgs {
    /**
     * Whether the GCP Filestore CSI driver is enabled for this cluster.
     */
    enabled?: pulumi.Input<boolean>;
}

/**
 * Configuration for the Backup for GKE Agent.
 */
export interface GkeBackupAgentConfigArgs {
    /**
     * Whether the Backup for GKE agent is enabled for this cluster.
     */
    enabled?: pulumi.Input<boolean>;
}

/**
 * Configuration options for the horizontal pod autoscaling feature, which increases or decreases the number of replica pods a replication controller has based on the resource usage of the existing pods.
 */
export interface HorizontalPodAutoscalingArgs {
    /**
     * Whether the Horizontal Pod Autoscaling feature is enabled in the cluster. When enabled, it ensures that metrics are collected into Stackdriver Monitoring.
     */
    disabled?: pulumi.Input<boolean>;
}

/**
 * Configuration options for the HTTP (L7) load balancing controller addon, which makes it easy to set up HTTP load balancers for services in a cluster.
 */
export interface HttpLoadBalancingArgs {
    /**
     * Whether the HTTP Load Balancing controller is enabled in the cluster. When enabled, it runs a small pod in the cluster that manages the load balancers.
     */
    disabled?: pulumi.Input<boolean>;
}

/**
 * Configuration for controlling how IPs are allocated in the cluster.
 */
export interface IPAllocationPolicyArgs {
    /**
     * This field is deprecated, use cluster_ipv4_cidr_block.
     *
     * @deprecated This field is deprecated, use cluster_ipv4_cidr_block.
     */
    clusterIpv4Cidr?: pulumi.Input<string>;
    /**
     * The IP address range for the cluster pod IPs. If this field is set, then `cluster.cluster_ipv4_cidr` must be left blank. This field is only applicable when `use_ip_aliases` is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. `/14`) to have a range chosen with a specific netmask. Set to a [CIDR](http://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing) notation (e.g. `10.96.0.0/14`) from the RFC-1918 private networks (e.g. `10.0.0.0/8`, `172.16.0.0/12`, `192.168.0.0/16`) to pick a specific range to use.
     */
    clusterIpv4CidrBlock?: pulumi.Input<string>;
    /**
     * The name of the secondary range to be used for the cluster CIDR block. The secondary range will be used for pod IP addresses. This must be an existing secondary range associated with the cluster subnetwork. This field is only applicable with use_ip_aliases is true and create_subnetwork is false.
     */
    clusterSecondaryRangeName?: pulumi.Input<string>;
    /**
     * Whether a new subnetwork will be created automatically for the cluster. This field is only applicable when `use_ip_aliases` is true.
     */
    createSubnetwork?: pulumi.Input<boolean>;
    /**
     * The ipv6 access type (internal or external) when create_subnetwork is true
     */
    ipv6AccessType?: pulumi.Input<enums.container.v1.IPAllocationPolicyIpv6AccessType>;
    /**
     * This field is deprecated, use node_ipv4_cidr_block.
     *
     * @deprecated This field is deprecated, use node_ipv4_cidr_block.
     */
    nodeIpv4Cidr?: pulumi.Input<string>;
    /**
     * The IP address range of the instance IPs in this cluster. This is applicable only if `create_subnetwork` is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. `/14`) to have a range chosen with a specific netmask. Set to a [CIDR](http://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing) notation (e.g. `10.96.0.0/14`) from the RFC-1918 private networks (e.g. `10.0.0.0/8`, `172.16.0.0/12`, `192.168.0.0/16`) to pick a specific range to use.
     */
    nodeIpv4CidrBlock?: pulumi.Input<string>;
    /**
     * This field is deprecated, use services_ipv4_cidr_block.
     *
     * @deprecated This field is deprecated, use services_ipv4_cidr_block.
     */
    servicesIpv4Cidr?: pulumi.Input<string>;
    /**
     * The IP address range of the services IPs in this cluster. If blank, a range will be automatically chosen with the default size. This field is only applicable when `use_ip_aliases` is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. `/14`) to have a range chosen with a specific netmask. Set to a [CIDR](http://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing) notation (e.g. `10.96.0.0/14`) from the RFC-1918 private networks (e.g. `10.0.0.0/8`, `172.16.0.0/12`, `192.168.0.0/16`) to pick a specific range to use.
     */
    servicesIpv4CidrBlock?: pulumi.Input<string>;
    /**
     * The name of the secondary range to be used as for the services CIDR block. The secondary range will be used for service ClusterIPs. This must be an existing secondary range associated with the cluster subnetwork. This field is only applicable with use_ip_aliases is true and create_subnetwork is false.
     */
    servicesSecondaryRangeName?: pulumi.Input<string>;
    /**
     * The IP stack type of the cluster
     */
    stackType?: pulumi.Input<enums.container.v1.IPAllocationPolicyStackType>;
    /**
     * A custom subnetwork name to be used if `create_subnetwork` is true. If this field is empty, then an automatic name will be chosen for the new subnetwork.
     */
    subnetworkName?: pulumi.Input<string>;
    /**
     * The IP address range of the Cloud TPUs in this cluster. If unspecified, a range will be automatically chosen with the default size. This field is only applicable when `use_ip_aliases` is true. If unspecified, the range will use the default size. Set to /netmask (e.g. `/14`) to have a range chosen with a specific netmask. Set to a [CIDR](http://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing) notation (e.g. `10.96.0.0/14`) from the RFC-1918 private networks (e.g. `10.0.0.0/8`, `172.16.0.0/12`, `192.168.0.0/16`) to pick a specific range to use.
     */
    tpuIpv4CidrBlock?: pulumi.Input<string>;
    /**
     * Whether alias IPs will be used for pod IPs in the cluster. This is used in conjunction with use_routes. It cannot be true if use_routes is true. If both use_ip_aliases and use_routes are false, then the server picks the default IP allocation mode
     */
    useIpAliases?: pulumi.Input<boolean>;
    /**
     * Whether routes will be used for pod IPs in the cluster. This is used in conjunction with use_ip_aliases. It cannot be true if use_ip_aliases is true. If both use_ip_aliases and use_routes are false, then the server picks the default IP allocation mode
     */
    useRoutes?: pulumi.Input<boolean>;
}

/**
 * IdentityServiceConfig is configuration for Identity Service which allows customers to use external identity providers with the K8S API
 */
export interface IdentityServiceConfigArgs {
    /**
     * Whether to enable the Identity Service component
     */
    enabled?: pulumi.Input<boolean>;
}

/**
 * Configuration for the Kubernetes Dashboard.
 */
export interface KubernetesDashboardArgs {
    /**
     * Whether the Kubernetes Dashboard is enabled for this cluster.
     */
    disabled?: pulumi.Input<boolean>;
}

/**
 * Configuration for the legacy Attribute Based Access Control authorization mode.
 */
export interface LegacyAbacArgs {
    /**
     * Whether the ABAC authorizer is enabled for this cluster. When enabled, identities in the system, including service accounts, nodes, and controllers, will have statically granted permissions beyond those provided by the RBAC configuration or IAM.
     */
    enabled?: pulumi.Input<boolean>;
}

/**
 * Parameters that can be configured on Linux nodes.
 */
export interface LinuxNodeConfigArgs {
    /**
     * cgroup_mode specifies the cgroup mode to be used on the node.
     */
    cgroupMode?: pulumi.Input<enums.container.v1.LinuxNodeConfigCgroupMode>;
    /**
     * The Linux kernel parameters to be applied to the nodes and all pods running on the nodes. The following parameters are supported. net.core.busy_poll net.core.busy_read net.core.netdev_max_backlog net.core.rmem_max net.core.wmem_default net.core.wmem_max net.core.optmem_max net.core.somaxconn net.ipv4.tcp_rmem net.ipv4.tcp_wmem net.ipv4.tcp_tw_reuse
     */
    sysctls?: pulumi.Input<{[key: string]: pulumi.Input<string>}>;
}

/**
 * LoggingComponentConfig is cluster logging component configuration.
 */
export interface LoggingComponentConfigArgs {
    /**
     * Select components to collect logs. An empty set would disable all logging.
     */
    enableComponents?: pulumi.Input<pulumi.Input<enums.container.v1.LoggingComponentConfigEnableComponentsItem>[]>;
}

/**
 * LoggingConfig is cluster logging configuration.
 */
export interface LoggingConfigArgs {
    /**
     * Logging components configuration
     */
    componentConfig?: pulumi.Input<inputs.container.v1.LoggingComponentConfigArgs>;
}

/**
 * LoggingVariantConfig specifies the behaviour of the logging component.
 */
export interface LoggingVariantConfigArgs {
    /**
     * Logging variant deployed on nodes.
     */
    variant?: pulumi.Input<enums.container.v1.LoggingVariantConfigVariant>;
}

/**
 * Represents the Maintenance exclusion option.
 */
export interface MaintenanceExclusionOptionsArgs {
    /**
     * Scope specifies the upgrade scope which upgrades are blocked by the exclusion.
     */
    scope?: pulumi.Input<enums.container.v1.MaintenanceExclusionOptionsScope>;
}

/**
 * MaintenancePolicy defines the maintenance policy to be used for the cluster.
 */
export interface MaintenancePolicyArgs {
    /**
     * A hash identifying the version of this policy, so that updates to fields of the policy won't accidentally undo intermediate changes (and so that users of the API unaware of some fields won't accidentally remove other fields). Make a `get()` request to the cluster to get the current resource version and include it with requests to set the policy.
     */
    resourceVersion?: pulumi.Input<string>;
    /**
     * Specifies the maintenance window in which maintenance may be performed.
     */
    window?: pulumi.Input<inputs.container.v1.MaintenanceWindowArgs>;
}

/**
 * MaintenanceWindow defines the maintenance window to be used for the cluster.
 */
export interface MaintenanceWindowArgs {
    /**
     * DailyMaintenanceWindow specifies a daily maintenance operation window.
     */
    dailyMaintenanceWindow?: pulumi.Input<inputs.container.v1.DailyMaintenanceWindowArgs>;
    /**
     * Exceptions to maintenance window. Non-emergency maintenance should not occur in these windows.
     */
    maintenanceExclusions?: pulumi.Input<{[key: string]: pulumi.Input<string>}>;
    /**
     * RecurringWindow specifies some number of recurring time periods for maintenance to occur. The time windows may be overlapping. If no maintenance windows are set, maintenance can occur at any time.
     */
    recurringWindow?: pulumi.Input<inputs.container.v1.RecurringTimeWindowArgs>;
}

/**
 * ManagedPrometheusConfig defines the configuration for Google Cloud Managed Service for Prometheus.
 */
export interface ManagedPrometheusConfigArgs {
    /**
     * Enable Managed Collection.
     */
    enabled?: pulumi.Input<boolean>;
}

/**
 * The authentication information for accessing the master endpoint. Authentication can be done using HTTP basic auth or using client certificates.
 */
export interface MasterAuthArgs {
    /**
     * Configuration for client certificate authentication on the cluster. For clusters before v1.12, if no configuration is specified, a client certificate is issued.
     */
    clientCertificateConfig?: pulumi.Input<inputs.container.v1.ClientCertificateConfigArgs>;
    /**
     * The password to use for HTTP basic authentication to the master endpoint. Because the master endpoint is open to the Internet, you should create a strong password. If a password is provided for cluster creation, username must be non-empty. Warning: basic authentication is deprecated, and will be removed in GKE control plane versions 1.19 and newer. For a list of recommended authentication methods, see: https://cloud.google.com/kubernetes-engine/docs/how-to/api-server-authentication
     */
    password?: pulumi.Input<string>;
    /**
     * The username to use for HTTP basic authentication to the master endpoint. For clusters v1.6.0 and later, basic authentication can be disabled by leaving username unspecified (or setting it to the empty string). Warning: basic authentication is deprecated, and will be removed in GKE control plane versions 1.19 and newer. For a list of recommended authentication methods, see: https://cloud.google.com/kubernetes-engine/docs/how-to/api-server-authentication
     */
    username?: pulumi.Input<string>;
}

/**
 * Configuration options for the master authorized networks feature. Enabled master authorized networks will disallow all external traffic to access Kubernetes master through HTTPS except traffic from the given CIDR blocks, Google Compute Engine Public IPs and Google Prod IPs.
 */
export interface MasterAuthorizedNetworksConfigArgs {
    /**
     * cidr_blocks define up to 50 external networks that could access Kubernetes master through HTTPS.
     */
    cidrBlocks?: pulumi.Input<pulumi.Input<inputs.container.v1.CidrBlockArgs>[]>;
    /**
     * Whether or not master authorized networks is enabled.
     */
    enabled?: pulumi.Input<boolean>;
    /**
     * Whether master is accessbile via Google Compute Engine Public IP addresses.
     */
    gcpPublicCidrsAccessEnabled?: pulumi.Input<boolean>;
}

/**
 * Constraints applied to pods.
 */
export interface MaxPodsConstraintArgs {
    /**
     * Constraint enforced on the max num of pods per node.
     */
    maxPodsPerNode?: pulumi.Input<string>;
}

/**
 * Configuration for issuance of mTLS keys and certificates to Kubernetes pods.
 */
export interface MeshCertificatesArgs {
    /**
     * enable_certificates controls issuance of workload mTLS certificates. If set, the GKE Workload Identity Certificates controller and node agent will be deployed in the cluster, which can then be configured by creating a WorkloadCertificateConfig Custom Resource. Requires Workload Identity (workload_pool must be non-empty).
     */
    enableCertificates?: pulumi.Input<boolean>;
}

/**
 * MonitoringComponentConfig is cluster monitoring component configuration.
 */
export interface MonitoringComponentConfigArgs {
    /**
     * Select components to collect metrics. An empty set would disable all monitoring.
     */
    enableComponents?: pulumi.Input<pulumi.Input<enums.container.v1.MonitoringComponentConfigEnableComponentsItem>[]>;
}

/**
 * MonitoringConfig is cluster monitoring configuration.
 */
export interface MonitoringConfigArgs {
    /**
     * Monitoring components configuration
     */
    componentConfig?: pulumi.Input<inputs.container.v1.MonitoringComponentConfigArgs>;
    /**
     * Enable Google Cloud Managed Service for Prometheus in the cluster.
     */
    managedPrometheusConfig?: pulumi.Input<inputs.container.v1.ManagedPrometheusConfigArgs>;
}

/**
 * NetworkConfig reports the relative names of network & subnetwork.
 */
export interface NetworkConfigArgs {
    /**
     * The desired datapath provider for this cluster. By default, uses the IPTables-based kube-proxy implementation.
     */
    datapathProvider?: pulumi.Input<enums.container.v1.NetworkConfigDatapathProvider>;
    /**
     * Whether the cluster disables default in-node sNAT rules. In-node sNAT rules will be disabled when default_snat_status is disabled. When disabled is set to false, default IP masquerade rules will be applied to the nodes to prevent sNAT on cluster internal traffic.
     */
    defaultSnatStatus?: pulumi.Input<inputs.container.v1.DefaultSnatStatusArgs>;
    /**
     * DNSConfig contains clusterDNS config for this cluster.
     */
    dnsConfig?: pulumi.Input<inputs.container.v1.DNSConfigArgs>;
    /**
     * Whether Intra-node visibility is enabled for this cluster. This makes same node pod to pod traffic visible for VPC network.
     */
    enableIntraNodeVisibility?: pulumi.Input<boolean>;
    /**
     * Whether L4ILB Subsetting is enabled for this cluster.
     */
    enableL4ilbSubsetting?: pulumi.Input<boolean>;
    /**
     * GatewayAPIConfig contains the desired config of Gateway API on this cluster.
     */
    gatewayApiConfig?: pulumi.Input<inputs.container.v1.GatewayAPIConfigArgs>;
    /**
     * The desired state of IPv6 connectivity to Google Services. By default, no private IPv6 access to or from Google Services (all access will be via IPv4)
     */
    privateIpv6GoogleAccess?: pulumi.Input<enums.container.v1.NetworkConfigPrivateIpv6GoogleAccess>;
    /**
     * ServiceExternalIPsConfig specifies if services with externalIPs field are blocked or not.
     */
    serviceExternalIpsConfig?: pulumi.Input<inputs.container.v1.ServiceExternalIPsConfigArgs>;
}

/**
 * Configuration of all network bandwidth tiers
 */
export interface NetworkPerformanceConfigArgs {
    /**
     * Specifies the total network bandwidth tier for the NodePool.
     */
    totalEgressBandwidthTier?: pulumi.Input<enums.container.v1.NetworkPerformanceConfigTotalEgressBandwidthTier>;
}

/**
 * Configuration options for the NetworkPolicy feature. https://kubernetes.io/docs/concepts/services-networking/networkpolicies/
 */
export interface NetworkPolicyArgs {
    /**
     * Whether network policy is enabled on the cluster.
     */
    enabled?: pulumi.Input<boolean>;
    /**
     * The selected network policy provider.
     */
    provider?: pulumi.Input<enums.container.v1.NetworkPolicyProvider>;
}

/**
 * Configuration for NetworkPolicy. This only tracks whether the addon is enabled or not on the Master, it does not track whether network policy is enabled for the nodes.
 */
export interface NetworkPolicyConfigArgs {
    /**
     * Whether NetworkPolicy is enabled for this cluster.
     */
    disabled?: pulumi.Input<boolean>;
}

/**
 * Collection of Compute Engine network tags that can be applied to a node's underlying VM instance.
 */
export interface NetworkTagsArgs {
    /**
     * List of network tags.
     */
    tags?: pulumi.Input<pulumi.Input<string>[]>;
}

/**
 * Parameters that describe the nodes in a cluster. GKE Autopilot clusters do not recognize parameters in `NodeConfig`. Use AutoprovisioningNodePoolDefaults instead.
 */
export interface NodeConfigArgs {
    /**
     * A list of hardware accelerators to be attached to each node. See https://cloud.google.com/compute/docs/gpus for more information about support for GPUs.
     */
    accelerators?: pulumi.Input<pulumi.Input<inputs.container.v1.AcceleratorConfigArgs>[]>;
    /**
     * Advanced features for the Compute Engine VM.
     */
    advancedMachineFeatures?: pulumi.Input<inputs.container.v1.AdvancedMachineFeaturesArgs>;
    /**
     *  The Customer Managed Encryption Key used to encrypt the boot disk attached to each node in the node pool. This should be of the form projects/[KEY_PROJECT_ID]/locations/[LOCATION]/keyRings/[RING_NAME]/cryptoKeys/[KEY_NAME]. For more information about protecting resources with Cloud KMS Keys please see: https://cloud.google.com/compute/docs/disks/customer-managed-encryption
     */
    bootDiskKmsKey?: pulumi.Input<string>;
    /**
     * Confidential nodes config. All the nodes in the node pool will be Confidential VM once enabled.
     */
    confidentialNodes?: pulumi.Input<inputs.container.v1.ConfidentialNodesArgs>;
    /**
     * Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB. If unspecified, the default disk size is 100GB.
     */
    diskSizeGb?: pulumi.Input<number>;
    /**
     * Type of the disk attached to each node (e.g. 'pd-standard', 'pd-ssd' or 'pd-balanced') If unspecified, the default disk type is 'pd-standard'
     */
    diskType?: pulumi.Input<string>;
    /**
     * Google Container File System (image streaming) configs.
     */
    gcfsConfig?: pulumi.Input<inputs.container.v1.GcfsConfigArgs>;
    /**
     * Enable or disable gvnic in the node pool.
     */
    gvnic?: pulumi.Input<inputs.container.v1.VirtualNICArgs>;
    /**
     * The image type to use for this node. Note that for a given image type, the latest version of it will be used.
     */
    imageType?: pulumi.Input<string>;
    /**
     * Node kubelet configs.
     */
    kubeletConfig?: pulumi.Input<inputs.container.v1.NodeKubeletConfigArgs>;
    /**
     * The map of Kubernetes labels (key/value pairs) to be applied to each node. These will added in addition to any default label(s) that Kubernetes may apply to the node. In case of conflict in label keys, the applied set may differ depending on the Kubernetes version -- it's best to assume the behavior is undefined and conflicts should be avoided. For more information, including usage and the valid values, see: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
     */
    labels?: pulumi.Input<{[key: string]: pulumi.Input<string>}>;
    /**
     * Parameters that can be configured on Linux nodes.
     */
    linuxNodeConfig?: pulumi.Input<inputs.container.v1.LinuxNodeConfigArgs>;
    /**
     * The number of local SSD disks to be attached to the node. The limit for this value is dependent upon the maximum number of disks available on a machine per zone. See: https://cloud.google.com/compute/docs/disks/local-ssd for more information.
     */
    localSsdCount?: pulumi.Input<number>;
    /**
     * Logging configuration.
     */
    loggingConfig?: pulumi.Input<inputs.container.v1.NodePoolLoggingConfigArgs>;
    /**
     * The name of a Google Compute Engine [machine type](https://cloud.google.com/compute/docs/machine-types) If unspecified, the default machine type is `e2-medium`.
     */
    machineType?: pulumi.Input<string>;
    /**
     * The metadata key/value pairs assigned to instances in the cluster. Keys must conform to the regexp `[a-zA-Z0-9-_]+` and be less than 128 bytes in length. These are reflected as part of a URL in the metadata server. Additionally, to avoid ambiguity, keys must not conflict with any other metadata keys for the project or be one of the reserved keys: - "cluster-location" - "cluster-name" - "cluster-uid" - "configure-sh" - "containerd-configure-sh" - "enable-os-login" - "gci-ensure-gke-docker" - "gci-metrics-enabled" - "gci-update-strategy" - "instance-template" - "kube-env" - "startup-script" - "user-data" - "disable-address-manager" - "windows-startup-script-ps1" - "common-psm1" - "k8s-node-setup-psm1" - "install-ssh-psm1" - "user-profile-psm1" Values are free-form strings, and only have meaning as interpreted by the image running in the instance. The only restriction placed on them is that each value's size must be less than or equal to 32 KB. The total size of all keys and values must be less than 512 KB.
     */
    metadata?: pulumi.Input<{[key: string]: pulumi.Input<string>}>;
    /**
     * Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform. Applicable values are the friendly names of CPU platforms, such as `minCpuPlatform: "Intel Haswell"` or `minCpuPlatform: "Intel Sandy Bridge"`. For more information, read [how to specify min CPU platform](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
     */
    minCpuPlatform?: pulumi.Input<string>;
    /**
     * Setting this field will assign instances of this pool to run on the specified node group. This is useful for running workloads on [sole tenant nodes](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes).
     */
    nodeGroup?: pulumi.Input<string>;
    /**
     * The set of Google API scopes to be made available on all of the node VMs under the "default" service account. The following scopes are recommended, but not required, and by default are not included: * `https://www.googleapis.com/auth/compute` is required for mounting persistent storage on your nodes. * `https://www.googleapis.com/auth/devstorage.read_only` is required for communicating with **gcr.io** (the [Google Container Registry](https://cloud.google.com/container-registry/)). If unspecified, no scopes are added, unless Cloud Logging or Cloud Monitoring are enabled, in which case their required scopes will be added.
     */
    oauthScopes?: pulumi.Input<pulumi.Input<string>[]>;
    /**
     * Whether the nodes are created as preemptible VM instances. See: https://cloud.google.com/compute/docs/instances/preemptible for more information about preemptible VM instances.
     */
    preemptible?: pulumi.Input<boolean>;
    /**
     * The optional reservation affinity. Setting this field will apply the specified [Zonal Compute Reservation](https://cloud.google.com/compute/docs/instances/reserving-zonal-resources) to this node pool.
     */
    reservationAffinity?: pulumi.Input<inputs.container.v1.ReservationAffinityArgs>;
    /**
     * The resource labels for the node pool to use to annotate any related Google Compute Engine resources.
     */
    resourceLabels?: pulumi.Input<{[key: string]: pulumi.Input<string>}>;
    /**
     * Sandbox configuration for this node.
     */
    sandboxConfig?: pulumi.Input<inputs.container.v1.SandboxConfigArgs>;
    /**
     * The Google Cloud Platform Service Account to be used by the node VMs. Specify the email address of the Service Account; otherwise, if no Service Account is specified, the "default" service account is used.
     */
    serviceAccount?: pulumi.Input<string>;
    /**
     * Shielded Instance options.
     */
    shieldedInstanceConfig?: pulumi.Input<inputs.container.v1.ShieldedInstanceConfigArgs>;
    /**
     * Spot flag for enabling Spot VM, which is a rebrand of the existing preemptible flag.
     */
    spot?: pulumi.Input<boolean>;
    /**
     * The list of instance tags applied to all nodes. Tags are used to identify valid sources or targets for network firewalls and are specified by the client during cluster or node pool creation. Each tag within the list must comply with RFC1035.
     */
    tags?: pulumi.Input<pulumi.Input<string>[]>;
    /**
     * List of kubernetes taints to be applied to each node. For more information, including usage and the valid values, see: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
     */
    taints?: pulumi.Input<pulumi.Input<inputs.container.v1.NodeTaintArgs>[]>;
    /**
     * The workload metadata configuration for this node.
     */
    workloadMetadataConfig?: pulumi.Input<inputs.container.v1.WorkloadMetadataConfigArgs>;
}

/**
 * Subset of NodeConfig message that has defaults.
 */
export interface NodeConfigDefaultsArgs {
    /**
     * GCFS (Google Container File System, also known as Riptide) options.
     */
    gcfsConfig?: pulumi.Input<inputs.container.v1.GcfsConfigArgs>;
    /**
     * Logging configuration for node pools.
     */
    loggingConfig?: pulumi.Input<inputs.container.v1.NodePoolLoggingConfigArgs>;
}

/**
 * Node kubelet configs.
 */
export interface NodeKubeletConfigArgs {
    /**
     * Enable CPU CFS quota enforcement for containers that specify CPU limits. This option is enabled by default which makes kubelet use CFS quota (https://www.kernel.org/doc/Documentation/scheduler/sched-bwc.txt) to enforce container CPU limits. Otherwise, CPU limits will not be enforced at all. Disable this option to mitigate CPU throttling problems while still having your pods to be in Guaranteed QoS class by specifying the CPU limits. The default value is 'true' if unspecified.
     */
    cpuCfsQuota?: pulumi.Input<boolean>;
    /**
     * Set the CPU CFS quota period value 'cpu.cfs_period_us'. The string must be a sequence of decimal numbers, each with optional fraction and a unit suffix, such as "300ms". Valid time units are "ns", "us" (or "Âµs"), "ms", "s", "m", "h". The value must be a positive duration.
     */
    cpuCfsQuotaPeriod?: pulumi.Input<string>;
    /**
     * Control the CPU management policy on the node. See https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/ The following values are allowed. * "none": the default, which represents the existing scheduling behavior. * "static": allows pods with certain resource characteristics to be granted increased CPU affinity and exclusivity on the node. The default value is 'none' if unspecified.
     */
    cpuManagerPolicy?: pulumi.Input<string>;
    /**
     * Set the Pod PID limits. See https://kubernetes.io/docs/concepts/policy/pid-limiting/#pod-pid-limits Controls the maximum number of processes allowed to run in a pod. The value must be greater than or equal to 1024 and less than 4194304.
     */
    podPidsLimit?: pulumi.Input<string>;
}

/**
 * NodeManagement defines the set of node management services turned on for the node pool.
 */
export interface NodeManagementArgs {
    /**
     * A flag that specifies whether the node auto-repair is enabled for the node pool. If enabled, the nodes in this node pool will be monitored and, if they fail health checks too many times, an automatic repair action will be triggered.
     */
    autoRepair?: pulumi.Input<boolean>;
    /**
     * A flag that specifies whether node auto-upgrade is enabled for the node pool. If enabled, node auto-upgrade helps keep the nodes in your node pool up to date with the latest release version of Kubernetes.
     */
    autoUpgrade?: pulumi.Input<boolean>;
    /**
     * Specifies the Auto Upgrade knobs for the node pool.
     */
    upgradeOptions?: pulumi.Input<inputs.container.v1.AutoUpgradeOptionsArgs>;
}

/**
 * Parameters for node pool-level network config.
 */
export interface NodeNetworkConfigArgs {
    /**
     * Input only. Whether to create a new range for pod IPs in this node pool. Defaults are provided for `pod_range` and `pod_ipv4_cidr_block` if they are not specified. If neither `create_pod_range` or `pod_range` are specified, the cluster-level default (`ip_allocation_policy.cluster_ipv4_cidr_block`) is used. Only applicable if `ip_allocation_policy.use_ip_aliases` is true. This field cannot be changed after the node pool has been created.
     */
    createPodRange?: pulumi.Input<boolean>;
    /**
     * Whether nodes have internal IP addresses only. If enable_private_nodes is not specified, then the value is derived from cluster.privateClusterConfig.enablePrivateNodes
     */
    enablePrivateNodes?: pulumi.Input<boolean>;
    /**
     * Network bandwidth tier configuration.
     */
    networkPerformanceConfig?: pulumi.Input<inputs.container.v1.NetworkPerformanceConfigArgs>;
    /**
     * The IP address range for pod IPs in this node pool. Only applicable if `create_pod_range` is true. Set to blank to have a range chosen with the default size. Set to /netmask (e.g. `/14`) to have a range chosen with a specific netmask. Set to a [CIDR](https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing) notation (e.g. `10.96.0.0/14`) to pick a specific range to use. Only applicable if `ip_allocation_policy.use_ip_aliases` is true. This field cannot be changed after the node pool has been created.
     */
    podIpv4CidrBlock?: pulumi.Input<string>;
    /**
     * The ID of the secondary range for pod IPs. If `create_pod_range` is true, this ID is used for the new range. If `create_pod_range` is false, uses an existing secondary range with this ID. Only applicable if `ip_allocation_policy.use_ip_aliases` is true. This field cannot be changed after the node pool has been created.
     */
    podRange?: pulumi.Input<string>;
}

/**
 * NodePool contains the name and configuration for a cluster's node pool. Node pools are a set of nodes (i.e. VM's), with a common configuration and specification, under the control of the cluster master. They may have a set of Kubernetes labels applied to them, which may be used to reference them during pod scheduling. They may also be resized up or down, to accommodate the workload.
 */
export interface NodePoolArgs {
    /**
     * Autoscaler configuration for this NodePool. Autoscaler is enabled only if a valid configuration is present.
     */
    autoscaling?: pulumi.Input<inputs.container.v1.NodePoolAutoscalingArgs>;
    /**
     * Which conditions caused the current node pool state.
     */
    conditions?: pulumi.Input<pulumi.Input<inputs.container.v1.StatusConditionArgs>[]>;
    /**
     * The node configuration of the pool.
     */
    config?: pulumi.Input<inputs.container.v1.NodeConfigArgs>;
    /**
     * The initial node count for the pool. You must ensure that your Compute Engine [resource quota](https://cloud.google.com/compute/quotas) is sufficient for this number of instances. You must also have available firewall and routes quota.
     */
    initialNodeCount?: pulumi.Input<number>;
    /**
     * The list of Google Compute Engine [zones](https://cloud.google.com/compute/docs/zones#available) in which the NodePool's nodes should be located. If this value is unspecified during node pool creation, the [Cluster.Locations](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1/projects.locations.clusters#Cluster.FIELDS.locations) value will be used, instead. Warning: changing node pool locations will result in nodes being added and/or removed.
     */
    locations?: pulumi.Input<pulumi.Input<string>[]>;
    /**
     * NodeManagement configuration for this NodePool.
     */
    management?: pulumi.Input<inputs.container.v1.NodeManagementArgs>;
    /**
     * The constraint on the maximum number of pods that can be run simultaneously on a node in the node pool.
     */
    maxPodsConstraint?: pulumi.Input<inputs.container.v1.MaxPodsConstraintArgs>;
    /**
     * The name of the node pool.
     */
    name?: pulumi.Input<string>;
    /**
     * Networking configuration for this NodePool. If specified, it overrides the cluster-level defaults.
     */
    networkConfig?: pulumi.Input<inputs.container.v1.NodeNetworkConfigArgs>;
    /**
     * Upgrade settings control disruption and speed of the upgrade.
     */
    upgradeSettings?: pulumi.Input<inputs.container.v1.UpgradeSettingsArgs>;
    /**
     * The version of the Kubernetes of this node.
     */
    version?: pulumi.Input<string>;
}

/**
 * Node pool configs that apply to all auto-provisioned node pools in autopilot clusters and node auto-provisioning enabled clusters.
 */
export interface NodePoolAutoConfigArgs {
    /**
     * The list of instance tags applied to all nodes. Tags are used to identify valid sources or targets for network firewalls and are specified by the client during cluster creation. Each tag within the list must comply with RFC1035.
     */
    networkTags?: pulumi.Input<inputs.container.v1.NetworkTagsArgs>;
}

/**
 * NodePoolAutoscaling contains information required by cluster autoscaler to adjust the size of the node pool to the current cluster usage.
 */
export interface NodePoolAutoscalingArgs {
    /**
     * Can this node pool be deleted automatically.
     */
    autoprovisioned?: pulumi.Input<boolean>;
    /**
     * Is autoscaling enabled for this node pool.
     */
    enabled?: pulumi.Input<boolean>;
    /**
     * Location policy used when scaling up a nodepool.
     */
    locationPolicy?: pulumi.Input<enums.container.v1.NodePoolAutoscalingLocationPolicy>;
    /**
     * Maximum number of nodes for one location in the NodePool. Must be >= min_node_count. There has to be enough quota to scale up the cluster.
     */
    maxNodeCount?: pulumi.Input<number>;
    /**
     * Minimum number of nodes for one location in the NodePool. Must be >= 1 and <= max_node_count.
     */
    minNodeCount?: pulumi.Input<number>;
    /**
     * Maximum number of nodes in the node pool. Must be greater than total_min_node_count. There has to be enough quota to scale up the cluster. The total_*_node_count fields are mutually exclusive with the *_node_count fields.
     */
    totalMaxNodeCount?: pulumi.Input<number>;
    /**
     * Minimum number of nodes in the node pool. Must be greater than 1 less than total_max_node_count. The total_*_node_count fields are mutually exclusive with the *_node_count fields.
     */
    totalMinNodeCount?: pulumi.Input<number>;
}

/**
 * Subset of Nodepool message that has defaults.
 */
export interface NodePoolDefaultsArgs {
    /**
     * Subset of NodeConfig message that has defaults.
     */
    nodeConfigDefaults?: pulumi.Input<inputs.container.v1.NodeConfigDefaultsArgs>;
}

/**
 * NodePoolLoggingConfig specifies logging configuration for nodepools.
 */
export interface NodePoolLoggingConfigArgs {
    /**
     * Logging variant configuration.
     */
    variantConfig?: pulumi.Input<inputs.container.v1.LoggingVariantConfigArgs>;
}

/**
 * Kubernetes taint is comprised of three fields: key, value, and effect. Effect can only be one of three types: NoSchedule, PreferNoSchedule or NoExecute. See [here](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration) for more information, including usage and the valid values.
 */
export interface NodeTaintArgs {
    /**
     * Effect for taint.
     */
    effect?: pulumi.Input<enums.container.v1.NodeTaintEffect>;
    /**
     * Key for taint.
     */
    key?: pulumi.Input<string>;
    /**
     * Value for taint.
     */
    value?: pulumi.Input<string>;
}

/**
 * NotificationConfig is the configuration of notifications.
 */
export interface NotificationConfigArgs {
    /**
     * Notification config for Pub/Sub.
     */
    pubsub?: pulumi.Input<inputs.container.v1.PubSubArgs>;
}

/**
 * Configuration options for private clusters.
 */
export interface PrivateClusterConfigArgs {
    /**
     * Whether the master's internal IP address is used as the cluster endpoint.
     */
    enablePrivateEndpoint?: pulumi.Input<boolean>;
    /**
     * Whether nodes have internal IP addresses only. If enabled, all nodes are given only RFC 1918 private addresses and communicate with the master via private networking.
     */
    enablePrivateNodes?: pulumi.Input<boolean>;
    /**
     * Controls master global access settings.
     */
    masterGlobalAccessConfig?: pulumi.Input<inputs.container.v1.PrivateClusterMasterGlobalAccessConfigArgs>;
    /**
     * The IP range in CIDR notation to use for the hosted master network. This range will be used for assigning internal IP addresses to the master or set of masters, as well as the ILB VIP. This range must not overlap with any other ranges in use within the cluster's network.
     */
    masterIpv4CidrBlock?: pulumi.Input<string>;
    /**
     * Subnet to provision the master's private endpoint during cluster creation. Specified in projects/*&#47;regions/*&#47;subnetworks/* format.
     */
    privateEndpointSubnetwork?: pulumi.Input<string>;
}

/**
 * Configuration for controlling master global access settings.
 */
export interface PrivateClusterMasterGlobalAccessConfigArgs {
    /**
     * Whenever master is accessible globally or not.
     */
    enabled?: pulumi.Input<boolean>;
}

/**
 * Pub/Sub specific notification config.
 */
export interface PubSubArgs {
    /**
     * Enable notifications for Pub/Sub.
     */
    enabled?: pulumi.Input<boolean>;
    /**
     * Allows filtering to one or more specific event types. If no filter is specified, or if a filter is specified with no event types, all event types will be sent
     */
    filter?: pulumi.Input<inputs.container.v1.FilterArgs>;
    /**
     * The desired Pub/Sub topic to which notifications will be sent by GKE. Format is `projects/{project}/topics/{topic}`.
     */
    topic?: pulumi.Input<string>;
}

/**
 * Represents an arbitrary window of time that recurs.
 */
export interface RecurringTimeWindowArgs {
    /**
     * An RRULE (https://tools.ietf.org/html/rfc5545#section-3.8.5.3) for how this window reccurs. They go on for the span of time between the start and end time. For example, to have something repeat every weekday, you'd use: `FREQ=WEEKLY;BYDAY=MO,TU,WE,TH,FR` To repeat some window daily (equivalent to the DailyMaintenanceWindow): `FREQ=DAILY` For the first weekend of every month: `FREQ=MONTHLY;BYSETPOS=1;BYDAY=SA,SU` This specifies how frequently the window starts. Eg, if you wanted to have a 9-5 UTC-4 window every weekday, you'd use something like: ``` start time = 2019-01-01T09:00:00-0400 end time = 2019-01-01T17:00:00-0400 recurrence = FREQ=WEEKLY;BYDAY=MO,TU,WE,TH,FR ``` Windows can span multiple days. Eg, to make the window encompass every weekend from midnight Saturday till the last minute of Sunday UTC: ``` start time = 2019-01-05T00:00:00Z end time = 2019-01-07T23:59:00Z recurrence = FREQ=WEEKLY;BYDAY=SA ``` Note the start and end time's specific dates are largely arbitrary except to specify duration of the window and when it first starts. The FREQ values of HOURLY, MINUTELY, and SECONDLY are not supported.
     */
    recurrence?: pulumi.Input<string>;
    /**
     * The window of the first recurrence.
     */
    window?: pulumi.Input<inputs.container.v1.TimeWindowArgs>;
}

/**
 * ReleaseChannel indicates which release channel a cluster is subscribed to. Release channels are arranged in order of risk. When a cluster is subscribed to a release channel, Google maintains both the master version and the node version. Node auto-upgrade defaults to true and cannot be disabled.
 */
export interface ReleaseChannelArgs {
    /**
     * channel specifies which release channel the cluster is subscribed to.
     */
    channel?: pulumi.Input<enums.container.v1.ReleaseChannelChannel>;
}

/**
 * [ReservationAffinity](https://cloud.google.com/compute/docs/instances/reserving-zonal-resources) is the configuration of desired reservation which instances could take capacity from.
 */
export interface ReservationAffinityArgs {
    /**
     * Corresponds to the type of reservation consumption.
     */
    consumeReservationType?: pulumi.Input<enums.container.v1.ReservationAffinityConsumeReservationType>;
    /**
     * Corresponds to the label key of a reservation resource. To target a SPECIFIC_RESERVATION by name, specify "compute.googleapis.com/reservation-name" as the key and specify the name of your reservation as its value.
     */
    key?: pulumi.Input<string>;
    /**
     * Corresponds to the label value(s) of reservation resource(s).
     */
    values?: pulumi.Input<pulumi.Input<string>[]>;
}

/**
 * Contains information about amount of some resource in the cluster. For memory, value should be in GB.
 */
export interface ResourceLimitArgs {
    /**
     * Maximum amount of the resource in the cluster.
     */
    maximum?: pulumi.Input<string>;
    /**
     * Minimum amount of the resource in the cluster.
     */
    minimum?: pulumi.Input<string>;
    /**
     * Resource name "cpu", "memory" or gpu-specific string.
     */
    resourceType?: pulumi.Input<string>;
}

/**
 * Configuration for exporting cluster resource usages.
 */
export interface ResourceUsageExportConfigArgs {
    /**
     * Configuration to use BigQuery as usage export destination.
     */
    bigqueryDestination?: pulumi.Input<inputs.container.v1.BigQueryDestinationArgs>;
    /**
     * Configuration to enable resource consumption metering.
     */
    consumptionMeteringConfig?: pulumi.Input<inputs.container.v1.ConsumptionMeteringConfigArgs>;
    /**
     * Whether to enable network egress metering for this cluster. If enabled, a daemonset will be created in the cluster to meter network egress traffic.
     */
    enableNetworkEgressMetering?: pulumi.Input<boolean>;
}

/**
 * SandboxConfig contains configurations of the sandbox to use for the node.
 */
export interface SandboxConfigArgs {
    /**
     * Type of the sandbox to use for the node.
     */
    type?: pulumi.Input<enums.container.v1.SandboxConfigType>;
}

/**
 * Config to block services with externalIPs field.
 */
export interface ServiceExternalIPsConfigArgs {
    /**
     * Whether Services with ExternalIPs field are allowed or not.
     */
    enabled?: pulumi.Input<boolean>;
}

/**
 * A set of Shielded Instance options.
 */
export interface ShieldedInstanceConfigArgs {
    /**
     * Defines whether the instance has integrity monitoring enabled. Enables monitoring and attestation of the boot integrity of the instance. The attestation is performed against the integrity policy baseline. This baseline is initially derived from the implicitly trusted boot image when the instance is created.
     */
    enableIntegrityMonitoring?: pulumi.Input<boolean>;
    /**
     * Defines whether the instance has Secure Boot enabled. Secure Boot helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.
     */
    enableSecureBoot?: pulumi.Input<boolean>;
}

/**
 * Configuration of Shielded Nodes feature.
 */
export interface ShieldedNodesArgs {
    /**
     * Whether Shielded Nodes features are enabled on all nodes in this cluster.
     */
    enabled?: pulumi.Input<boolean>;
}

/**
 * Standard rollout policy is the default policy for blue-green.
 */
export interface StandardRolloutPolicyArgs {
    /**
     * Number of blue nodes to drain in a batch.
     */
    batchNodeCount?: pulumi.Input<number>;
    /**
     * Percentage of the blue pool nodes to drain in a batch. The range of this field should be (0.0, 1.0].
     */
    batchPercentage?: pulumi.Input<number>;
    /**
     * Soak time after each batch gets drained. Default to zero.
     */
    batchSoakDuration?: pulumi.Input<string>;
}

/**
 * StatusCondition describes why a cluster or a node pool has a certain status (e.g., ERROR or DEGRADED).
 */
export interface StatusConditionArgs {
    /**
     * Canonical code of the condition.
     */
    canonicalCode?: pulumi.Input<enums.container.v1.StatusConditionCanonicalCode>;
    /**
     * Machine-friendly representation of the condition Deprecated. Use canonical_code instead.
     *
     * @deprecated Machine-friendly representation of the condition Deprecated. Use canonical_code instead.
     */
    code?: pulumi.Input<enums.container.v1.StatusConditionCode>;
    /**
     * Human-friendly representation of the condition
     */
    message?: pulumi.Input<string>;
}

/**
 * Represents an arbitrary window of time.
 */
export interface TimeWindowArgs {
    /**
     * The time that the window ends. The end time should take place after the start time.
     */
    endTime?: pulumi.Input<string>;
    /**
     * MaintenanceExclusionOptions provides maintenance exclusion related options.
     */
    maintenanceExclusionOptions?: pulumi.Input<inputs.container.v1.MaintenanceExclusionOptionsArgs>;
    /**
     * The time that the window first starts.
     */
    startTime?: pulumi.Input<string>;
}

/**
 * These upgrade settings control the level of parallelism and the level of disruption caused by an upgrade. maxUnavailable controls the number of nodes that can be simultaneously unavailable. maxSurge controls the number of additional nodes that can be added to the node pool temporarily for the time of the upgrade to increase the number of available nodes. (maxUnavailable + maxSurge) determines the level of parallelism (how many nodes are being upgraded at the same time). Note: upgrades inevitably introduce some disruption since workloads need to be moved from old nodes to new, upgraded ones. Even if maxUnavailable=0, this holds true. (Disruption stays within the limits of PodDisruptionBudget, if it is configured.) Consider a hypothetical node pool with 5 nodes having maxSurge=2, maxUnavailable=1. This means the upgrade process upgrades 3 nodes simultaneously. It creates 2 additional (upgraded) nodes, then it brings down 3 old (not yet upgraded) nodes at the same time. This ensures that there are always at least 4 nodes available. These upgrade settings configure the upgrade strategy for the node pool. Use strategy to switch between the strategies applied to the node pool. If the strategy is ROLLING, use max_surge and max_unavailable to control the level of parallelism and the level of disruption caused by upgrade. 1. maxSurge controls the number of additional nodes that can be added to the node pool temporarily for the time of the upgrade to increase the number of available nodes. 2. maxUnavailable controls the number of nodes that can be simultaneously unavailable. 3. (maxUnavailable + maxSurge) determines the level of parallelism (how many nodes are being upgraded at the same time). If the strategy is BLUE_GREEN, use blue_green_settings to configure the blue-green upgrade related settings. 1. standard_rollout_policy is the default policy. The policy is used to control the way blue pool gets drained. The draining is executed in the batch mode. The batch size could be specified as either percentage of the node pool size or the number of nodes. batch_soak_duration is the soak time after each batch gets drained. 2. node_pool_soak_duration is the soak time after all blue nodes are drained. After this period, the blue pool nodes will be deleted.
 */
export interface UpgradeSettingsArgs {
    /**
     * Settings for blue-green upgrade strategy.
     */
    blueGreenSettings?: pulumi.Input<inputs.container.v1.BlueGreenSettingsArgs>;
    /**
     * The maximum number of nodes that can be created beyond the current size of the node pool during the upgrade process.
     */
    maxSurge?: pulumi.Input<number>;
    /**
     * The maximum number of nodes that can be simultaneously unavailable during the upgrade process. A node is considered available if its status is Ready.
     */
    maxUnavailable?: pulumi.Input<number>;
    /**
     * Update strategy of the node pool.
     */
    strategy?: pulumi.Input<enums.container.v1.UpgradeSettingsStrategy>;
}

/**
 * VerticalPodAutoscaling contains global, per-cluster information required by Vertical Pod Autoscaler to automatically adjust the resources of pods controlled by it.
 */
export interface VerticalPodAutoscalingArgs {
    /**
     * Enables vertical pod autoscaling.
     */
    enabled?: pulumi.Input<boolean>;
}

/**
 * Configuration of gVNIC feature.
 */
export interface VirtualNICArgs {
    /**
     * Whether gVNIC features are enabled in the node pool.
     */
    enabled?: pulumi.Input<boolean>;
}

/**
 * Configuration for the use of Kubernetes Service Accounts in GCP IAM policies.
 */
export interface WorkloadIdentityConfigArgs {
    /**
     * The workload pool to attach all Kubernetes service accounts to.
     */
    workloadPool?: pulumi.Input<string>;
}

/**
 * WorkloadMetadataConfig defines the metadata configuration to expose to workloads on the node pool.
 */
export interface WorkloadMetadataConfigArgs {
    /**
     * Mode is the configuration for how to expose metadata to workloads running on the node pool.
     */
    mode?: pulumi.Input<enums.container.v1.WorkloadMetadataConfigMode>;
}

